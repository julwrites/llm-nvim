==============================================================================
tests/init.lua
==============================================================================
  -- This file is intentionally left empty.
  -- It's presence is required for Neovim to recognize this as a plugin's test directory.

==============================================================================
tests/spec/mock_vim.lua
==============================================================================
  -- tests/spec/mock_vim.lua

* local M = {}

* M.log = {
*   levels = {
*     INFO = 1,
*     WARN = 2,
*     ERROR = 3,
*     DEBUG = 4,
*   },
* }

* M.fn = {
    stdpath = function(type)
*     if type == "config" then
0       return "/fake/config"
*     elseif type == "cache" then
*       return "/fake/cache"
      else
*       return "/fake/path"
      end
    end,
    json_encode = function(tbl)
*     return M.json.encode(tbl)
    end,
    json_decode = function(s)
*     return M.json.decode(s)
    end,
*   shellescape = function(s) return s end,
*   jobstart = function() return 1 end,
*   jobsend = function() end,
*   jobclose = function() end,
*   expand = function(s) return s end,
    system = function(cmd)
*     if type(cmd) == 'table' then
0       cmd = table.concat(cmd, " ")
      end
*     if string.match(cmd, "models list --json") then
0       return '[]'
      end
*     if string.match(cmd, "aliases list --json") then
0       return '[]'
      end
*     if string.match(cmd, "fragments list --json") then
0       return '[]'
      end
*     return ""
    end,
* }

* M.api = {
*   nvim_buf_set_name = function() end,
*   nvim_win_set_config = function() end,
*   nvim_win_close = function() end,
*   nvim_win_get_cursor = function() return {1, 0} end,
*   nvim_buf_get_name = function() return "buffer_name" end,
*   nvim_get_current_buf = function() return 1 end,
*   nvim_create_user_command = function() end,
*   nvim_buf_set_option = function() end,
*   nvim_buf_set_lines = function() end,
*   nvim_create_buf = function() return 1 end,
*   nvim_set_current_buf = function() end,
*   nvim_buf_get_lines = function() return {} end,
*   nvim_buf_is_valid = function() return true end,
*   nvim_create_augroup = function() return 1 end,
*   nvim_create_autocmd = function() end,
*   nvim_open_win = function() return 1 end,
* }

  M.schedule = function(cb)
0   cb()
  end

  M.list_extend = function(t1, t2)
*   for _, v in ipairs(t2) do
*     table.insert(t1, v)
    end
  end

  M.defer_fn = function(fn, _)
0   fn()
  end

* M.wait = function() end

* M.json = {
    encode = function(val)
*     if type(val) == 'table' then
*       local parts = {}
        -- Check if it's an array or a map
*       local is_array = #val > 0 and val[1] ~= nil
*       if is_array then
*         for i = 1, #val do
*           table.insert(parts, M.json.encode(val[i]))
          end
*         return '[' .. table.concat(parts, ',') .. ']'
        else -- map
*         for k, v in pairs(val) do
*           table.insert(parts, string.format('"%s":%s', tostring(k), M.json.encode(v)))
          end
*         return '{' .. table.concat(parts, ',') .. '}'
        end
*     elseif type(val) == 'string' then
*       return '"' .. val .. '"'
      else
0       return tostring(val)
      end
    end,
    decode = function(s)
*     if s == '[]' then return {} end
*     if s == '[{"name": "test-template"}]' then
*         return { { name = 'test-template' } }
      end
*     if s == '[{"id": "schema1", "name": "Schema 1"}]' then
0         return { { id = 'schema1', name = 'Schema 1' } }
      end
*     if s == '{"id": "schema1", "name": "Schema 1"}' then
0         return { id = 'schema1', name = 'Schema 1' }
      end
*     if s == '{"name": "test-template-details", "prompt": "Test prompt"}' then
*         return { name = 'test-template-details', prompt = 'Test prompt' }
      end
*     return {}
    end,
* }

* M.cmd = function() end
* M.env = {}
* M.b = {}
  M.split = function(str, sep)
*   local result = {}
*   for s in string.gmatch(str, "([^" .. sep .. "]+)") do
*     table.insert(result, s)
    end
*   return result
  end

  M.tbl_deep_extend = function(a, b)
*   for k, v in pairs(b) do
0     if type(v) == "table" and type(a[k]) == "table" then
0       a[k] = M.tbl_deep_extend(a[k], v)
      else
0       a[k] = v
      end
    end
*   return a
  end

  M.tbl_isempty = function(tbl)
*   return next(tbl) == nil
  end

  M.tbl_count = function(tbl)
0   local count = 0
0   for _ in pairs(tbl) do
0     count = count + 1
    end
0   return count
  end

* M.notify = function() end

* function M.inspect(v)
0   return tostring(v)
  end

* function M.system(cmd, opts, callback)
0   return {
      wait = function()
0       return {
          stdout = "",
          stderr = "",
          code = 0,
        }
      end,
    }
  end


* _G.vim = M

* return M

==============================================================================
tests/spec/plugin_spec.lua
==============================================================================
* local spy = require('luassert.spy')

* describe('plugin/llm.lua', function()
    local command_handler_func
    local chat_mock
    local llm_mock
    local commands_mock
    local schemas_manager_mock
    local templates_manager_mock
    local shell_mock
    local config_mock

*   before_each(function()
      -- The existing mock_vim doesn't use a .new() constructor.
      -- We load it and then add the specific spies we need for this test.
*     _G.vim = require('tests.spec.mock_vim')
*     _G.vim.g = {} -- For the if vim.g.loaded_llm check
*     _G.vim.split = spy.new(function(str, _)
*         if str == '' then return {} end
*         local result = {}
          -- Simple space-based split for testing
*         for s in str:gmatch("%S+") do
*           table.insert(result, s)
          end
*         return result
      end)

*     command_handler_func = nil
*     _G.vim.api.nvim_create_user_command = spy.new(function(name, handler, _)
*       if name == 'LLM' then
*         command_handler_func = handler
        end
      end)
      -- Add mocks for the functions called by chat.start_chat() -> ui.create_split_buffer()
*     _G.vim.api.nvim_create_buf = spy.new(function() return 1 end) -- return a dummy buffer handle
*     _G.vim.api.nvim_open_win = spy.new(function() return 1 end) -- return a dummy window handle

*     chat_mock = { start_chat = spy.new() }
*     llm_mock = { prompt = spy.new() }
*     commands_mock = {
*       prompt = spy.new(),
*       prompt_with_current_file = spy.new(),
*       prompt_with_selection = spy.new(),
*       explain_code = spy.new(),
*     }
*     schemas_manager_mock = { select_schema = spy.new() }
*     templates_manager_mock = { select_template = spy.new() }
*     shell_mock = {
*       check_llm_installed = spy.new(function() return true end),
*       update_llm_cli = spy.new(),
*     }
*     config_mock = { get = spy.new() }

      -- Use package.loaded for robust mocking
*     package.loaded['llm'] = llm_mock
*     package.loaded['llm.chat'] = chat_mock
*     package.loaded['llm.commands'] = commands_mock
*     package.loaded['llm.managers.schemas_manager'] = schemas_manager_mock
*     package.loaded['llm.managers.templates_manager'] = templates_manager_mock
*     package.loaded['llm.core.utils.shell'] = shell_mock
*     package.loaded['llm.config'] = config_mock
      -- The chat module requires the ui module, so we need a mock for it.
*     package.loaded['llm.core.utils.ui'] = { create_split_buffer = spy.new() }


      -- Sideload the plugin. This will call our mocked nvim_create_user_command
      -- which captures the handler function.
*     package.loaded['plugin/llm'] = nil
      -- Using require is better than dofile as it interacts with package.loaded
*     require('plugin/llm')
    end)

*   after_each(function()
      -- Clean up mocks from package.loaded
*     package.loaded['plugin/llm'] = nil
*     package.loaded['llm'] = nil
*     package.loaded['llm.chat'] = nil
*     package.loaded['llm.commands'] = nil
*     package.loaded['llm.managers.schemas_manager'] = nil
*     package.loaded['llm.managers.templates_manager'] = nil
*     package.loaded['llm.core.utils.shell'] = nil
*     package.loaded['llm.config'] = nil
*     package.loaded['llm.core.utils.ui'] = nil
*     _G.vim = nil
    end)

*   describe(':LLM command handler', function()
*     it('should call chat.start_chat() when called with no arguments', function()
*       assert.is_not_nil(command_handler_func)
*       command_handler_func({ args = '', range = 0 })
*       assert.spy(chat_mock.start_chat).was.called()
*       assert.spy(llm_mock.prompt).was.not_called()
      end)

*     it('should call commands.prompt() when called with a prompt', function()
*       assert.is_not_nil(command_handler_func)
*       command_handler_func({ args = 'hello world', range = 0 })
*       assert.spy(commands_mock.prompt).was.called_with('hello world')
*       assert.spy(chat_mock.start_chat).was.not_called()
      end)
    end)
  end)

==============================================================================
tests/spec/loaders_spec.lua
==============================================================================
  -- tests/spec/core/loaders_spec.lua
  --
  -- Unit tests for the loaders module.
  -- License: Apache 2.0

* describe('llm.core.loaders', function()
*   describe('load_models()', function()
*     it('should parse model list and set cache', function()
        -- Arrange
*       local mock_llm_cli = {
*         run_llm_command = spy.new(function()
0           return [[
  openai: gpt-4
  openai: gpt-3.5-turbo
* ]]
          end),
        }
*       local mock_cache = {
*         set = spy.new(function() end),
        }
*       package.loaded['llm.core.data.llm_cli'] = mock_llm_cli
*       package.loaded['llm.core.data.cache'] = mock_cache
*       package.loaded['llm.core.loaders'] = nil
*       local loaders = require('llm.core.loaders')

        -- Act
*       loaders.load_models()

        -- Assert
*       assert.spy(mock_llm_cli.run_llm_command).was_called_with('models list')
*       assert.spy(mock_cache.set).was_called()
*       local cache_args = mock_cache.set.calls[1].vals
*       assert.are.equal('models', cache_args[1])
*       assert.are.same({
*         { provider = 'openai', id = 'gpt-4', name = 'gpt-4' },
*         { provider = 'openai', id = 'gpt-3.5-turbo', name = 'gpt-3.5-turbo' },
*       }, cache_args[2])

        -- Clean up
*       package.loaded['llm.core.data.llm_cli'] = nil
*       package.loaded['llm.core.data.cache'] = nil
      end)
    end)

*   describe('load_schemas()', function()
*     it('should parse schema list and set cache', function()
        -- Arrange
*       local mock_llm_cli = {
*         run_llm_command = spy.new(function()
0           return [[
  schema1 - description1
  schema2 - description2
* ]]
          end),
        }
*       local mock_cache = {
*         set = spy.new(function() end),
        }
*       package.loaded['llm.core.data.llm_cli'] = mock_llm_cli
*       package.loaded['llm.core.data.cache'] = mock_cache
*       package.loaded['llm.core.loaders'] = nil
*       local loaders = require('llm.core.loaders')

        -- Act
*       loaders.load_schemas()

        -- Assert
*       assert.spy(mock_llm_cli.run_llm_command).was_called_with('schemas list')
*       assert.spy(mock_cache.set).was_called()
*       local cache_args = mock_cache.set.calls[1].vals
*       assert.are.equal('schemas', cache_args[1])
*       assert.are.same({
*         { id = 'schema1', description = 'description1' },
*         { id = 'schema2', description = 'description2' },
*       }, cache_args[2])

        -- Clean up
*       package.loaded['llm.core.data.llm_cli'] = nil
*       package.loaded['llm.core.data.cache'] = nil
      end)
    end)

*   describe('load_templates()', function()
*     it('should parse template list and set cache', function()
        -- Arrange
*       local mock_llm_cli = {
*         run_llm_command = spy.new(function()
0           return [[
  template1 - description1
  template2 - description2
* ]]
          end),
        }
*       local mock_cache = {
*         set = spy.new(function() end),
        }
*       package.loaded['llm.core.data.llm_cli'] = mock_llm_cli
*       package.loaded['llm.core.data.cache'] = mock_cache
*       package.loaded['llm.core.loaders'] = nil
*       local loaders = require('llm.core.loaders')

        -- Act
*       loaders.load_templates()

        -- Assert
*       assert.spy(mock_llm_cli.run_llm_command).was_called_with('templates list')
*       assert.spy(mock_cache.set).was_called()
*       local cache_args = mock_cache.set.calls[1].vals
*       assert.are.equal('templates', cache_args[1])
*       assert.are.same({
*         { name = 'template1', description = 'description1' },
*         { name = 'template2', description = 'description2' },
*       }, cache_args[2])

        -- Clean up
*       package.loaded['llm.core.data.llm_cli'] = nil
*       package.loaded['llm.core.data.cache'] = nil
      end)
    end)

*   describe('load_fragments()', function()
*     it('should parse fragment list and set cache', function()
        -- Arrange
*       local mock_llm_cli = {
*         run_llm_command = spy.new(function()
0           return [[
    - hash: 12345
      - alias1
      - alias2
      source: source1
      content: content1
      datetime: datetime1
    - hash: 67890
      - alias3
      source: source2
      content: content2
      datetime: datetime2
* ]]
          end),
        }
*       local mock_cache = {
*         set = spy.new(function() end),
        }
*       package.loaded['llm.core.data.llm_cli'] = mock_llm_cli
*       package.loaded['llm.core.data.cache'] = mock_cache
*       package.loaded['llm.core.loaders'] = nil
*       local loaders = require('llm.core.loaders')

        -- Act
*       loaders.load_fragments()

        -- Assert
*       assert.spy(mock_llm_cli.run_llm_command).was_called_with('fragments list')
*       assert.spy(mock_cache.set).was_called()
*       local cache_args = mock_cache.set.calls[1].vals
*       assert.are.equal('fragments', cache_args[1])
*       assert.are.same({
          {
*           hash = '12345',
*           aliases = { 'alias1', 'alias2' },
*           source = 'source1',
*           content = 'content1',
*           datetime = 'datetime1',
*         },
          {
*           hash = '67890',
*           aliases = { 'alias3' },
*           source = 'source2',
*           content = 'content2',
*           datetime = 'datetime2',
          },
*       }, cache_args[2])

        -- Clean up
*       package.loaded['llm.core.data.llm_cli'] = nil
*       package.loaded['llm.core.data.cache'] = nil
      end)
    end)

*   describe('load_keys()', function()
*     it('should parse key list and set cache', function()
        -- Arrange
*       local mock_llm_cli = {
*         run_llm_command = spy.new(function()
0           return [[
  Stored keys:
  ------------------
  key1
  key2
* ]]
          end),
        }
*       local mock_cache = {
*         set = spy.new(function() end),
        }
*       package.loaded['llm.core.data.llm_cli'] = mock_llm_cli
*       package.loaded['llm.core.data.cache'] = mock_cache
*       package.loaded['llm.core.loaders'] = nil
*       local loaders = require('llm.core.loaders')

        -- Act
*       loaders.load_keys()

        -- Assert
*       assert.spy(mock_llm_cli.run_llm_command).was_called_with('keys list')
*       assert.spy(mock_cache.set).was_called()
*       local cache_args = mock_cache.set.calls[1].vals
*       assert.are.equal('keys', cache_args[1])
*       assert.are.same({
*         { name = 'key1' },
*         { name = 'key2' },
*       }, cache_args[2])

        -- Clean up
*       package.loaded['llm.core.data.llm_cli'] = nil
*       package.loaded['llm.core.data.cache'] = nil
      end)
    end)

*   describe('load_available_plugins()', function()
*     it('should parse plugin list and set cache', function()
        -- Arrange
*       local mock_llm_cli = {
*         run_llm_command = spy.new(function()
0           return [[
  plugin1 - description1
  plugin2 - description2
* ]]
          end),
        }
*       local mock_cache = {
*         set = spy.new(function() end),
        }
*       package.loaded['llm.core.data.llm_cli'] = mock_llm_cli
*       package.loaded['llm.core.data.cache'] = mock_cache
*       package.loaded['llm.core.loaders'] = nil
*       local loaders = require('llm.core.loaders')

        -- Act
*       loaders.load_available_plugins()

        -- Assert
*       assert.spy(mock_llm_cli.run_llm_command).was_called_with('plugins --all')
*       assert.spy(mock_cache.set).was_called()
*       local cache_args = mock_cache.set.calls[1].vals
*       assert.are.equal('available_plugins', cache_args[1])
*       assert.are.same({
*         { name = 'plugin1', description = 'description1' },
*         { name = 'plugin2', description = 'description2' },
*       }, cache_args[2])

        -- Clean up
*       package.loaded['llm.core.data.llm_cli'] = nil
*       package.loaded['llm.core.data.cache'] = nil
      end)
    end)

*   describe('load_all()', function()
*     it('should call all loader functions', function()
        -- Arrange
*       local loaders = require('llm.core.loaders')
*       local spy_load_models = spy.on(loaders, 'load_models')
*       local spy_load_available_plugins = spy.on(loaders, 'load_available_plugins')
*       local spy_load_keys = spy.on(loaders, 'load_keys')
*       local spy_load_fragments = spy.on(loaders, 'load_fragments')
*       local spy_load_templates = spy.on(loaders, 'load_templates')
*       local spy_load_schemas = spy.on(loaders, 'load_schemas')

        -- Act
*       loaders.load_all()

        -- Assert
*       assert.spy(spy_load_models).was_called()
*       assert.spy(spy_load_available_plugins).was_called()
*       assert.spy(spy_load_keys).was_called()
*       assert.spy(spy_load_fragments).was_called()
*       assert.spy(spy_load_templates).was_called()
*       assert.spy(spy_load_schemas).was_called()
      end)
    end)
  end)

==============================================================================
tests/spec/cache_spec.lua
==============================================================================
  -- tests/spec/core/data/cache_spec.lua

* describe("llm.core.data.cache", function()
    local cache
    local mock_io
    local mock_json

*   before_each(function()
      -- Mock io functions
*     mock_io = {
        open = function()
0         return {
            read = function() return "" end,
            write = function() end,
            close = function() end,
          }
        end,
*     }
*     package.loaded['io'] = mock_io

      -- Mock vim object
*     _G.vim = {
*       fn = {
*         stdpath = function() return "/tmp" end,
          json_decode = function(str)
*           if str == "" then return {} end
0           return { test_key = "test_value" }
          end,
*         json_encode = function() return "" end,
*       },
*     }

      -- Reload the cache module to use the mocks
*     package.loaded['llm.core.data.cache'] = nil
*     cache = require('llm.core.data.cache')
    end)

*   after_each(function()
      -- Restore original modules
*     package.loaded['io'] = nil
*     package.loaded['llm.core.data.cache'] = nil
*     _G.vim = nil
    end)

*   it("should set a value in the cache", function()
*     local key = "test_key"
*     local value = "test_value"
*     cache.set(key, value)
*     assert.are.equal(value, cache.get(key))
    end)

*   it("should get a value from the cache", function()
*     local key = "test_key"
*     local value = "test_value"
*     cache.set(key, value)
*     local retrieved_value = cache.get(key)
*     assert.are.equal(value, retrieved_value)
    end)

*   it("should invalidate a value in the cache", function()
*     local key = "test_key"
*     local value = "test_value"
*     cache.set(key, value)
*     cache.invalidate(key)
*     assert.is_nil(cache.get(key))
    end)
  end)

==============================================================================
tests/spec/scratch_buffer_spec.lua
==============================================================================
* require('spec_helper')

* describe('llm.core.utils.ui', function()
*   local ui_utils = require('llm.core.utils.ui')

*   describe('create_prompt_buffer()', function()
*     it('should create a prompt buffer', function()
*         spy.on(vim, 'cmd')
*         spy.on(vim.api, 'nvim_get_current_buf')
*         spy.on(vim.api, 'nvim_buf_set_lines')
*         spy.on(vim.api, 'nvim_create_augroup')
*         spy.on(vim.api, 'nvim_create_autocmd')

*         ui_utils.create_prompt_buffer()

*         assert.spy(vim.cmd).was.called_with('vnew')
*         assert.spy(vim.cmd).was.called_with('startinsert')
*         assert.spy(vim.api.nvim_get_current_buf).was.called()
*         assert.spy(vim.api.nvim_buf_set_lines).was.called()
*         assert.spy(vim.api.nvim_create_augroup).was.called()
*         assert.spy(vim.api.nvim_create_autocmd).was.called()
      end)
    end)
  end)

==============================================================================
tests/spec/chat_spec.lua
==============================================================================
* require('spec_helper')

* describe('llm.chat', function()
    local chat
    local ChatSession
    local ChatBuffer
    local config_mock

*   before_each(function()
      -- Mock config
*     config_mock = {
*       get = spy.new(function(key)
*         if key == "model" then return "test-model" end
*         if key == "system_prompt" then return "test-system-prompt" end
*         if key == "llm_executable_path" then return "/usr/bin/llm" end
*         if key == "debug" then return false end
0         return nil
        end),
*     }
*     package.loaded['llm.config'] = config_mock

      -- Mock shell module
*     local shell_mock = {
*       run = spy.new(function(cmd)
          -- Mock llm logs response
0         return '[{"conversation_id": "test-conv-123"}]'
        end),
      }
*     package.loaded['llm.core.utils.shell'] = shell_mock

      -- Mock job module
*     local job_mock = {
*       run = spy.new(function(cmd, callbacks)
          -- Return a mock job ID
*         return 12345
        end),
      }
*     package.loaded['llm.core.utils.job'] = job_mock

      -- Mock vim functions
*     vim.api.nvim_get_current_buf = spy.new(function() return 1 end)
*     vim.api.nvim_create_buf = spy.new(function() return 1 end)
*     vim.api.nvim_buf_set_option = spy.new(function() end)
*     vim.api.nvim_buf_set_name = spy.new(function() end)
*     vim.api.nvim_buf_set_lines = spy.new(function() end)
*     vim.api.nvim_buf_get_lines = spy.new(function()
*       return {
*         "╭──────────────────────╮",
*         "│ Status: Ready        │",
*         "╰──────────────────────╯",
*         "",
*         "┌─ Conversation History ──┐",
*         "│ No messages yet         │",
*         "└─────────────────────────┘",
*         "",
*         "┌─ Your Message (Press <C-CR> to send) ──┐",
*         "│ Test message                            │",
          "└─────────────────────────────────────────┘",
*       }
      end)
*     vim.api.nvim_buf_add_highlight = spy.new(function() end)
*     vim.api.nvim_buf_set_keymap = spy.new(function() end)
*     vim.api.nvim_win_get_cursor = spy.new(function() return { 10, 0 } end)
*     vim.api.nvim_win_set_cursor = spy.new(function() end)
*     vim.api.nvim_buf_line_count = spy.new(function() return 11 end)
*     vim.api.nvim_set_hl = spy.new(function() end)
*     vim.api.nvim_create_autocmd = spy.new(function() end)
*     vim.cmd = spy.new(function() end)
*     vim.fn.jobstart = spy.new(function() return 12345 end)
*     vim.fn.jobstop = spy.new(function() end)
*     vim.fn.chansend = spy.new(function() end)
*     vim.fn.chanclose = spy.new(function() end)
*     vim.fn.mode = spy.new(function() return 'n' end)

      -- Mock vim.b with proper metatable for indexing
*     local b_storage = {}
*     vim.b = setmetatable({}, {
        __index = function(t, k)
*         if not b_storage[k] then
*           b_storage[k] = {}
          end
*         return b_storage[k]
        end,
        __newindex = function(t, k, v)
*         b_storage[k] = v
        end
*     })

      -- Mock notify
*     vim.notify = spy.new(function() end)

      -- Reload modules to pick up mocks
*     package.loaded['llm.chat.session'] = nil
*     package.loaded['llm.chat.buffer'] = nil
*     package.loaded['llm.chat'] = nil

*     ChatSession = require('llm.chat.session').ChatSession
*     ChatBuffer = require('llm.chat.buffer').ChatBuffer
*     chat = require('llm.chat')
    end)

*   after_each(function()
*     package.loaded['llm.config'] = nil
*     package.loaded['llm.core.utils.shell'] = nil
*     package.loaded['llm.core.utils.job'] = nil
*     package.loaded['llm.chat.session'] = nil
*     package.loaded['llm.chat.buffer'] = nil
*     package.loaded['llm.chat'] = nil
    end)

*   describe('ChatSession', function()
*     it('should create a new session with default options', function()
*       local session = ChatSession.new()

*       assert.is_not_nil(session)
*       assert.is_nil(session.conversation_id)
*       assert.are.equal('ready', session.state)
      end)

*     it('should create a new session with custom options', function()
*       local session = ChatSession.new({
*         model = "custom-model",
*         system_prompt = "custom-prompt",
*         fragments = { "/path/to/file.txt" },
        })

*       assert.are.equal("custom-model", session.model)
*       assert.are.equal("custom-prompt", session.system_prompt)
*       assert.are.same({ "/path/to/file.txt" }, session.fragments)
      end)

*     it('should build command for first message', function()
*       local session = ChatSession.new({
*         model = "gpt-4",
*         system_prompt = "You are helpful",
        })

*       local cmd = session:build_command("Hello")

*       assert.are.same({
*         "/usr/bin/llm", "prompt",
*         "-m", "gpt-4",
*         "-s", "You are helpful",
*       }, cmd)
      end)

*     it('should build command for continuation', function()
*       local session = ChatSession.new({
*         model = "gpt-4",
*         system_prompt = "You are helpful",
        })
*       session.conversation_id = "conv-123"

*       local cmd = session:build_command("Follow up")

*       assert.are.same({
*         "/usr/bin/llm", "prompt",
*         "-m", "gpt-4",
*         "-c", "conv-123",
*       }, cmd)
      end)

*     it('should extract conversation ID from output', function()
*       local session = ChatSession.new()

*       local output = "Some response text\n\nConversation ID: abc123def\n"
*       local id = session:extract_conversation_id(output)

*       assert.are.equal("abc123def", id)
      end)

*     it('should send prompt and update state', function()
*       local session = ChatSession.new()

*       local callbacks = {
*         on_stdout = spy.new(function() end),
*         on_stderr = spy.new(function() end),
*         on_exit = spy.new(function() end),
        }

*       local job_id = session:send_prompt("Test prompt", callbacks)

*       assert.are.equal(12345, job_id)
*       assert.are.equal('processing', session.state)
*       assert.are.equal(12345, session.current_job_id)
      end)

*     it('should check if session is ready', function()
*       local session = ChatSession.new()

*       assert.is_true(session:is_ready())

*       session.state = 'processing'
*       assert.is_false(session:is_ready())

*       session.state = 'error'
*       assert.is_false(session:is_ready())
      end)
    end)

*   describe('ChatBuffer', function()
*     it('should create a new buffer', function()
*       local buffer = ChatBuffer.new()

*       assert.is_not_nil(buffer)
*       assert.are.equal(1, buffer.bufnr)
*       assert.spy(vim.api.nvim_buf_set_option).was.called()
*       assert.spy(vim.api.nvim_buf_set_keymap).was.called()
      end)

*     it('should initialize layout with sections', function()
*       local buffer = ChatBuffer.new()

*       assert.spy(vim.api.nvim_buf_set_lines).was.called()
*       assert.is_number(buffer.history_start_line)
*       assert.is_number(buffer.history_end_line)
*       assert.is_number(buffer.input_start_line)
*       assert.is_number(buffer.input_end_line)
      end)

*     it('should set status message', function()
*       local buffer = ChatBuffer.new()

*       buffer:set_status("Processing...")

*       assert.spy(vim.api.nvim_buf_set_lines).was.called()
      end)

*     it('should update conversation ID', function()
*       local buffer = ChatBuffer.new()

*       buffer:update_conversation_id("new-conv-123")

*       assert.are.equal("new-conv-123", buffer.conversation_id)
*       assert.spy(vim.api.nvim_buf_set_name).was.called()
      end)

*     it('should append user message to history', function()
*       local buffer = ChatBuffer.new()

*       buffer:append_user_message("Hello, LLM!")

*       assert.spy(vim.api.nvim_buf_set_lines).was.called()
*       assert.spy(vim.api.nvim_buf_add_highlight).was.called()
      end)

*     it('should append LLM message to history', function()
*       local buffer = ChatBuffer.new()

*       buffer:append_llm_message("Hello, user!")

*       assert.spy(vim.api.nvim_buf_set_lines).was.called()
*       assert.spy(vim.api.nvim_buf_add_highlight).was.called()
      end)

*     it('should get user input from input area', function()
*       local buffer = ChatBuffer.new()

*       local input = buffer:get_user_input()

        -- Should extract "Test message" from the mocked buffer lines
*       assert.is_string(input)
      end)

*     it('should clear input area', function()
*       local buffer = ChatBuffer.new()

*       buffer:clear_input()

*       assert.spy(vim.api.nvim_buf_set_lines).was.called()
      end)

*     it('should focus input area', function()
*       local buffer = ChatBuffer.new()

*       buffer:focus_input()

*       assert.spy(vim.api.nvim_win_set_cursor).was.called()
*       assert.spy(vim.cmd).was.called_with('startinsert')
      end)
    end)

*   describe('chat orchestration', function()
      local _session, _buffer, _bufnr

*     before_each(function()
*       local result = chat.start_chat({
*         model = "gpt-4",
*         system_prompt = "Test prompt",
        })
*       _session = result.session
*       _buffer = result.buffer
*       _bufnr = _buffer:get_bufnr()

        -- Ensure vim.b is correctly set for the mocked buffer
*       vim.b[_bufnr].llm_chat_bufnr = _bufnr

        -- Mock vim.api.nvim_get_current_buf to return the chat buffer
*       vim.api.nvim_get_current_buf = spy.new(function() return _bufnr end)
      end)
*     it('should start a new chat session', function()
*       local result = chat.start_chat({
*         model = "gpt-4",
*         system_prompt = "Test prompt",
        })

*       assert.is_not_nil(result)
*       assert.is_not_nil(result.session)
*       assert.is_not_nil(result.buffer)

*       local bufnr = result.buffer:get_bufnr()
*       assert.is_not_nil(vim.b[bufnr].llm_chat_bufnr)
*       assert.are.equal(bufnr, vim.b[bufnr].llm_chat_bufnr)

*       local retrieved_chat_data = chat.get_session(bufnr)
*       assert.is_not_nil(retrieved_chat_data)
*       assert.are.equal(result.session, retrieved_chat_data.session)
*       assert.are.equal(result.buffer, retrieved_chat_data.buffer)
      end)

*     it('should send message from chat buffer', function()
        -- Mock get_user_input to return a message
*       _buffer.get_user_input = spy.new(function() return "Test message" end)
*       _buffer.set_status = spy.new(function() end)
*       _buffer.append_user_message = spy.new(function() end)
*       _buffer.clear_input = spy.new(function() end)
*       _buffer.append_llm_message = spy.new(function() end)
*       _buffer.update_conversation_id = spy.new(function() end)
*       _buffer.focus_input = spy.new(function() end)

*       chat.send_message()

*       assert.spy(_buffer.get_user_input).was.called()
*       assert.spy(_buffer.set_status).was.called_with(match._, "Processing...")
*       assert.spy(_buffer.append_user_message).was.called()
*       assert.spy(_buffer.clear_input).was.called()
      end)

*     it('should not send empty message', function()
*       _buffer.get_user_input = spy.new(function() return "" end)

*       chat.send_message()

*       assert.spy(vim.notify).was.called_with("Cannot send empty message", vim.log.levels.WARN)
      end)

*     it('should not send when session is processing', function()
*       _session.state = 'processing'

*       chat.send_message()

*       assert.spy(vim.notify).was.called_with("Chat is processing, please wait", vim.log.levels.WARN)
      end)

*     it('should handle new message command', function()
*       local result = chat.start_chat()
*       vim.b[1] = { llm_chat_session = result }

*       result.buffer.clear_input = spy.new(function() end)
*       result.buffer.focus_input = spy.new(function() end)

*       chat.new_message()

*       assert.spy(result.buffer.clear_input).was.called()
*       assert.spy(result.buffer.focus_input).was.called()
      end)

*     it('should get active session for buffer', function()
*       local result = chat.start_chat()

*       local session = chat.get_session(1)

*       assert.is_not_nil(session)
*       assert.are.equal(result.session, session.session)
*       assert.are.equal(result.buffer, session.buffer)
      end)

*     it('should stop current job', function()
*       local result = chat.start_chat()
*       vim.b[1] = { llm_chat_session = result }

*       result.session.current_job_id = 12345
*       result.session.stop_current_job = spy.new(function()
*         result.session.current_job_id = nil
*         result.session.state = 'ready'
        end)
*       result.buffer.set_status = spy.new(function() end)

*       chat.stop_current_job()

*       assert.spy(result.session.stop_current_job).was.called()
*       assert.spy(result.buffer.set_status).was.called_with(match._, "Stopped")
      end)
    end)

*   describe('error handling', function()
*     it('should handle send_message on non-chat buffer', function()
*       vim.b[1] = nil

*       chat.send_message()

*       assert.spy(vim.notify).was.called_with("Not a chat buffer", vim.log.levels.ERROR)
      end)

*     it('should handle new_message on non-chat buffer', function()
*       vim.b[1] = nil

*       chat.new_message()

*       assert.spy(vim.notify).was.called_with("Not a chat buffer", vim.log.levels.ERROR)
      end)

*     it('should handle stop_current_job on non-chat buffer', function()
*       vim.b[1] = nil

*       chat.stop_current_job()

*       assert.spy(vim.notify).was.called_with("Not a chat buffer", vim.log.levels.ERROR)
      end)
    end)
  end)

==============================================================================
tests/spec/llm_cli_spec.lua
==============================================================================
  -- tests/spec/core/data/llm_cli_spec.lua
* require('spec_helper')

* describe("llm.core.data.llm_cli", function()
    local llm_cli
    local shell

*   before_each(function()
      -- Create a mock for the shell module
*     shell = {
*       safe_shell_command = function() end,
*     }
*     package.loaded['llm.core.utils.shell'] = shell

      -- Reload the llm_cli module to use the mock
*     package.loaded['llm.core.data.llm_cli'] = nil
*     llm_cli = require('llm.core.data.llm_cli')
    end)

*   after_each(function()
      -- Restore original modules
*     package.loaded['llm.core.utils.shell'] = nil
*     package.loaded['llm.core.data.llm_cli'] = nil
    end)

*   it("should prepend 'llm ' to the command and call shell.safe_shell_command", function()
      -- Spy on the safe_shell_command function
*     local spy = spy.on(shell, "safe_shell_command")

      -- Call the function to be tested
*     local command = "models list"
*     llm_cli.run_llm_command(command)

      -- Assert that the spy was called with the correct argument
*     assert.spy(spy).was.called_with("llm " .. command)
    end)

*   it("should handle an empty command", function()
*     local spy = spy.on(shell, "safe_shell_command")
*     llm_cli.run_llm_command("")
*     assert.spy(spy).was.called_with("llm")
    end)

*   it("should handle a command with special characters", function()
*     local spy = spy.on(shell, "safe_shell_command")
*     local command = "prompt 'hello world'"
*     llm_cli.run_llm_command(command)
*     assert.spy(spy).was.called_with("llm " .. command)
    end)
  end)

==============================================================================
tests/spec/spec_helper.lua
==============================================================================
* require('mock_vim')
* require('mock_helper')

==============================================================================
tests/spec/config_spec.lua
==============================================================================
  -- tests/spec/config_spec.lua

* local spy = require('luassert.spy')

* describe('llm.config', function()
    local config

*   before_each(function()
      -- Mock the vim object
*     _G.vim = {
        tbl_deep_extend = function(_, ...)
*         local result = {}
*         for _, tbl in ipairs({...}) do
*           for k, v in pairs(tbl) do
*             result[k] = v
            end
          end
*         return result
        end,
*     }

      -- Reset the module to ensure a clean state for each test
*     package.loaded['llm.config'] = nil
*     config = require('llm.config')
    end)

*   after_each(function()
*     _G.vim = nil
    end)

*   describe('setup()', function()
*     it('should merge user options with defaults', function()
*       local user_opts = {
*         model = 'test-model',
*         debug = true,
        }
*       config.setup(user_opts)
*       assert.are.same('test-model', config.get('model'))
*       assert.are.same(true, config.get('debug'))
        -- Check a default value was not overwritten
*       assert.are.same('You are a helpful assistant.', config.get('system_prompt'))
      end)

*     it('should notify listeners on change', function()
*       local listener_spy = spy.new(function() end)
*       config.on_change(listener_spy)

*       local user_opts = { model = 'new-model' }
*       config.setup(user_opts)

*       assert.spy(listener_spy).was.called()
      end)
    end)

*   describe('get()', function()
*     it('should return the value for a single key', function()
*       config.setup({ model = 'get-test' })
*       assert.are.same('get-test', config.get('model'))
      end)

*     it('should return the default value if a key is not set', function()
*       assert.are.same(false, config.get('debug'))
      end)

*     it('should return a table of all values if no key is provided', function()
*       config.setup({ model = 'all-values-test', debug = true })
*       local all_opts = config.get()
*       assert.are.same('all-values-test', all_opts.model)
*       assert.are.same(true, all_opts.debug)
*       assert.are.same('You are a helpful assistant.', all_opts.system_prompt)
      end)
    end)

*   describe('reset()', function()
*     it('should restore the configuration to its default state', function()
*       config.setup({ model = 'reset-test', debug = true })
*       config.reset()
*       assert.are.same(nil, config.get('model'))
*       assert.are.same(false, config.get('debug'))
*       assert.are.same('You are a helpful assistant.', config.get('system_prompt'))
      end)
    end)
  end)

==============================================================================
tests/spec/facade_spec.lua
==============================================================================
  -- tests/spec/facade_spec.lua
* require('spec_helper')
* local spy = require('luassert.spy')
* local facade = require('llm.facade')

* describe('llm.facade', function()
    local facade
*   before_each(function()
      -- Reset the facade module to ensure isolation between tests
*     package.loaded['llm.facade'] = nil
*     facade = require('llm.facade')
    end)

*   after_each(function()
*     package.loaded['llm.facade'] = nil
    end)

*   describe('get_manager', function()
*     it('should return the correct manager instance for a valid name', function()
*       local models_manager_mock = {}
*       package.loaded['llm.managers.models_manager'] = models_manager_mock

*       local manager = facade.get_manager('models')
*       assert.are.same(models_manager_mock, manager)

*       package.loaded['llm.managers.models_manager'] = nil
      end)

*     it('should cache manager instances', function()
*       vim.env.NVIM_LLM_TEST = 'true'
        -- We need to reload the facade module to expose the test function
*       package.loaded['llm.facade'] = nil
*       facade = require('llm.facade')

*       local models_manager_mock = {}
*       package.loaded['llm.managers.models_manager'] = models_manager_mock

*       facade.get_manager('models')
*       local managers = facade._get_managers()
*       assert.are.same(models_manager_mock, managers.models)

        -- To verify caching, we'll check that the manager is already loaded
        -- without calling require again. We can't spy on require, so we'll
        -- just check that the object is the same.
*       local manager1 = facade.get_manager('models')
*       local manager2 = facade.get_manager('models')
*       assert.are.same(manager1, manager2)

*       package.loaded['llm.managers.models_manager'] = nil
*       vim.env.NVIM_LLM_TEST = nil
      end)

*     it('should return nil for an invalid manager name', function()
*       local manager = facade.get_manager('invalid_manager')
*       assert.is_nil(manager)
      end)
    end)

*   describe('command', function()
*     it('should call llm.commands.dispatch_command with the correct arguments', function()
*       local commands_mock = {
*         dispatch_command = spy.new(function() end),
        }
*       package.loaded['llm.commands'] = commands_mock

*       facade.command('test_subcmd', 'arg1', 'arg2')
*       assert.spy(commands_mock.dispatch_command).was.called_with('test_subcmd', 'arg1', 'arg2')

*       package.loaded['llm.commands'] = nil
      end)
    end)

*   describe('prompt functions', function()
      local commands_mock

*     before_each(function()
*       commands_mock = {
*         prompt = spy.new(function() end),
*         prompt_with_selection = spy.new(function() end),
*         prompt_with_current_file = spy.new(function() end),
*       }
*       package.loaded['llm.commands'] = commands_mock
      end)

*     after_each(function()
*       package.loaded['llm.commands'] = nil
      end)

*     it('should call llm.commands.prompt with the correct arguments', function()
*       facade.prompt('test_prompt', { 'frag1', 'frag2' })
*       assert.spy(commands_mock.prompt).was.called_with('test_prompt', { 'frag1', 'frag2' })
      end)

*     it('should call llm.commands.prompt_with_selection with the correct arguments', function()
*       facade.prompt_with_selection('test_prompt', { 'frag1', 'frag2' })
*       assert.spy(commands_mock.prompt_with_selection).was.called_with('test_prompt', { 'frag1', 'frag2' })
      end)

*     it('should call llm.commands.prompt_with_current_file with the correct arguments', function()
*       facade.prompt_with_current_file('test_prompt')
*       assert.spy(commands_mock.prompt_with_current_file).was.called_with('test_prompt')
      end)
    end)

*   describe('toggle_unified_manager', function()
*     it('should call unified_manager.toggle with the correct initial view', function()
*       local unified_manager_mock = {
*         toggle = spy.new(function() end),
        }
*       package.loaded['llm.ui.unified_manager'] = unified_manager_mock

*       facade.toggle_unified_manager('test_view')
*       assert.spy(unified_manager_mock.toggle).was.called_with('test_view')

*       package.loaded['llm.ui.unified_manager'] = nil
      end)
    end)
  end)

==============================================================================
tests/spec/scratch_buffer_save_spec.lua
==============================================================================
* require('spec_helper')

* describe('llm.commands', function()
    local commands
    local config_mock
    local job_mock

*   before_each(function()
*     config_mock = {
*       get = spy.new(function(key)
*         if key == 'model' then
*           return 'test-model'
          end
*         return nil
        end),
*     }
*     package.loaded['llm.config'] = config_mock

*     job_mock = {
*       run = spy.new(function() end),
*     }
*     package.loaded['llm.core.utils.job'] = job_mock

*     package.loaded['llm.commands'] = nil
*     commands = require('llm.commands')
    end)

*   after_each(function()
*     package.loaded['llm.config'] = nil
*     package.loaded['llm.core.utils.job'] = nil
    end)

*   it('should call llm with buffer content on BufWriteCmd', function()
*     local get_lines_spy = spy.new(function()
*         return { "Enter your prompt here and then save and close the buffer to continue.", "test prompt" }
      end)
*     _G.vim.api.nvim_buf_get_lines = get_lines_spy

*     local prompt_spy = spy.on(commands, 'prompt')

      -- To simulate the save, we need to get the callback from the autocmd
*     local create_autocmd_spy = spy.new(function(event, opts)
*         opts.callback()
      end)
*     _G.vim.api.nvim_create_autocmd = create_autocmd_spy

*     local ui_utils = require('llm.core.utils.ui')
*     ui_utils.create_prompt_buffer()

*     assert.spy(prompt_spy).was.called_with('test prompt')
    end)
  end)

==============================================================================
tests/spec/init_spec.lua
==============================================================================
* local spy = require('luassert.spy')

* describe('llm.init', function()
    local llm_init
    local config_mock
    local styles_mock
    local loaders_mock
    local shell_mock

*   before_each(function()
*     _G.vim = {
*       env = {},
*       fn = {
*         stdpath = function() return "/tmp" end,
*         json_encode = function(data) return "" end,
*         system = function() end,
*       },
*       log = {
*         levels = {
*           INFO = 1,
*           WARN = 2,
*           ERROR = 3,
*         },
*       },
*       notify = spy.new(function() end),
*       defer_fn = function(fn) fn() end,
*     }
*     package.loaded['llm.managers.plugins_manager'] = {
*         refresh_available_plugins = function() end,
*     }
*     package.loaded['llm.init'] = nil
*     package.loaded['llm.config'] = nil
*     package.loaded['llm.ui.styles'] = nil
*     package.loaded['llm.core.loaders'] = nil
*     package.loaded['llm.core.utils.shell'] = nil

*     config_mock = {
*       setup = spy.new(function() end),
*       get = spy.new(function(key)
*         if key == 'auto_update_cli' then
*           return false
          end
*         if key == 'auto_update_interval_days' then
*           return 7
          end
0         return nil
        end),
*     }

*     styles_mock = {
*       setup_highlights = spy.new(function() end),
*     }

*     loaders_mock = {
*       load_all = spy.new(function() end),
*     }

*     shell_mock = {
*       get_last_update_timestamp = spy.new(function() return 0 end),
*       update_llm_cli = spy.new(function() end),
*     }

*     package.loaded['llm.config'] = config_mock
*     package.loaded['llm.ui.styles'] = styles_mock
*     package.loaded['llm.core.loaders'] = loaders_mock
*     package.loaded['llm.core.utils.shell'] = shell_mock

*     llm_init = require('llm.init')
    end)

*   after_each(function()
*     package.loaded['llm.config'] = nil
*     package.loaded['llm.ui.styles'] = nil
*     package.loaded['llm.core.loaders'] = nil
*     package.loaded['llm.core.utils.shell'] = nil
    end)

*   it('should call config.setup with provided options', function()
*     local opts = { model = 'test-model' }
*     llm_init.setup(opts)
*     assert.spy(config_mock.setup).was.called_with(opts)
    end)

*   it('should call styles.setup_highlights', function()
*     llm_init.setup({})
*     assert.spy(styles_mock.setup_highlights).was.called()
    end)

*   it('should call loaders.load_all', function()
*     llm_init.setup({})
*     assert.spy(loaders_mock.load_all).was.called()
    end)

*   describe('auto-update', function()
*     it('should not check for updates if auto_update_cli is false', function()
*       config_mock.get = spy.new(function(key)
*         if key == 'auto_update_cli' then
*           return false
          end
*         return nil
        end)
*       llm_init.setup({})
*       assert.spy(shell_mock.get_last_update_timestamp).was.not_called()
      end)

*     it('should check for updates if auto_update_cli is true and interval has passed', function()
*       config_mock.get = spy.new(function(key)
*         if key == 'auto_update_cli' then
*           return true
          end
*         if key == 'auto_update_interval_days' then
*           return 7
          end
0         return nil
        end)
*       shell_mock.get_last_update_timestamp = spy.new(function() return os.time() - (8 * 24 * 60 * 60) end) -- 8 days ago
*       vim.defer_fn = function(fn) fn() end
*       shell_mock.update_llm_cli = spy.new(function() return { success = true } end)

*       llm_init.setup({})

*       assert.spy(shell_mock.get_last_update_timestamp).was.called()
*       assert.spy(shell_mock.update_llm_cli).was.called()
      end)

*     it('should not check for updates if auto_update_cli is true but interval has not passed', function()
*       config_mock.get = spy.new(function(key)
*         if key == 'auto_update_cli' then
*           return true
          end
*         if key == 'auto_update_interval_days' then
*           return 7
          end
0         return nil
        end)
*       shell_mock.get_last_update_timestamp = spy.new(function() return os.time() - (6 * 24 * 60 * 60) end) -- 6 days ago

*       llm_init.setup({})
*       assert.spy(shell_mock.get_last_update_timestamp).was.called()
*       assert.spy(shell_mock.update_llm_cli).was.not_called()
      end)
    end)
  end)

==============================================================================
tests/spec/mock_helper.lua
==============================================================================
* local M = {}

* function M.mock_io_open(filename_to_mock)
0   local old_open = io.open
    io.open = function(filename, ...)
0     if filename == filename_to_mock then
0       return { write = function() end, close = function() end }
      else
0       return old_open(filename, ...)
      end
    end

    return function()
0     io.open = old_open
    end
  end

* return M

==============================================================================
tests/spec/errors_spec.lua
==============================================================================
* local spy = require('luassert.spy')

* describe('llm.errors', function()
    local errors

*   before_each(function()
*     _G.vim = {
*       notify = spy.new(function() end),
        tbl_deep_extend = function(_, ...)
*         local result = {}
*         for i = 1, select('#', ...) do
*           local tbl = select(i, ...)
*           for k, v in pairs(tbl) do
*             result[k] = v
            end
          end
*         return result
        end,
*       log = {
*         levels = {
*           INFO = 1,
*           WARN = 2,
*           ERROR = 3,
*         },
*       },
*       inspect = function(v) return tostring(v) end,
*     }

*     package.loaded['llm.errors'] = nil
*     errors = require('llm.errors')
    end)

*   after_each(function()
*     package.loaded['llm.errors'] = nil
    end)

*   describe('handle', function()
*     it('should call vim.notify with a formatted message', function()
*       local notify_spy = spy.new(function() end)
*       errors.handle('category', 'message', nil, errors.levels.ERROR, notify_spy)
*       assert.spy(notify_spy).was.called()
      end)
    end)

*   describe('wrap', function()
*     it('should return the function result on success', function()
        local func = function()
*         return 'success'
        end
*       local wrapped = errors.wrap(func)
*       local result = wrapped()
*       assert.are.equal('success', result)
      end)

*     it('should call handle on failure', function()
*       local error_message = 'test error'
        local func = function()
*         error(error_message)
        end
*       local handle_spy = spy.on(errors, 'handle')
*       local wrapped = errors.wrap(func, 'Test Function')
*       wrapped()
*       assert.spy(handle_spy).was.called()
*       handle_spy:revert()
      end)
    end)

*   describe('shell_error', function()
*     it('should call handle with a formatted shell error message', function()
*       local handle_spy = spy.on(errors, 'handle')
*       local command = 'ls -l'
*       local code = 1
*       local stdout = 'stdout'
*       local stderr = 'stderr'
*       errors.shell_error(command, code, stdout, stderr)
*       assert.spy(handle_spy).was.called()
*       handle_spy:revert()
      end)
    end)
  end)

==============================================================================
tests/spec/commands_spec.lua
==============================================================================
* require('spec_helper')

* describe('llm.commands', function() -- This is a new test suite for llm.commands
    local commands
    local api_mock
    local ui_mock

*   before_each(function()
      -- Mock the llm.api module
*     api_mock = {
*       run_streaming_command = spy.new(function(cmd_parts, prompt, callbacks)
*         api_mock.run_streaming_command.calls = { { cmd_parts, prompt, callbacks } }
        end),
*     }
*     package.loaded['llm.api'] = api_mock

      -- Mock the llm.core.utils.ui module
*     ui_mock = {
*       append_to_buffer = spy.new(function() end), -- Mock the append_to_buffer function
*     }
*     package.loaded['llm.core.utils.ui'] = ui_mock

      -- Mock the llm.config module
*     package.loaded['llm.config'] = {
*       get = spy.new(function(key)
*         if key == 'llm_executable_path' then
*           return '/usr/bin/llm'
*         elseif key == 'model' then
*           return 'test-model'
*         elseif key == 'system_prompt' then
*           return 'test-system-prompt'
          end
0         return nil
        end),
*     }

      -- Mock the llm.core.utils.text module
*     local text_mock = { get_visual_selection = spy.new(function() return 'selected text' end) }
*     package.loaded['llm.core.utils.text'] = text_mock

      -- Clear the commands module from package.loaded to ensure a fresh load
*     package.loaded['llm.commands'] = nil
*     commands = require('llm.commands')
    end)

*   after_each(function()
      -- Clean up mocks after each test
*     package.loaded['llm.api'] = nil
*     package.loaded['llm.core.utils.ui'] = nil
    end)

*   describe('prompt', function()
*     it('should call api.run_streaming_command with the correct arguments', function()
*       commands.prompt('test prompt', {}, 1)

*       assert.spy(api_mock.run_streaming_command).was.called()
*       local call_args = api_mock.run_streaming_command.calls[1]
*       assert.same({ '/usr/bin/llm', '-m', 'test-model', '-s', 'test-system-prompt' }, call_args[1])
*       assert.are.equal('test prompt', call_args[2])
      end)

*     it('should append data to the buffer on stdout', function()
*       commands.prompt('test prompt', {}, 1)

*       local call_args = api_mock.run_streaming_command.calls[1]
*       local callbacks = call_args[3]
*       callbacks.on_stdout(nil, { 'test output' })

*       assert.spy(ui_mock.append_to_buffer).was.called_with(1, 'test output\n', 'LlmModelResponse')
      end)
    end)

*   describe('prompt_with_current_file', function()
*     it('should call api.run_streaming_command with the correct arguments', function()
        -- Mock vim.fn.expand to return a dummy file path
*       vim.fn.expand = spy.new(function() return '/path/to/file.lua' end)

*       commands.prompt_with_current_file('test prompt', {}, 1)

*       assert.spy(api_mock.run_streaming_command).was.called()
*       local call_args = api_mock.run_streaming_command.calls[1]
*       assert.same({ '/usr/bin/llm', '-m', 'test-model', '-s', 'test-system-prompt', '-f', '/path/to/file.lua' }, call_args[1])
*       assert.are.equal('test prompt', call_args[2])
      end)

*     it('should append data to the buffer on stdout', function()
        -- Mock vim.fn.expand to return a dummy file path
*       vim.fn.expand = spy.new(function() return '/path/to/file.lua' end)

*       commands.prompt_with_current_file('test prompt', {}, 1)

*       local call_args = api_mock.run_streaming_command.calls[1]
*       local callbacks = call_args[3]
*       callbacks.on_stdout(nil, { 'test output' })

*       assert.spy(ui_mock.append_to_buffer).was.called_with(1, 'test output\n', 'LlmModelResponse')
      end)
    end)

*   describe('prompt_with_selection', function()
*     it('should call api.run_streaming_command with the correct arguments', function()
        -- Mock dependencies
*       commands.write_context_to_temp_file = spy.new(function() return '/tmp/temp_file' end)
*       os.remove = spy.new(function() end)

*       commands.prompt_with_selection('test prompt', {}, true, 1)

*       assert.spy(api_mock.run_streaming_command).was.called()
*       local call_args = api_mock.run_streaming_command.calls[1]
*       assert.same({ '/usr/bin/llm', '-m', 'test-model', '-s', 'test-system-prompt', '-f', '/tmp/temp_file' }, call_args[1])
*       assert.are.equal('test prompt', call_args[2])

        -- Test on_exit callback
*       local callbacks = call_args[3]
*       callbacks.on_exit()
*       assert.spy(os.remove).was.called_with('/tmp/temp_file')
      end)
    end)
  end)

==============================================================================
tests/spec/mock_llm_cli.lua
==============================================================================
* local M = {}

* function M.get_llm_executable_path()
*     return "/usr/bin/llm"
  end

* function M.run_llm_command(command)
0     if command == 'schemas list --json' then
0         return '[]'
      end
0     return ''
  end

* return M

==============================================================================
tests/spec/api_spec.lua
==============================================================================

* describe("api", function()
    local api
    local job_mock

*   before_each(function()
*     package.loaded["llm.api"] = nil
*     package.loaded["llm.core.utils.job"] = nil
*     require("spec_helper")

*     job_mock = {
*       run = spy.new(function() end),
*     }
*     package.loaded["llm.core.utils.job"] = job_mock

*     api = require("llm.api")
    end)

*   describe("run_streaming_command", function()
*     it("should call job.run with the correct command and callbacks", function()
        -- Arrange
*       local command_parts = { "llm", "prompt", "hello" }
*       local callbacks = {
*         on_stdout = function() end,
*         on_stderr = function() end,
*         on_exit = function() end,
        }
*       job_mock.run = spy.new(function() return 123 end)

        -- Act
*       local result = api.run_streaming_command(command_parts, "test prompt", callbacks)

        -- Assert
*       assert.spy(job_mock.run).was.called_with(command_parts, callbacks)
*       assert.are.equal(result, 123)
      end)

*     it("should call jobsend and jobclose when a prompt is provided", function()
        -- Arrange
*       local command_parts = { "llm", "prompt", "hello" }
*       local callbacks = {}
*       job_mock.run = spy.new(function() return 123 end)
*       local jobsend_spy = spy.on(vim.fn, "jobsend")
*       jobsend_spy.revert = function() end
*       local jobclose_spy = spy.on(vim.fn, "jobclose")
*       jobclose_spy.revert = function() end

        -- Act
*       api.run_streaming_command(command_parts, "test prompt", callbacks)

        -- Assert
*       assert.spy(jobsend_spy).was.called_with(123, "test prompt")
*       assert.spy(jobclose_spy).was.called_with(123, "stdin")
      end)

*     it("should not call jobsend when prompt is nil or empty", function()
        -- Arrange
*       local command_parts = { "llm", "prompt", "hello" }
*       local callbacks = {}
*       job_mock.run = spy.new(function() return 123 end)
*       local jobsend_spy = spy.on(vim.fn, "jobsend")
*       jobsend_spy.revert = function() end

        -- Act
*       api.run_streaming_command(command_parts, nil, callbacks)
*       api.run_streaming_command(command_parts, "", callbacks)

        -- Assert
*       assert.spy(jobsend_spy).was.not_called()
      end)
    end)
  end)

==============================================================================
tests/spec/file_utils_spec.lua
==============================================================================
* require('tests.spec.spec_helper')

* describe('llm.core.utils.file_utils', function()
    local file_utils

*   before_each(function()
*     package.loaded['llm.core.utils.file_utils'] = nil
*     file_utils = require('llm.core.utils.file_utils')
    end)

*   describe('ensure_config_dir_exists()', function()
*     it('should return true if directory is writable', function()
*       local was_called = false
*       file_utils._test_directory_writable = function(dir)
*         was_called = true
*         assert.are.equal('/tmp/llm-nvim', dir)
*         return true
        end

*       assert.is_true(file_utils.ensure_config_dir_exists('/tmp/llm-nvim'))
*       assert.is_true(was_called)
      end)

*     it('should create directory if not writable', function()
*       local was_called_test = false
*       local was_called_create = false
*       file_utils._test_directory_writable = function(dir)
*         was_called_test = true
*         return false
        end
*       file_utils._create_directory = function(dir)
*         was_called_create = true
*         assert.are.equal('/tmp/llm-nvim', dir)
*         return true
        end

*       assert.is_true(file_utils.ensure_config_dir_exists('/tmp/llm-nvim'))
*       assert.is_true(was_called_test)
*       assert.is_true(was_called_create)
      end)

*     it('should return false if directory creation fails', function()
*       file_utils._test_directory_writable = function() return false end
*       file_utils._create_directory = function() return false end
*       assert.is_false(file_utils.ensure_config_dir_exists('/tmp/llm-nvim'))
      end)
    end)

*   describe('get_config_path()', function()
      local mock_shell

*     before_each(function()
*       mock_shell = {
*         safe_shell_command = function() end
*       }
*       file_utils.set_shell(mock_shell)
*       file_utils.config_dir_cache = nil
      end)

*     it('should resolve and cache the config path', function()
*       local shell_calls = 0
*       mock_shell.safe_shell_command = function(cmd)
*         shell_calls = shell_calls + 1
*         if cmd == 'llm logs path' then
*           return '/home/user/.logs/llm'
*         elseif cmd == "dirname '/home/user/.logs/llm'" then
*           return '/home/user/.logs'
          end
        end

*       file_utils.ensure_config_dir_exists = function() return true end

*       local config_dir, path = file_utils.get_config_path('test.json')
*       assert.are.equal('/home/user/.logs', config_dir)
*       assert.are.equal('/home/user/.logs/test.json', path)
*       assert.are.equal(2, shell_calls)

        -- Call again to test caching
*       file_utils.get_config_path('test.json')
*       assert.are.equal(2, shell_calls) -- No new calls
      end)

*     it('should return nil if filename is not provided', function()
*       local config_dir, path = file_utils.get_config_path(nil)
*       assert.is_nil(config_dir)
*       assert.is_nil(path)
      end)

*     it('should return nil if llm logs path fails', function()
*       mock_shell.safe_shell_command = function() return nil end
*       local config_dir, path = file_utils.get_config_path('test.json')
*       assert.is_nil(config_dir)
*       assert.is_nil(path)
      end)

*     it('should return nil if ensure_config_dir_exists fails', function()
*       mock_shell.safe_shell_command = function() return '/home/user/.logs/llm' end
*       file_utils.ensure_config_dir_exists = function() return false end
*       local config_dir, path = file_utils.get_config_path('test.json')
*       assert.is_nil(config_dir)
*       assert.is_nil(path)
      end)
    end)
  end)

==============================================================================
tests/spec/notify_spec.lua
==============================================================================
* require('tests.spec.spec_helper')

* local spy = require('luassert.spy')

* describe('llm.core.utils.notify', function()
    local notify

*   before_each(function()
*     package.loaded['llm.core.utils.notify'] = nil
*     notify = require('llm.core.utils.notify')
    end)

*   it('should call vim.notify with the correct arguments', function()
*     spy.on(vim, 'notify')
*     notify.notify('test message', vim.log.levels.INFO, { title = 'Test' })
*     assert.spy(vim.notify).was.called_with('test message', vim.log.levels.INFO, { title = 'Test' })
    end)

*   it('should call vim.notify with an empty table if opts is nil', function()
*     spy.on(vim, 'notify')
*     notify.notify('test message', vim.log.levels.INFO)
*     assert.spy(vim.notify).was.called_with('test message', vim.log.levels.INFO, {})
    end)
  end)

==============================================================================
tests/spec/managers/models_manager_spec.lua
==============================================================================
  -- tests/spec/managers/models_manager_spec.lua
* require('spec_helper')
* local models_manager = require('llm.managers.models_manager')
* local llm_cli = require('llm.core.data.llm_cli')
* local cache = require('llm.core.data.cache')
* local models_io = require('llm.managers.models_io')

* describe('models_manager', function()
*   describe('get_available_models', function()
*     it('should parse the output from llm-cli correctly', function()
        -- Mock the llm_cli.run_llm_command function
*       llm_cli.run_llm_command = function()
*         return 'gpt-4\ngpt-3.5-turbo'
        end

*       local models = models_manager.get_available_models()

        -- Assert that the models are parsed correctly
*       local expected_models = {
*         { provider = 'Other', id = 'gpt-4', name = 'gpt-4' },
*         { provider = 'Other', id = 'gpt-3.5-turbo', name = 'gpt-3.5-turbo' },
*       }
*       assert.are.same(expected_models, models)
      end)

*     it('should cache the models', function()
        -- Mock the llm_cli.run_llm_command and cache.get/cache.set functions
*       local llm_cli_call_count = 0
*       llm_cli.run_llm_command = function()
*         llm_cli_call_count = llm_cli_call_count + 1
*         return 'gpt-4\ngpt-3.5-turbo'
        end

*       local cache_data = nil
*       cache.get = function()
*         return cache_data
        end
*       cache.set = function(key, value)
*         cache_data = value
        end

        -- Call get_available_models twice
*       models_manager.get_available_models()
*       models_manager.get_available_models()

        -- Assert that llm_cli.run_llm_command was only called once
*       assert.are.equal(1, llm_cli_call_count)
      end)
    end)

*   describe('is_model_available', function()
*     it('should return true for an available model', function()
        -- Mock get_available_providers to return a table indicating that the provider is available
*       local original_get_available_providers = models_manager.get_available_providers
*       models_manager.get_available_providers = function()
*         return {
*           OpenAI = true,
*         }
        end

*       local result = models_manager.is_model_available('OpenAI Chat: gpt-4')
*       assert.is_true(result)

        -- Restore the original function
*       models_manager.get_available_providers = original_get_available_providers
      end)

*     it('should return false for an unavailable model', function()
        -- Mock get_available_providers to return a table indicating that the provider is not available
*       local original_get_available_providers = models_manager.get_available_providers
*       models_manager.get_available_providers = function()
*         return {
*           OpenAI = false,
*         }
        end

*       local result = models_manager.is_model_available('OpenAI Chat: gpt-4')
*       assert.is_false(result)

        -- Restore the original function
*       models_manager.get_available_providers = original_get_available_providers
      end)
    end)

*   describe('delegation to models_io', function()
*     it('should call set_default_model_in_cli in models_io', function()
        -- Mock the models_io.set_default_model_in_cli function
        local models_io_call_args
*       models_io.set_default_model_in_cli = function(model_name)
*         models_io_call_args = { model_name = model_name }
*         return true
        end

*       models_manager.set_default_model('gpt-4')
*       assert.are.same({ model_name = 'gpt-4' }, models_io_call_args)
      end)

*     it('should call set_alias_in_cli in models_io', function()
        -- Mock the models_io.set_alias_in_cli function
        local models_io_call_args
*       models_io.set_alias_in_cli = function(alias, model)
*         models_io_call_args = { alias = alias, model = model }
*         return true
        end

*       models_manager.set_model_alias('my-alias', 'gpt-4')
*       assert.are.same({ alias = 'my-alias', model = 'gpt-4' }, models_io_call_args)
      end)

*     it('should call remove_alias_in_cli in models_io', function()
        -- Mock the models_io.remove_alias_in_cli function
        local models_io_call_args
*       models_io.remove_alias_in_cli = function(alias)
*         models_io_call_args = { alias = alias }
*         return true
        end

*       models_manager.remove_model_alias('my-alias')
*       assert.are.same({ alias = 'my-alias' }, models_io_call_args)
      end)
    end)
  end)

==============================================================================
tests/spec/managers/schemas_manager_spec.lua
==============================================================================
* require('spec_helper')

* describe('llm.managers.schemas_manager', function()
    local schemas_manager
    local llm_cli
    local cache

*   before_each(function()
*     vim.fn = {
*       tempname = function() return '/tmp/test' end,
*       stdpath = function() return '/tmp' end,
*       json_decode = function(s) if s == '[]' then return {} else return { s } end end,
*       json_encode = function() return '' end
*     }
*     llm_cli = {
*       run_llm_command = spy.new(function() return '[]' end),
*       get_llm_executable_path = function() return 'llm' end
*     }
*     package.loaded['llm.core.data.llm_cli'] = llm_cli

*     cache = {
*       get = spy.new(function() return nil end),
*       set = spy.new(function() end),
*       invalidate = spy.new(function() end)
*     }
*     package.loaded['llm.core.data.cache'] = cache

*     package.loaded['llm.managers.schemas_manager'] = nil
*     schemas_manager = require('llm.managers.schemas_manager')
    end)

*   describe('get_schemas()', function()
*     it('should call llm_cli.run_llm_command with "schemas list --json" on cache miss', function()
*       schemas_manager.get_schemas()
*       assert.spy(cache.get).was.called_with('schemas')
*       assert.spy(llm_cli.run_llm_command).was.called_with('schemas list --json')
*       assert.spy(cache.set).was.called()
      end)

*     it('should return cached schemas on cache hit', function()
*       cache.get = spy.new(function(key)
*         if key == 'schemas' then
*           return { { id = 'cached_schema' } }
          end
        end)
*       schemas_manager.get_schemas()
*       assert.spy(cache.get).was.called_with('schemas')
*       assert.spy(llm_cli.run_llm_command).was.not_called()
      end)
    end)

*   describe('get_schema()', function()
*     it('should call llm_cli.run_llm_command with "schemas get <id> --json"', function()
*       schemas_manager.get_schema('test_id')
*       assert.spy(llm_cli.run_llm_command).was.called_with('schemas get test_id --json')
      end)
    end)

*   describe('save_schema()', function()
      local old_io_open, old_os_remove
*     before_each(function()
*       old_io_open = io.open
*       old_os_remove = os.remove
      end)
*     after_each(function()
*       io.open = old_io_open
*       os.remove = old_os_remove
      end)

*     it('should return the correct command string in test mode', function()
*       local command = schemas_manager.save_schema('test_schema', '{"type": "string"}', true)
*       assert.are.equal('schemas save test_schema /tmp/test', command)
      end)

*     it('should write to a temp file and call llm-cli', function()
*       local file_mock = {
*         write = spy.new(),
*         close = spy.new(),
*       }
*       io.open = spy.new(function()
*         return file_mock
        end)
*       os.remove = spy.new()

*       schemas_manager.save_schema('test_schema', '{"type": "string"}')
*       assert.spy(io.open).was.called_with('/tmp/test', 'w')
*       assert.spy(file_mock.write).was.called_with(file_mock, '{"type": "string"}')
*       assert.spy(file_mock.close).was.called_with(file_mock)
*       assert.spy(llm_cli.run_llm_command).was.called_with('schemas save test_schema /tmp/test')
*       assert.spy(os.remove).was.called_with('/tmp/test')
*       assert.spy(cache.invalidate).was.called_with('schemas')
      end)
    end)

*   describe('run_schema()', function()
      local old_io_open
      local old_llm_api
      local api_mock

*     before_each(function()
*       old_io_open = io.open
*       old_llm_api = package.loaded['llm.api']
*       api_mock = { run_llm_command_streamed = spy.new() }
*       package.loaded['llm.api'] = api_mock
*       package.loaded['llm.managers.schemas_manager'] = nil
*       schemas_manager = require('llm.managers.schemas_manager')
      end)

*     after_each(function()
*       io.open = old_io_open
*       package.loaded['llm.api'] = old_llm_api
      end)

*     it('should return the correct command string for a regular schema in test mode', function()
*       local command = schemas_manager.run_schema('test_schema', 'input', false, nil, true)
*       assert.are.equal('schema test_schema /tmp/test', command)
      end)

*     it('should return the correct command string for a multi schema in test mode', function()
*       local command = schemas_manager.run_schema('test_schema', 'input', true, nil, true)
*       assert.are.equal('schema test_schema /tmp/test --multi', command)
      end)

*     it('should write to a temp file and call streaming api', function()
*       local file_mock = {
*         write = spy.new(),
*         close = spy.new(),
*       }
*       io.open = spy.new(function()
*         return file_mock
        end)

*       schemas_manager.run_schema('test_schema', 'my_input', false, 123)
*       assert.spy(io.open).was.called_with('/tmp/test', 'w')
*       assert.spy(file_mock.write).was.called_with(file_mock, 'my_input')
*       assert.spy(file_mock.close).was.called_with(file_mock)
*       assert.spy(api_mock.run_llm_command_streamed).was.called()
      end)
    end)

*   describe('UI helper functions', function()
*     it('should categorize schemas correctly', function()
*       local all_schemas = {
*         { id = 'schema1', name = 'Schema A' },
*         { id = 'schema2' },
*         { id = 'schema3', name = 'Schema C' },
*         { id = 'schema4', name = 'Schema B' },
*       }
*       local named, unnamed = schemas_manager.categorize_schemas(all_schemas)
*       assert.are.same({
*         { id = 'schema1', name = 'Schema A' },
*         { id = 'schema4', name = 'Schema B' },
*         { id = 'schema3', name = 'Schema C' },
*       }, named)
*       assert.are.same({
*         { id = 'schema2' },
*       }, unnamed)
      end)

*     it('should build buffer lines correctly', function()
*         local schemas = {
*             { id = 'schema1', name = 'Schema A', description = 'Description A' },
*             { id = 'schema2', description = 'Description B' },
*         }
*         schemas_manager.get_schema = function(id)
*             if id == 'schema1' or id == 'schema2' then
*                 return { content = '{"type": "string"}' }
              end
*             return nil
          end

*         local lines = schemas_manager.build_buffer_lines(schemas, true)
*         assert.are.equal('# Schema Management', lines[1])
*         assert.are.equal('Showing: Only named schemas', lines[7])
*         assert.are.equal('Schema 1: schema1', lines[11])
*         assert.are.equal('  Name: Schema A', lines[12])
*         assert.are.equal('  Status: Valid', lines[13])
*         assert.are.equal('  Description: Description A', lines[14])
      end)

*     it('should build schema data correctly', function()
*         local schemas = {
*             { id = 'schema1', name = 'Schema A', description = 'Description A' },
*         }
*         schemas_manager.get_schema = function(id)
*             if id == 'schema1' then
*                 return { content = '{"type": "string"}' }
              end
*             return nil
          end

*         local schema_data, line_to_schema = schemas_manager.build_schema_data(schemas, 11)
*         assert.is_not_nil(schema_data['schema1'])
*         assert.are.equal('Schema A', schema_data['schema1'].name)
*         assert.are.equal(11, schema_data['schema1'].start_line)
*         assert.are.equal('schema1', line_to_schema[11])
*         assert.are.equal('schema1', line_to_schema[12])
*         assert.are.equal('schema1', line_to_schema[13])
*         assert.are.equal('schema1', line_to_schema[14])
      end)
    end)
  end)

==============================================================================
tests/spec/managers/keys_manager_spec.lua
==============================================================================
  -- tests/spec/managers/keys_manager_spec.lua
* require('spec_helper')
* local mock = require('luassert.mock')
* local stub = require('luassert.stub')

* local llm_cli = require('llm.core.data.llm_cli')
* local KeysManager = require('llm.managers.keys_manager')
* local cache = require('llm.core.data.cache')
* local config = require('llm.config')

* describe('llm.managers.keys_manager', function()
*   before_each(function()
*     stub(cache, 'get')
*     stub(cache, 'set')
*     stub(cache, 'invalidate')
*     stub(config, 'get')
    end)

*   after_each(function()
*     mock.revert(cache)
*     mock.revert(config)
    end)

*   describe('get_stored_keys', function()
*     it('should return a table of keys', function()
*       local keys = KeysManager.get_stored_keys()
*       assert.is_table(keys)
      end)
    end)

*   describe('is_key_set', function()
*     it('should return true if the key is in the list of stored keys', function()
*         stub(KeysManager, 'get_stored_keys', function()
*             return { { name = 'openai', is_set = true } }
          end)
*         assert.is_true(KeysManager.is_key_set('openai'))
*         mock.revert(KeysManager)
      end)

*     it('should return false if the key is not in the list', function()
*         stub(KeysManager, 'get_stored_keys', function()
*             return {}
          end)
*         assert.is_false(KeysManager.is_key_set('anthropic'))
*         mock.revert(KeysManager)
      end)
    end)

*   describe('set_api_key', function()
*     it('should call `llm_cli.run_llm_command` with `\'keys set <key_name> <key_value>\'`', function()
*       local llm_cli_spy = spy.on(llm_cli, 'run_llm_command')
*       KeysManager.set_api_key('openai', 'sk-12345')
*       assert.spy(llm_cli_spy).was_called_with('keys set openai sk-12345')
*       llm_cli_spy:revert()
      end)
    end)

*   describe('remove_api_key', function()
*     it('should call `llm_cli.run_llm_command` with `\'keys remove <key_name>\'`', function()
*       local llm_cli_spy = spy.on(llm_cli, 'run_llm_command')
*       KeysManager.remove_api_key('openai')
*       assert.spy(llm_cli_spy).was_called_with('keys remove openai')
*       llm_cli_spy:revert()
      end)
    end)
  end)

==============================================================================
tests/spec/managers/custom_openai_spec.lua
==============================================================================
  -- tests/spec/managers/custom_openai_spec.lua

* require("spec_helper")

* describe("llm.managers.custom_openai", function()
    local custom_openai
    local file_utils
    local text_utils
    local keys_manager
    local config

*   before_each(function()
*     _G.io_open = io.open
*     package.loaded["llm.managers.custom_openai"] = nil
*     package.loaded["llm.core.utils.file_utils"] = nil
*     package.loaded["llm.core.utils.text"] = nil
*     package.loaded["llm.managers.keys_manager"] = nil
*     package.loaded["llm.config"] = nil

      -- Mock config
*     package.loaded["llm.config"] = {
*       get = function() return false end
*     }
*     config = package.loaded["llm.config"]

*     file_utils = require("llm.core.utils.file_utils")
*     text_utils = require("llm.core.utils.text")
*     keys_manager = require("llm.managers.keys_manager")
*     custom_openai = require("llm.managers.custom_openai")
    end)

*   after_each(function()
*     package.loaded["llm.managers.custom_openai"] = nil
*     package.loaded["llm.core.utils.file_utils"] = nil
*     package.loaded["llm.core.utils.text"] = nil
*     package.loaded["llm.managers.keys_manager"] = nil
*     io.open = _G.io_open
    end)

*   describe("load_custom_openai_models()", function()
*     before_each(function()
*       local template_file = io.open("tests/templates/extra-openai-models.yaml.template", "r")
*       local content = template_file:read("*a")
*       template_file:close()
*       local temp_file = io.open("tests/spec/extra-openai-models.yaml", "w")
*       temp_file:write(content)
*       temp_file:close()
      end)

*     after_each(function()
*       os.remove("tests/spec/extra-openai-models.yaml")
      end)

*     it("should load models from a valid YAML file", function()
        -- Mock dependencies
*       file_utils.get_config_path = function() return "tests/spec", "tests/spec/extra-openai-models.yaml" end
*       text_utils.parse_simple_yaml = function()
*         return {
*           { model_id = "test-model-1", model_name = "Test Model 1", needs_auth = true, api_key_name = "test_key_1" },
*           { model_id = "test-model-2", model_name = "Test Model 2", needs_auth = false }
*         }
        end
*       keys_manager.is_key_set = function(key)
*         return key == "test_key_1"
        end

        -- Call the function
*       local models = custom_openai.load_custom_openai_models()

        -- Assertions
*       assert.is_not_nil(models["test-model-1"])
*       assert.are.equal("Test Model 1", models["test-model-1"].model_name)
*       assert.is_true(models["test-model-1"].is_valid)

*       assert.is_not_nil(models["test-model-2"])
*       assert.are.equal("Test Model 2", models["test-model-2"].model_name)
*       assert.is_true(models["test-model-2"].is_valid)
      end)

*     it("should handle a missing or empty YAML file", function()
        -- Mock dependencies
*       file_utils.get_config_path = function() return nil, "/fake/path/extra-openai-models.yaml" end
*       io.open = function() return nil end

        -- Call the function
*       local models = custom_openai.load_custom_openai_models()

        -- Assertions
*       assert.is_true(vim.tbl_isempty(models))
      end)

*     it("should handle an invalid YAML file", function()
        -- Mock dependencies
*       file_utils.get_config_path = function() return "tests/spec", "tests/spec/extra-openai-models.yaml" end
*       local temp_file = io.open("tests/spec/extra-openai-models.yaml", "w")
*       temp_file:write("invalid: yaml:")
*       temp_file:close()
*       text_utils.parse_simple_yaml = function() return nil end
*       os.rename = function() end

        -- Call the function
*       local models = custom_openai.load_custom_openai_models()

        -- Assertions
*       assert.is_true(vim.tbl_isempty(models))
      end)
    end)

*   describe("is_custom_openai_model_valid()", function()
*     it("should return true for a valid model with an API key", function()
        -- Mock dependencies
*       keys_manager.is_key_set = function() return true end

        -- Call the function
*       local is_valid = custom_openai.is_custom_openai_model_valid({
*         needs_auth = true,
*         api_key_name = "test_key"
        })

        -- Assertions
*       assert.is_true(is_valid)
      end)

*     it("should return false for a valid model without an API key", function()
        -- Mock dependencies
*       keys_manager.is_key_set = function() return false end

        -- Call the function
*       local is_valid = custom_openai.is_custom_openai_model_valid({
*         needs_auth = true,
*         api_key_name = "test_key"
        })

        -- Assertions
*       assert.is_false(is_valid)
      end)

*     it("should return true for a model that does not require auth", function()
        -- Call the function
*       local is_valid = custom_openai.is_custom_openai_model_valid({
*         needs_auth = false
        })

        -- Assertions
*       assert.is_true(is_valid)
      end)
    end)
  end)

==============================================================================
tests/spec/managers/fragments_manager_spec.lua
==============================================================================
* require('spec_helper')
* local fragments_manager = require('llm.managers.fragments_manager')
* local llm_cli = require('llm.core.data.llm_cli')
* local cache = require('llm.core.data.cache')
* local fragments_view = require('llm.ui.views.fragments_view')
* local unified_manager = require('llm.ui.unified_manager')

* describe('fragments_manager', function()
*   describe('get_fragments', function()
      local cache_data
*     before_each(function()
*       cache_data = nil
*       cache.get = function()
*         return cache_data
        end
*       cache.set = function(key, value)
*         cache_data = value
        end
      end)

*     it('should return a table of fragments', function()
*       local fragments = fragments_manager.get_fragments()
*       assert.is_table(fragments)
      end)

*     it('should cache the fragments', function()
        -- Mock the llm_cli.run_llm_command
*       local llm_cli_call_count = 0
*       llm_cli.run_llm_command = function()
*         llm_cli_call_count = llm_cli_call_count + 1
*         return '[]'
        end

        -- Call get_fragments twice
*       fragments_manager.get_fragments()
*       fragments_manager.get_fragments()

        -- Assert that llm_cli.run_llm_command was only called once
*       assert.are.equal(1, llm_cli_call_count)
      end)
    end)

*   describe('set_alias_for_fragment_under_cursor', function()
*     it('should call llm_cli.run_llm_command with the correct arguments', function()
        -- Mock the necessary functions
*       fragments_manager.get_fragment_info_under_cursor = function()
*         return '123', {}
        end
*       fragments_view.get_alias = function(callback)
*         callback('my-alias')
        end
*       local llm_cli_spy = spy.new(function()
*         return true
        end)
*       llm_cli.run_llm_command = llm_cli_spy
*       unified_manager.switch_view = function() end

        -- Call the function to be tested
*       fragments_manager.set_alias_for_fragment_under_cursor(0)

        -- Assert that llm_cli.run_llm_command was called with the correct arguments
*       assert.spy(llm_cli_spy).was.called_with('fragments alias set 123 my-alias')
      end)
    end)

*   describe('remove_alias_from_fragment_under_cursor', function()
*     it('should call llm_cli.run_llm_command with the correct arguments', function()
        -- Mock the necessary functions
*       fragments_manager.get_fragment_info_under_cursor = function()
*         return '123', { aliases = { 'my-alias' } }
        end
*       fragments_view.confirm_remove_alias = function(alias, callback)
*         callback(true)
        end
*       local llm_cli_spy = spy.new(function()
*         return true
        end)
*       llm_cli.run_llm_command = llm_cli_spy
*       unified_manager.switch_view = function() end

        -- Call the function to be tested
*       fragments_manager.remove_alias_from_fragment_under_cursor(0)

        -- Assert that llm_cli.run_llm_command was called with the correct arguments
*       assert.spy(llm_cli_spy).was.called_with('fragments alias remove my-alias')
      end)
    end)

*   describe('add_file_fragment', function()
*     it('should call llm_cli.run_llm_command with the correct arguments', function()
        -- Mock the necessary functions
*       fragments_view.select_file = function(callback)
*         callback('/path/to/file.txt')
        end
*       local llm_cli_spy = spy.new(function()
*         return true
        end)
*       llm_cli.run_llm_command = llm_cli_spy
*       unified_manager.switch_view = function() end

        -- Call the function to be tested
*       fragments_manager.add_file_fragment(0)

        -- Assert that llm_cli.run_llm_command was called with the correct arguments
*       assert.spy(llm_cli_spy).was.called_with('fragments store /path/to/file.txt')
      end)
    end)

*   describe('add_github_fragment_from_manager', function()
*     it('should call llm_cli.run_llm_command with the correct arguments', function()
        -- Mock the necessary functions
*       fragments_view.get_github_url = function(callback)
*         callback('https://github.com/user/repo/blob/main/file.txt')
        end
*       local llm_cli_spy = spy.new(function()
*         return true
        end)
*       llm_cli.run_llm_command = llm_cli_spy
*       unified_manager.switch_view = function() end

        -- Call the function to be tested
*       fragments_manager.add_github_fragment_from_manager(0)

        -- Assert that llm_cli.run_llm_command was called with the correct arguments
*       assert.spy(llm_cli_spy).was.called_with('fragments store https://github.com/user/repo/blob/main/file.txt')
      end)
    end)
  end)

==============================================================================
tests/spec/managers/templates_manager_spec.lua
==============================================================================
* package.preload['llm.core.data.llm_cli'] = function()
*     return require('mock_llm_cli')
  end

* require('spec_helper')
* local assert = require('luassert')
* local templates_manager = require('llm.managers.templates_manager')
* local llm_cli = require('llm.core.data.llm_cli')
* local cache = require('llm.core.data.cache')

* describe('llm.managers.templates_manager', function()
*   before_each(function()
*     cache.invalidate('templates')
*     llm_cli.run_llm_command = function() return '[]' end
    end)

*   describe('get_templates', function()
*     it('should parse JSON output from llm_cli.run_llm_command', function()
*       llm_cli.run_llm_command = function(cmd)
*         if cmd == 'templates list --json' then
*           return '[{"name": "test-template"}]'
          end
*         return '[]'
        end
*       local templates = templates_manager.get_templates()
*       assert.same({ { name = "test-template" } }, templates)
      end)
    end)

*   describe('get_template_details', function()
*     it('should parse JSON output from llm_cli.run_llm_command', function()
*       llm_cli.run_llm_command = function(cmd)
*         if cmd == 'templates show test-template-details' then
*           return '{"name": "test-template-details", "prompt": "Test prompt"}'
          end
*         return '{}'
        end
*       local template_details = templates_manager.get_template_details('test-template-details')
*       assert.are.same('test-template-details', template_details.name)
*       assert.are.same('Test prompt', template_details.prompt)
      end)
    end)

*   describe('save_template', function()
*     it('should construct the correct llm_cli.run_llm_command string', function()
*         local spy = spy.on(llm_cli, 'run_llm_command')
*         templates_manager.save_template('test-template-save', 'Test prompt', 'Test system', 'gpt-4', { temperature = 0.5 }, { 'fragment1' }, { 'system_fragment1' }, { param1 = 'default1' }, true, 'schema1')
*         assert.spy(spy).was.called_with("templates save test-template-save --prompt 'Test prompt' --system 'Test system' --model gpt-4 -o temperature '0.5' -f fragment1 -sf system_fragment1 -d param1 'default1' --extract --schema schema1")
*         spy:revert()
      end)
    end)

*   describe('delete_template', function()
*     it('should call llm_cli.run_llm_command with the correct arguments', function()
*         local spy = spy.on(llm_cli, 'run_llm_command')
*         templates_manager.delete_template('test-template-delete')
*         assert.spy(spy).was.called_with("templates delete test-template-delete -y")
*         spy:revert()
      end)
    end)

*   describe('run_template', function()
*     it('should construct the correct command table', function()
*       local cmd = templates_manager.run_template('test-template', 'Test input', { param1 = 'value1' })
*       assert.same({"/usr/bin/llm", "-t", "test-template", "'Test input'", "-p", "param1", "'value1'"}, cmd)
      end)
    end)

*   describe('run_template_with_selection', function()
*     it('should call api.run_llm_command_streamed with correct executable path', function()
*         local api = require('llm.api')
*         local old_run_llm_command_streamed = api.run_llm_command_streamed
*         local was_called = false
          local call_args
*         api.run_llm_command_streamed = function(...)
*             was_called = true
*             call_args = {...}
          end

*         local old_get_template_details = templates_manager.get_template_details
*         templates_manager.get_template_details = function() return { name = 'test', prompt = 'test' } end

*         local old_create_floating_window = require('llm.core.utils.ui').create_floating_window
*         require('llm.core.utils.ui').create_floating_window = function() end

*         templates_manager.run_template_with_selection('test-template', 'my selection')

*         assert.is_true(was_called)
*         assert.is_not_nil(call_args)
*         assert.are.equal('/usr/bin/llm', call_args[1][1])

*         templates_manager.get_template_details = old_get_template_details
*         require('llm.core.utils.ui').create_floating_window = old_create_floating_window
*         api.run_llm_command_streamed = old_run_llm_command_streamed
      end)
    end)
  end)

==============================================================================
tests/spec/managers/models_io_spec.lua
==============================================================================
  -- tests/spec/managers/models_io_spec.lua

* require("spec_helper")

* describe("llm.managers.models_io", function()
    local models_io
    local llm_cli

*   before_each(function()
*     _G.package = require('package')
*     package.loaded["llm.managers.models_io"] = nil
*     package.loaded["llm.core.data.llm_cli"] = nil

*     llm_cli = require("llm.core.data.llm_cli")
*     models_io = require("llm.managers.models_io")
    end)

*   after_each(function()
*     package.loaded["llm.managers.models_io"] = nil
*     package.loaded["llm.core.data.llm_cli"] = nil
*     _G.package = nil
    end)

*   describe("get_models_from_cli()", function()
*     it("should call llm_cli.run_llm_command with the correct command string", function()
        -- Mock llm_cli.run_llm_command
*       local run_llm_command_spy = spy.on(llm_cli, "run_llm_command")

        -- Call the function
*       models_io.get_models_from_cli()

        -- Assertions
*       assert.spy(run_llm_command_spy).was.called_with("models list --json")
      end)
    end)

*   describe("get_default_model_from_cli()", function()
*     it("should call llm_cli.run_llm_command with the correct command string", function()
        -- Mock llm_cli.run_llm_command
*       local run_llm_command_spy = spy.on(llm_cli, "run_llm_command")

        -- Call the function
*       models_io.get_default_model_from_cli()

        -- Assertions
*       assert.spy(run_llm_command_spy).was.called_with("default")
      end)
    end)

*   describe("set_default_model_in_cli()", function()
*     it("should call llm_cli.run_llm_command with the correct command string", function()
        -- Mock llm_cli.run_llm_command
*       local run_llm_command_spy = spy.on(llm_cli, "run_llm_command")

        -- Call the function
*       models_io.set_default_model_in_cli("test-model")

        -- Assertions
*       assert.spy(run_llm_command_spy).was.called_with("default test-model")
      end)
    end)

*   describe("get_aliases_from_cli()", function()
*     it("should call llm_cli.run_llm_command with the correct command string", function()
        -- Mock llm_cli.run_llm_command
*       local run_llm_command_spy = spy.on(llm_cli, "run_llm_command")

        -- Call the function
*       models_io.get_aliases_from_cli()

        -- Assertions
*       assert.spy(run_llm_command_spy).was.called_with("aliases list --json")
      end)
    end)

*   describe("set_alias_in_cli()", function()
*     it("should call llm_cli.run_llm_command with the correct command string", function()
        -- Mock llm_cli.run_llm_command
*       local run_llm_command_spy = spy.on(llm_cli, "run_llm_command")

        -- Call the function
*       models_io.set_alias_in_cli("test-alias", "test-model")

        -- Assertions
*       assert.spy(run_llm_command_spy).was.called_with("aliases set test-alias test-model")
      end)
    end)

*   describe("remove_alias_in_cli()", function()
*     it("should call llm_cli.run_llm_command with the correct command string", function()
        -- Mock llm_cli.run_llm_command
*       local run_llm_command_spy = spy.on(llm_cli, "run_llm_command")

        -- Call the function
*       models_io.remove_alias_in_cli("test-alias")

        -- Assertions
*       assert.spy(run_llm_command_spy).was.called_with("aliases remove 'test-alias'")
      end)
    end)
  end)

==============================================================================
tests/spec/managers/plugins_manager_spec.lua
==============================================================================
* require('spec_helper')
* local plugins_manager = require('llm.managers.plugins_manager')
* local llm_cli = require('llm.core.data.llm_cli')
* local cache = require('llm.core.data.cache')

* describe('plugins_manager', function()
*   before_each(function()
*     cache.invalidate('available_plugins')
*     cache.invalidate('installed_plugins')
    end)

*   describe('get_available_plugins', function()
*     it('should parse the HTML from the plugin directory URL', function()
        local mock_html = [[
          <section id="official-plugins">
            <h2>Official Plugins</h2>
            <ul>
              <li><a href="https://github.com/simonw/llm-plugin-1"><strong>llm-plugin-1</strong></a>: Description 1</li>
              <li><a href="https://github.com/simonw/llm-plugin-2"><strong>llm-plugin-2</strong></a>: Description 2</li>
            </ul>
          </section>
*       ]]
*       local old_system = vim.fn.system
*       vim.fn.system = function()
*         return mock_html
        end

*       local plugins = plugins_manager.get_available_plugins()
*       assert.same({
*         { name = 'llm-plugin-1', url = 'https://github.com/simonw/llm-plugin-1', description = 'Description 1' },
*         { name = 'llm-plugin-2', url = 'https://github.com/simonw/llm-plugin-2', description = 'Description 2' },
*       }, plugins)

*       vim.fn.system = old_system
      end)

*     it('should handle a failed curl command gracefully', function()
*       local old_system = vim.fn.system
*       vim.fn.system = function()
*         return ''
        end

*       local plugins = plugins_manager.get_available_plugins()
*       assert.same({}, plugins)

*       vim.fn.system = old_system
      end)

*     it('should cache the available plugins', function()
*       local old_system = vim.fn.system
*       local call_count = 0
*       vim.fn.system = function()
*         call_count = call_count + 1
0         return [[
          <section id="official-plugins">
            <h2>Official Plugins</h2>
            <ul>
              <li><a href="https://github.com/simonw/llm-plugin-1"><strong>llm-plugin-1</strong></a>: Description 1</li>
            </ul>
          </section>
*       ]]
        end

*       plugins_manager.get_available_plugins()
*       plugins_manager.get_available_plugins()

*       assert.are.equal(1, call_count)

*       vim.fn.system = old_system
      end)
    end)

*   describe('get_installed_plugins', function()
*     it('should parse the JSON output from llm_cli.run_llm_command', function()
*       local mock_json = '[{"name": "llm-gpt4all"}]'
*       local old_run_llm_command = llm_cli.run_llm_command
*       llm_cli.run_llm_command = function()
*         return mock_json
        end

        -- Mock json_decode to avoid issues in the test environment
*       local old_json_decode = vim.fn.json_decode
*       vim.fn.json_decode = function(json)
*         if json == mock_json then
*           return { { name = 'llm-gpt4all' } }
          end
0         return {}
        end

*       local plugins = plugins_manager.get_installed_plugins()
*       assert.same({ { name = 'llm-gpt4all' } }, plugins)

*       llm_cli.run_llm_command = old_run_llm_command
*       vim.fn.json_decode = old_json_decode
      end)

*     it('should cache the installed plugins', function()
*       local call_count = 0
*       local old_run_llm_command = llm_cli.run_llm_command
*       llm_cli.run_llm_command = function()
*         call_count = call_count + 1
*         return '[]'
        end

        -- Mock json_decode to avoid issues in the test environment
*       local old_json_decode = vim.fn.json_decode
*       vim.fn.json_decode = function()
*         return {}
        end

*       plugins_manager.get_installed_plugins()
*       plugins_manager.get_installed_plugins()

*       assert.are.equal(1, call_count)

*       llm_cli.run_llm_command = old_run_llm_command
*       vim.fn.json_decode = old_json_decode
      end)
    end)

*   describe('is_plugin_installed', function()
*     it('should return true if the plugin is in the list of installed plugins', function()
*       local mock_json = '[{"name": "llm-gpt4all"}]'
*       local old_run_llm_command = llm_cli.run_llm_command
*       llm_cli.run_llm_command = function()
*         return mock_json
        end

        -- Mock json_decode to avoid issues in the test environment
*       local old_json_decode = vim.fn.json_decode
*       vim.fn.json_decode = function(json)
*         if json == mock_json then
*           return { { name = 'llm-gpt4all' } }
          end
0         return {}
        end

*       assert.is_true(plugins_manager.is_plugin_installed('llm-gpt4all'))

*       llm_cli.run_llm_command = old_run_llm_command
*       vim.fn.json_decode = old_json_decode
      end)

*     it('should return false if the plugin is not in the list of installed plugins', function()
*       local mock_json = '[{"name": "llm-gpt4all"}]'
*       local old_run_llm_command = llm_cli.run_llm_command
*       llm_cli.run_llm_command = function()
*         return mock_json
        end

        -- Mock json_decode to avoid issues in the test environment
*       local old_json_decode = vim.fn.json_decode
*       vim.fn.json_decode = function(json)
*         if json == mock_json then
*           return { { name = 'llm-gpt4all' } }
          end
0         return {}
        end

*       assert.is_false(plugins_manager.is_plugin_installed('some-other-plugin'))

*       llm_cli.run_llm_command = old_run_llm_command
*       vim.fn.json_decode = old_json_decode
      end)
    end)

*   describe('install_plugin', function()
*     it('should call llm_cli.run_llm_command with the correct arguments', function()
*       local old_run_llm_command = llm_cli.run_llm_command
        local command
*       llm_cli.run_llm_command = function(c)
*         command = c
        end

*       plugins_manager.install_plugin('my-plugin')

*       assert.are.equal('install my-plugin', command)

*       llm_cli.run_llm_command = old_run_llm_command
      end)
    end)

*   describe('uninstall_plugin', function()
*     it('should call llm_cli.run_llm_command with the correct arguments', function()
*       local old_run_llm_command = llm_cli.run_llm_command
        local command
*       llm_cli.run_llm_command = function(c)
*         command = c
        end

*       plugins_manager.uninstall_plugin('my-plugin')

*       assert.are.equal('uninstall my-plugin -y', command)

*       llm_cli.run_llm_command = old_run_llm_command
      end)
    end)
  end)

==============================================================================
tests/spec/core/loaders_spec.lua
==============================================================================
  -- tests/spec/core/loaders_spec.lua
  --
  -- Unit tests for the loaders module.
  -- License: Apache 2.0

* describe('llm.core.loaders', function()
*   describe('load_models()', function()
*     it('should parse model list and set cache', function()
        -- Arrange
*       local mock_llm_cli = {
*         run_llm_command = spy.new(function()
0           return [[
  openai: gpt-4
  openai: gpt-3.5-turbo
* ]]
          end),
        }
*       local mock_cache = {
*         set = spy.new(function() end),
        }
*       package.loaded['llm.core.data.llm_cli'] = mock_llm_cli
*       package.loaded['llm.core.data.cache'] = mock_cache
*       package.loaded['llm.core.loaders'] = nil
*       local loaders = require('llm.core.loaders')

        -- Act
*       loaders.load_models()

        -- Assert
*       assert.spy(mock_llm_cli.run_llm_command).was_called_with('models list')
*       assert.spy(mock_cache.set).was_called()
*       local cache_args = mock_cache.set.calls[1].vals
*       assert.are.equal('models', cache_args[1])
*       assert.are.same({
*         { provider = 'openai', id = 'gpt-4', name = 'gpt-4' },
*         { provider = 'openai', id = 'gpt-3.5-turbo', name = 'gpt-3.5-turbo' },
*       }, cache_args[2])

        -- Clean up
*       package.loaded['llm.core.data.llm_cli'] = nil
*       package.loaded['llm.core.data.cache'] = nil
      end)
    end)

*   describe('load_schemas()', function()
*     it('should parse schema list and set cache', function()
        -- Arrange
*       local mock_llm_cli = {
*         run_llm_command = spy.new(function()
0           return [[
  schema1 - description1
  schema2 - description2
* ]]
          end),
        }
*       local mock_cache = {
*         set = spy.new(function() end),
        }
*       package.loaded['llm.core.data.llm_cli'] = mock_llm_cli
*       package.loaded['llm.core.data.cache'] = mock_cache
*       package.loaded['llm.core.loaders'] = nil
*       local loaders = require('llm.core.loaders')

        -- Act
*       loaders.load_schemas()

        -- Assert
*       assert.spy(mock_llm_cli.run_llm_command).was_called_with('schemas list')
*       assert.spy(mock_cache.set).was_called()
*       local cache_args = mock_cache.set.calls[1].vals
*       assert.are.equal('schemas', cache_args[1])
*       assert.are.same({
*         { id = 'schema1', description = 'description1' },
*         { id = 'schema2', description = 'description2' },
*       }, cache_args[2])

        -- Clean up
*       package.loaded['llm.core.data.llm_cli'] = nil
*       package.loaded['llm.core.data.cache'] = nil
      end)
    end)

*   describe('load_templates()', function()
*     it('should parse template list and set cache', function()
        -- Arrange
*       local mock_llm_cli = {
*         run_llm_command = spy.new(function()
0           return [[
  template1 - description1
  template2 - description2
* ]]
          end),
        }
*       local mock_cache = {
*         set = spy.new(function() end),
        }
*       package.loaded['llm.core.data.llm_cli'] = mock_llm_cli
*       package.loaded['llm.core.data.cache'] = mock_cache
*       package.loaded['llm.core.loaders'] = nil
*       local loaders = require('llm.core.loaders')

        -- Act
*       loaders.load_templates()

        -- Assert
*       assert.spy(mock_llm_cli.run_llm_command).was_called_with('templates list')
*       assert.spy(mock_cache.set).was_called()
*       local cache_args = mock_cache.set.calls[1].vals
*       assert.are.equal('templates', cache_args[1])
*       assert.are.same({
*         { name = 'template1', description = 'description1' },
*         { name = 'template2', description = 'description2' },
*       }, cache_args[2])

        -- Clean up
*       package.loaded['llm.core.data.llm_cli'] = nil
*       package.loaded['llm.core.data.cache'] = nil
      end)
    end)

*   describe('load_fragments()', function()
*     it('should parse fragment list and set cache', function()
        -- Arrange
*       local mock_llm_cli = {
*         run_llm_command = spy.new(function()
0           return [[
    - hash: 12345
      - alias1
      - alias2
      source: source1
      content: content1
      datetime: datetime1
    - hash: 67890
      - alias3
      source: source2
      content: content2
      datetime: datetime2
* ]]
          end),
        }
*       local mock_cache = {
*         set = spy.new(function() end),
        }
*       package.loaded['llm.core.data.llm_cli'] = mock_llm_cli
*       package.loaded['llm.core.data.cache'] = mock_cache
*       package.loaded['llm.core.loaders'] = nil
*       local loaders = require('llm.core.loaders')

        -- Act
*       loaders.load_fragments()

        -- Assert
*       assert.spy(mock_llm_cli.run_llm_command).was_called_with('fragments list')
*       assert.spy(mock_cache.set).was_called()
*       local cache_args = mock_cache.set.calls[1].vals
*       assert.are.equal('fragments', cache_args[1])
*       assert.are.same({
          {
*           hash = '12345',
*           aliases = { 'alias1', 'alias2' },
*           source = 'source1',
*           content = 'content1',
*           datetime = 'datetime1',
*         },
          {
*           hash = '67890',
*           aliases = { 'alias3' },
*           source = 'source2',
*           content = 'content2',
*           datetime = 'datetime2',
          },
*       }, cache_args[2])

        -- Clean up
*       package.loaded['llm.core.data.llm_cli'] = nil
*       package.loaded['llm.core.data.cache'] = nil
      end)
    end)

*   describe('load_keys()', function()
*     it('should parse key list and set cache', function()
        -- Arrange
*       local mock_llm_cli = {
*         run_llm_command = spy.new(function()
0           return [[
  Stored keys:
  ------------------
  key1
  key2
* ]]
          end),
        }
*       local mock_cache = {
*         set = spy.new(function() end),
        }
*       package.loaded['llm.core.data.llm_cli'] = mock_llm_cli
*       package.loaded['llm.core.data.cache'] = mock_cache
*       package.loaded['llm.core.loaders'] = nil
*       local loaders = require('llm.core.loaders')

        -- Act
*       loaders.load_keys()

        -- Assert
*       assert.spy(mock_llm_cli.run_llm_command).was_called_with('keys list')
*       assert.spy(mock_cache.set).was_called()
*       local cache_args = mock_cache.set.calls[1].vals
*       assert.are.equal('keys', cache_args[1])
*       assert.are.same({
*         { name = 'key1' },
*         { name = 'key2' },
*       }, cache_args[2])

        -- Clean up
*       package.loaded['llm.core.data.llm_cli'] = nil
*       package.loaded['llm.core.data.cache'] = nil
      end)
    end)

*   describe('load_available_plugins()', function()
*     it('should parse plugin list and set cache', function()
        -- Arrange
*       local mock_llm_cli = {
*         run_llm_command = spy.new(function()
0           return [[
  plugin1 - description1
  plugin2 - description2
* ]]
          end),
        }
*       local mock_cache = {
*         set = spy.new(function() end),
        }
*       package.loaded['llm.core.data.llm_cli'] = mock_llm_cli
*       package.loaded['llm.core.data.cache'] = mock_cache
*       package.loaded['llm.core.loaders'] = nil
*       local loaders = require('llm.core.loaders')

        -- Act
*       loaders.load_available_plugins()

        -- Assert
*       assert.spy(mock_llm_cli.run_llm_command).was_called_with('plugins --all')
*       assert.spy(mock_cache.set).was_called()
*       local cache_args = mock_cache.set.calls[1].vals
*       assert.are.equal('available_plugins', cache_args[1])
*       assert.are.same({
*         { name = 'plugin1', description = 'description1' },
*         { name = 'plugin2', description = 'description2' },
*       }, cache_args[2])

        -- Clean up
*       package.loaded['llm.core.data.llm_cli'] = nil
*       package.loaded['llm.core.data.cache'] = nil
      end)
    end)

*   describe('load_all()', function()
*     it('should call all loader functions', function()
        -- Arrange
*       local loaders = require('llm.core.loaders')
*       local spy_load_models = spy.on(loaders, 'load_models')
*       local spy_load_available_plugins = spy.on(loaders, 'load_available_plugins')
*       local spy_load_keys = spy.on(loaders, 'load_keys')
*       local spy_load_fragments = spy.on(loaders, 'load_fragments')
*       local spy_load_templates = spy.on(loaders, 'load_templates')
*       local spy_load_schemas = spy.on(loaders, 'load_schemas')

        -- Act
*       loaders.load_all()

        -- Assert
*       assert.spy(spy_load_models).was_called()
*       assert.spy(spy_load_available_plugins).was_called()
*       assert.spy(spy_load_keys).was_called()
*       assert.spy(spy_load_fragments).was_called()
*       assert.spy(spy_load_templates).was_called()
*       assert.spy(spy_load_schemas).was_called()
      end)
    end)
  end)

==============================================================================
tests/spec/core/data/cache_spec.lua
==============================================================================
  -- tests/spec/core/data/cache_spec.lua

* describe("llm.core.data.cache", function()
    local cache
    local mock_io
    local mock_json

*   before_each(function()
      -- Mock io functions
*     mock_io = {
        open = function()
0         return {
            read = function() return "" end,
            write = function() end,
            close = function() end,
          }
        end,
*     }
*     package.loaded['io'] = mock_io

      -- Mock vim object
*     _G.vim = {
*       fn = {
*         stdpath = function() return "/tmp" end,
          json_decode = function(str)
*           if str == "" then return {} end
0           return { test_key = "test_value" }
          end,
*         json_encode = function() return "" end,
*       },
*     }

      -- Reload the cache module to use the mocks
*     package.loaded['llm.core.data.cache'] = nil
*     cache = require('llm.core.data.cache')
    end)

*   after_each(function()
      -- Restore original modules
*     package.loaded['io'] = nil
*     package.loaded['llm.core.data.cache'] = nil
*     _G.vim = nil
    end)

*   it("should set a value in the cache", function()
*     local key = "test_key"
*     local value = "test_value"
*     cache.set(key, value)
*     assert.are.equal(value, cache.get(key))
    end)

*   it("should get a value from the cache", function()
*     local key = "test_key"
*     local value = "test_value"
*     cache.set(key, value)
*     local retrieved_value = cache.get(key)
*     assert.are.equal(value, retrieved_value)
    end)

*   it("should invalidate a value in the cache", function()
*     local key = "test_key"
*     local value = "test_value"
*     cache.set(key, value)
*     cache.invalidate(key)
*     assert.is_nil(cache.get(key))
    end)
  end)

==============================================================================
tests/spec/core/data/llm_cli_spec.lua
==============================================================================
  -- tests/spec/core/data/llm_cli_spec.lua
* require('spec_helper')

* describe("llm.core.data.llm_cli", function()
    local llm_cli
    local shell

*   before_each(function()
      -- Create a mock for the shell module
*     shell = {
*       safe_shell_command = function() end,
*     }
*     package.loaded['llm.core.utils.shell'] = shell

      -- Reload the llm_cli module to use the mock
*     package.loaded['llm.core.data.llm_cli'] = nil
*     llm_cli = require('llm.core.data.llm_cli')
    end)

*   after_each(function()
      -- Restore original modules
*     package.loaded['llm.core.utils.shell'] = nil
*     package.loaded['llm.core.data.llm_cli'] = nil
    end)

*   it("should prepend 'llm ' to the command and call shell.safe_shell_command", function()
      -- Spy on the safe_shell_command function
*     local spy = spy.on(shell, "safe_shell_command")

      -- Call the function to be tested
*     local command = "models list"
*     llm_cli.run_llm_command(command)

      -- Assert that the spy was called with the correct argument
*     assert.spy(spy).was.called_with("llm " .. command)
    end)

*   it("should handle an empty command", function()
*     local spy = spy.on(shell, "safe_shell_command")
*     llm_cli.run_llm_command("")
*     assert.spy(spy).was.called_with("llm")
    end)

*   it("should handle a command with special characters", function()
*     local spy = spy.on(shell, "safe_shell_command")
*     local command = "prompt 'hello world'"
*     llm_cli.run_llm_command(command)
*     assert.spy(spy).was.called_with("llm " .. command)
    end)
  end)

==============================================================================
tests/spec/core/utils/shell_spec.lua
==============================================================================
* require('tests.spec.spec_helper')

* local spy = require('luassert.spy')

* describe('llm.core.utils.shell', function()
*   local shell = require('llm.core.utils.shell')


*   describe('safe_shell_command()', function()
      local original_vim_fn

*     before_each(function()
*       original_vim_fn = vim.fn
      end)

*     after_each(function()
*       vim.fn = original_vim_fn
      end)

*     it('should call vim.fn.system with the correct command', function()
*       local was_called = false
*       vim.fn.system = function(cmd)
*         was_called = true
*         assert.are.equal('ls 2>&1', cmd)
*         return ''
        end
*       shell.safe_shell_command('ls', 'error')
*       assert.is_true(was_called)
      end)

*     it('should return the trimmed result', function()
*       vim.fn.system = function() return '  result  \n' end
*       local result, err = shell.safe_shell_command('ls', 'error')
*       assert.are.equal('result', result)
*       assert.is_nil(err)
      end)

*     it('should handle multi-line results', function()
*       vim.fn.system = function() return 'line1\nline2\n' end
*       local result, err = shell.safe_shell_command('ls', 'error')
*       assert.are.equal('line1\nline2', result)
*       assert.is_nil(err)
      end)

*     it('should return an error if the command returns nil', function()
*       vim.fn.system = function() return nil end
*       local result, err = shell.safe_shell_command('ls', 'error')
*       assert.is_nil(result)
*       assert.are.equal('Command returned nil', err)
      end)

*     it('should return an error if the command returns an empty string', function()
*       vim.fn.system = function() return '' end
*       local result, err = shell.safe_shell_command('ls', 'error')
*       assert.is_nil(result)
*       assert.are.equal('error', err)
      end)
    end)

*   describe('command_exists()', function()
      local original_os_execute

*     before_each(function()
*       original_os_execute = os.execute
      end)

*     after_each(function()
*       os.execute = original_os_execute
      end)

*     it('should return true if command exists', function()
*       local was_called = false
*       os.execute = function(cmd)
*         was_called = true
*         assert.are.equal('command -v ls >/dev/null 2>&1', cmd)
*         return 0
        end
*       assert.is_true(shell.command_exists('ls'))
*       assert.is_true(was_called)
      end)

*     it('should return false if command does not exist', function()
*       os.execute = function() return 1 end
*       assert.is_false(shell.command_exists('not-a-command'))
      end)
    end)

*   describe('execute()', function()
      local original_io_popen

*     before_each(function()
*       original_io_popen = io.popen
      end)

*     after_each(function()
*       io.popen = original_io_popen
      end)

*     it('should return output on success', function()
*       io.popen = function()
*         return {
*           read = function() return 'output' end,
*           close = function() return true, '', 0 end,
*         }
        end
*       local output, err = shell.execute('ls')
*       assert.are.equal('output', output)
*       assert.is_nil(err)
      end)

*     it('should return an error on failure', function()
*       io.popen = function()
*         return {
*           read = function() return 'error' end,
*           close = function() return false, '', 1 end,
*         }
        end
*       local output, err = shell.execute('ls')
*       assert.is_nil(output)
*       assert.are.equal('Command failed', err)
      end)
    end)

    -- describe('timestamps', function()
    --   before_each(function()
    --     vim.fn.isdirectory = function() return 1 end
    --     vim.fn.mkdir = function() end
    --   end)
    --
*   describe('timestamps', function()
*     before_each(function()
*       vim.fn.isdirectory = function() return 1 end
*       vim.fn.mkdir = function() end
      end)

*     it('should get and set last update timestamp', function()
*       local was_read = false
*       local was_written = false
*       local original_io_open = io.open

*       io.open = function(path, mode)
*         if mode == 'r' then
*           was_read = true
*           return {
*             read = function() return '123' end,
*             close = function() end,
*           }
*         elseif mode == 'w' then
*           was_written = true
*           return {
*             write = function() end,
*             close = function() end,
*           }
          end
        end

*       assert.are.equal(123, shell.get_last_update_timestamp())
*       shell.set_last_update_timestamp()
*       assert.is_true(was_read)
*       assert.is_true(was_written)

*       io.open = original_io_open
      end)
    end)

*   describe('update_llm_cli()', function()
*     it('should try different update methods and succeed', function()
*       local command_exists_calls = {}
*       shell.command_exists = function(cmd)
*         table.insert(command_exists_calls, cmd)
*         return cmd == 'pipx'
        end

*       local run_update_calls = {}
*       local api_mock = {
          run_llm_command_streamed = function(cmd, bufnr, callbacks)
*             table.insert(run_update_calls, cmd)
*             callbacks.on_exit(0, 0, 'exit')
          end
        }

*       shell.update_llm_cli(1, api_mock)

*       assert.are.same({ 'uv', 'pipx' }, command_exists_calls)
*       assert.are.same({ {"pipx", "upgrade", "llm"} }, run_update_calls)
      end)

*     it('should try all methods and fail', function()
*         local command_exists_calls = {}
*         shell.command_exists = function(cmd)
*             table.insert(command_exists_calls, cmd)
*             return false
          end

*         local run_update_calls = {}
*         local api_mock = {
              run_llm_command_streamed = function(cmd, bufnr, callbacks)
*                 table.insert(run_update_calls, cmd)
*                 callbacks.on_exit(0, 1, 'exit')
              end
          }

*       shell.update_llm_cli(1, api_mock)
*       assert.are.same({ 'uv', 'pipx', 'brew' }, command_exists_calls)
      end)
    end)
  end)

==============================================================================
tests/spec/core/utils/job_spec.lua
==============================================================================
* require('tests.spec.spec_helper')

* describe('llm.core.utils.job', function()
    local job

*   before_each(function()
      -- Fresh module for each test
*     package.loaded['llm.core.utils.job'] = nil
*     job = require('llm.core.utils.job')
    end)

*   describe('on_stdout handling', function()
*     it('should handle multiple lines in one chunk', function()
        -- Given
*       local on_stdout_spy = spy.new()
        local captured_job_callbacks
*       vim.fn.jobstart = function(_, callbacks)
*         captured_job_callbacks = callbacks
*         return 1
        end

        -- When
*       job.run({ 'echo', 'line1\nline2' }, { on_stdout = on_stdout_spy })
*       captured_job_callbacks.on_stdout(0, { 'line1\nline2\n' }, 'stdout')

        -- Then
*       assert.spy(on_stdout_spy).was.called(1)
*       assert.spy(on_stdout_spy).was.called_with(nil, {'line1', 'line2'})
      end)

*     it('should handle partial lines', function()
        -- Given
*       local on_stdout_spy = spy.new()
        local captured_job_callbacks
*       vim.fn.jobstart = function(_, callbacks)
*         captured_job_callbacks = callbacks
*         return 1
        end

        -- When
*       job.run({ 'echo', 'partial' }, { on_stdout = on_stdout_spy })
*       captured_job_callbacks.on_stdout(0, { 'part' }, 'stdout')
*       captured_job_callbacks.on_stdout(0, { 'ial\n' }, 'stdout')

        -- Then
*       assert.spy(on_stdout_spy).was.called(1)
*       assert.spy(on_stdout_spy).was.called_with(nil, {'partial'})
      end)

*     it('should handle empty lines', function()
        -- Given
*       local on_stdout_spy = spy.new()
        local captured_job_callbacks
*       vim.fn.jobstart = function(_, callbacks)
*         captured_job_callbacks = callbacks
*         return 1
        end

        -- When
*       job.run({ 'echo', '\n' }, { on_stdout = on_stdout_spy })
*       captured_job_callbacks.on_stdout(0, { '\n' }, 'stdout')

        -- Then
*       assert.spy(on_stdout_spy).was.called(1)
*       assert.spy(on_stdout_spy).was.called_with(nil, {''})
      end)
    end)
  end)

==============================================================================
tests/spec/core/utils/validate_spec.lua
==============================================================================
* require('tests.spec.spec_helper')

* describe('llm.core.utils.validate', function()
*   local validate_utils = require('llm.core.utils.validate')

*   describe('convert()', function()
*     it('should convert string to boolean', function()
*       assert.is_true(validate_utils.convert('true', 'boolean'))
*       assert.is_false(validate_utils.convert('false', 'boolean'))
      end)

*     it('should convert string to number', function()
*       assert.are.equal(123, validate_utils.convert('123', 'number'))
      end)

*     it('should return the original value for other types', function()
*       assert.are.equal('hello', validate_utils.convert('hello', 'string'))
*       assert.are.equal(456, validate_utils.convert(456, 'number'))
      end)
    end)

*   describe('validate()', function()
*     it('should validate types correctly', function()
*       assert.is_true(validate_utils.validate('hello', 'string'))
*       assert.is_true(validate_utils.validate(123, 'number'))
*       assert.is_true(validate_utils.validate(true, 'boolean'))
*       assert.is_false(validate_utils.validate('hello', 'number'))
*       assert.is_false(validate_utils.validate(123, 'boolean'))
*       assert.is_false(validate_utils.validate(false, 'string'))
      end)
    end)
  end)

==============================================================================
tests/spec/core/utils/ui_spec.lua
==============================================================================
* require('spec_helper')

* describe('llm.core.utils.ui', function()
*   local ui_utils = require('llm.core.utils.ui')

*   describe('create_chat_buffer()', function()
*     it('should create and configure the chat buffer correctly', function()
        -- Spies for API calls
*       vim.cmd = spy.new(function() end)
*       vim.api.nvim_get_current_buf = spy.new(function() return 1 end)
*       vim.api.nvim_buf_set_lines = spy.new(function() end)
*       vim.api.nvim_buf_set_keymap = spy.new(function() end)
*       vim.api.nvim_win_set_cursor = spy.new(function() end)
*       vim.api.nvim_buf_set_option = spy.new(function() end)
*       vim.api.nvim_buf_set_name = spy.new(function() end)

        -- Execute the function
*       ui_utils.create_chat_buffer()

        -- Assertions
*       assert.spy(vim.cmd).was.called_with('vnew')
*       assert.spy(vim.api.nvim_get_current_buf).was.called()

        -- Check that the prompt is set correctly
*       local expected_prompt = {
*         '--- User Prompt ---',
*         'Enter your prompt below and press <Enter> to submit.',
*         '-------------------',
          ''
*       }
*       assert.spy(vim.api.nvim_buf_set_lines).was.called_with(1, 0, -1, false, expected_prompt)

        -- Check that keymaps are set
*       assert.spy(vim.api.nvim_buf_set_keymap).was.called_with(1, 'i', '<Enter>', '<Cmd>lua require("llm.chat").send_prompt()<CR>', { noremap = true, silent = true })
*       assert.spy(vim.api.nvim_buf_set_keymap).was.called_with(1, 'n', 'q', '<Cmd>bd<CR>', { noremap = true, silent = true })

        -- Check that the cursor is positioned correctly
*       assert.spy(vim.api.nvim_win_set_cursor).was.called_with(0, { 4, 0 })

        -- Check that Neovim is put into insert mode
*       assert.spy(vim.cmd).was.called_with('startinsert')
      end)
    end)

*   describe('create_prompt_buffer()', function()
*     it('should create a prompt buffer', function()
*       vim.cmd = spy.new(function() end)
*       vim.api.nvim_get_current_buf = spy.new(function() return 1 end)
*       vim.api.nvim_buf_set_lines = spy.new(function() end)
*       vim.api.nvim_create_augroup = spy.new(function() return 1 end)
*       vim.api.nvim_create_autocmd = spy.new(function() end)

*       ui_utils.create_prompt_buffer()

*       assert.spy(vim.cmd).was.called_with('vnew')
*       assert.spy(vim.cmd).was.called_with('startinsert')
*       assert.spy(vim.api.nvim_get_current_buf).was.called()
*       assert.spy(vim.api.nvim_buf_set_lines).was.called()
*       assert.spy(vim.api.nvim_create_augroup).was.called()
*       assert.spy(vim.api.nvim_create_autocmd).was.called()
      end)
    end)

*   describe('buffer content', function()
*     it('should create a buffer with content', function()
*       vim.api.nvim_create_buf = spy.new(function() return 1 end)
*       vim.api.nvim_open_win = spy.new(function() end)
*       vim.api.nvim_buf_set_lines = spy.new(function() end)
*       vim.cmd = spy.new(function() end)
*       vim.api.nvim_buf_set_option = spy.new(function() end)
*       vim.api.nvim_buf_set_name = spy.new(function() end)
*       vim.api.nvim_buf_get_name = spy.new(function() return "test_buffer" end)
*       vim.api.nvim_create_augroup = spy.new(function() end)
*       vim.api.nvim_create_autocmd = spy.new(function() end)

*       package.loaded['llm.core.utils.ui'] = nil
*       ui_utils = require('llm.core.utils.ui')

*       ui_utils.create_buffer_with_content('hello', 'test_buffer', 'markdown')

*       assert.spy(vim.api.nvim_create_buf).was.called()
*       assert.spy(vim.api.nvim_buf_set_lines).was.called_with(1, 0, -1, false, { 'hello' })
      end)

*     it('should replace buffer content', function()
*       vim.api.nvim_buf_set_option = spy.new(function() end)
*       vim.api.nvim_buf_set_lines = spy.new(function() end)

*       ui_utils.replace_buffer_with_content('new content', 2, 'text')

*       assert.spy(vim.api.nvim_buf_set_lines).was.called_with(2, 0, -1, false, { 'new content' })
      end)
    end)

*   describe('floating window', function()
*     it('should create a floating window', function()
*       vim.api.nvim_open_win = spy.new(function() return 1 end)
*       vim.api.nvim_win_set_option = spy.new(function() end)

*       vim.o = { columns = 100, lines = 50 }

*       ui_utils.create_floating_window(1, 'test_window')

*       assert.spy(vim.api.nvim_open_win).was.called()
*       assert.spy(vim.api.nvim_win_set_option).was.called_with(1, 'cursorline', true)
      end)
    end)

*   describe('floating input', function()
*     it('should create a floating input', function()
*       vim.api.nvim_create_buf = spy.new(function() return 1 end)
*       vim.api.nvim_open_win = spy.new(function() return 2 end)
*       vim.api.nvim_buf_set_keymap = spy.new(function() end)
*       vim.api.nvim_buf_set_var = spy.new(function() end)
*       vim.api.nvim_command = spy.new(function() end)
*       vim.o = { columns = 100, lines = 50 }

*       ui_utils.floating_input({ prompt = 'test' }, function() end)

*       assert.spy(vim.api.nvim_create_buf).was.called()
*       assert.spy(vim.api.nvim_open_win).was.called()
*       assert.spy(vim.api.nvim_buf_set_keymap).was.called()
*       assert.spy(vim.api.nvim_buf_set_var).was.called()
*       assert.spy(vim.api.nvim_command).was.called_with('startinsert')
      end)
    end)

*   describe('floating confirm', function()
*     it('should create a floating confirm', function()
*       vim.api.nvim_create_buf = spy.new(function() return 1 end)
*       vim.api.nvim_open_win = spy.new(function() return 2 end)
*       vim.api.nvim_set_hl = spy.new(function() end)
*       vim.api.nvim_win_set_option = spy.new(function() end)
*       vim.api.nvim_buf_set_lines = spy.new(function() end)
*       vim.api.nvim_buf_add_highlight = spy.new(function() end)
*       vim.api.nvim_buf_set_keymap = spy.new(function() end)
*       vim.api.nvim_buf_set_var = spy.new(function() end)
*       vim.o = { columns = 100, lines = 50 }

*       ui_utils.floating_confirm({ prompt = 'test' })

*       assert.spy(vim.api.nvim_create_buf).was.called()
*       assert.spy(vim.api.nvim_open_win).was.called()
*       assert.spy(vim.api.nvim_set_hl).was.called()
*       assert.spy(vim.api.nvim_win_set_option).was.called()
*       assert.spy(vim.api.nvim_buf_set_lines).was.called()
*       assert.spy(vim.api.nvim_buf_add_highlight).was.called()
*       assert.spy(vim.api.nvim_buf_set_keymap).was.called()
*       assert.spy(vim.api.nvim_buf_set_var).was.called()
      end)
    end)

*   describe('append_to_buffer', function()
      local orig_bufwinid

*     before_each(function()
*       orig_bufwinid = vim.fn.bufwinid
      end)

*     after_each(function()
*       vim.fn.bufwinid = orig_bufwinid
      end)

*     it('should append lines and move cursor', function()
*       vim.api.nvim_buf_set_lines = spy.new(function() end)
*       vim.api.nvim_win_set_cursor = spy.new(function() end)
*       vim.api.nvim_buf_line_count = spy.new(function() return 5 end)
*       vim.fn.bufwinid = spy.new(function() return 1 end)
*       vim.api.nvim_get_current_buf = spy.new(function() return 123 end)

*       ui_utils.append_to_buffer(123, 'some new content')

*       assert.spy(vim.api.nvim_buf_line_count).was.called_with(123)
*       assert.spy(vim.api.nvim_buf_set_lines).was.called_with(123, 5, 5, false, { 'some new content' })
*       assert.spy(vim.api.nvim_win_set_cursor).was.called_with(0, { 6, 0 })
      end)

*     it('should do nothing for empty content', function()
*       vim.api.nvim_buf_set_lines = spy.new(function() end)

*       ui_utils.append_to_buffer(123, '')

*       assert.spy(vim.api.nvim_buf_set_lines).was.not_called()
      end)

*     it('should do nothing for nil content', function()
*       vim.api.nvim_buf_set_lines = spy.new(function() end)

*       ui_utils.append_to_buffer(123, nil)

*       assert.spy(vim.api.nvim_buf_set_lines).was.not_called()
      end)

*     it('should handle invalid buffer handle gracefully', function()
*       vim.api.nvim_buf_line_count = spy.new(function()
*         error('Invalid buffer id')
        end)
*       vim.api.nvim_buf_set_lines = spy.new(function() end)

*       assert.is_not.error(function()
*         ui_utils.append_to_buffer(999, 'content')
        end)
*       assert.spy(vim.api.nvim_buf_set_lines).was.not_called()
      end)
    end)
  end)

==============================================================================
tests/spec/core/utils/file_utils_spec.lua
==============================================================================
* require('tests.spec.spec_helper')

* describe('llm.core.utils.file_utils', function()
    local file_utils

*   before_each(function()
*     package.loaded['llm.core.utils.file_utils'] = nil
*     file_utils = require('llm.core.utils.file_utils')
    end)

*   describe('ensure_config_dir_exists()', function()
*     it('should return true if directory is writable', function()
*       local was_called = false
*       file_utils._test_directory_writable = function(dir)
*         was_called = true
*         assert.are.equal('/tmp/llm-nvim', dir)
*         return true
        end

*       assert.is_true(file_utils.ensure_config_dir_exists('/tmp/llm-nvim'))
*       assert.is_true(was_called)
      end)

*     it('should create directory if not writable', function()
*       local was_called_test = false
*       local was_called_create = false
*       file_utils._test_directory_writable = function(dir)
*         was_called_test = true
*         return false
        end
*       file_utils._create_directory = function(dir)
*         was_called_create = true
*         assert.are.equal('/tmp/llm-nvim', dir)
*         return true
        end

*       assert.is_true(file_utils.ensure_config_dir_exists('/tmp/llm-nvim'))
*       assert.is_true(was_called_test)
*       assert.is_true(was_called_create)
      end)

*     it('should return false if directory creation fails', function()
*       file_utils._test_directory_writable = function() return false end
*       file_utils._create_directory = function() return false end
*       assert.is_false(file_utils.ensure_config_dir_exists('/tmp/llm-nvim'))
      end)
    end)

*   describe('get_config_path()', function()
      local mock_shell

*     before_each(function()
*       mock_shell = {
*         safe_shell_command = function() end
*       }
*       file_utils.set_shell(mock_shell)
*       file_utils.config_dir_cache = nil
      end)

*     it('should resolve and cache the config path', function()
*       local shell_calls = 0
*       mock_shell.safe_shell_command = function(cmd)
*         shell_calls = shell_calls + 1
*         if cmd == 'llm logs path' then
*           return '/home/user/.logs/llm'
*         elseif cmd == "dirname '/home/user/.logs/llm'" then
*           return '/home/user/.logs'
          end
        end

*       file_utils.ensure_config_dir_exists = function() return true end

*       local config_dir, path = file_utils.get_config_path('test.json')
*       assert.are.equal('/home/user/.logs', config_dir)
*       assert.are.equal('/home/user/.logs/test.json', path)
*       assert.are.equal(2, shell_calls)

        -- Call again to test caching
*       file_utils.get_config_path('test.json')
*       assert.are.equal(2, shell_calls) -- No new calls
      end)

*     it('should return nil if filename is not provided', function()
*       local config_dir, path = file_utils.get_config_path(nil)
*       assert.is_nil(config_dir)
*       assert.is_nil(path)
      end)

*     it('should return nil if llm logs path fails', function()
*       mock_shell.safe_shell_command = function() return nil end
*       local config_dir, path = file_utils.get_config_path('test.json')
*       assert.is_nil(config_dir)
*       assert.is_nil(path)
      end)

*     it('should return nil if ensure_config_dir_exists fails', function()
*       mock_shell.safe_shell_command = function() return '/home/user/.logs/llm' end
*       file_utils.ensure_config_dir_exists = function() return false end
*       local config_dir, path = file_utils.get_config_path('test.json')
*       assert.is_nil(config_dir)
*       assert.is_nil(path)
      end)
    end)
  end)

==============================================================================
tests/spec/core/utils/notify_spec.lua
==============================================================================
* require('tests.spec.spec_helper')

* local spy = require('luassert.spy')

* describe('llm.core.utils.notify', function()
    local notify

*   before_each(function()
*     package.loaded['llm.core.utils.notify'] = nil
*     notify = require('llm.core.utils.notify')
    end)

*   it('should call vim.notify with the correct arguments', function()
*     spy.on(vim, 'notify')
*     notify.notify('test message', vim.log.levels.INFO, { title = 'Test' })
*     assert.spy(vim.notify).was.called_with('test message', vim.log.levels.INFO, { title = 'Test' })
    end)

*   it('should call vim.notify with an empty table if opts is nil', function()
*     spy.on(vim, 'notify')
*     notify.notify('test message', vim.log.levels.INFO)
*     assert.spy(vim.notify).was.called_with('test message', vim.log.levels.INFO, {})
    end)
  end)

==============================================================================
tests/spec/core/utils/text_spec.lua
==============================================================================
* require('tests.spec.spec_helper')

* describe('llm.core.utils.text', function()
*   local text_utils = require('llm.core.utils.text')

*   describe('capitalize()', function()
*     it('should capitalize the first letter of a lowercase string', function()
*       assert.are.equal('Hello', text_utils.capitalize('hello'))
      end)

*     it('should not change a string that is already capitalized', function()
*       assert.are.equal('Hello', text_utils.capitalize('Hello'))
      end)

*     it('should handle an empty string', function()
*       assert.are.equal('', text_utils.capitalize(''))
      end)

*     it('should handle a single character string', function()
*       assert.are.equal('A', text_utils.capitalize('a'))
      end)

*     it('should not change a string that starts with a number', function()
*       assert.are.equal('1hello', text_utils.capitalize('1hello'))
      end)
    end)

*   describe('get_visual_selection()', function()
*     it('should return the selected text', function()
*       local original_vim_fn = vim.fn
*       local original_vim_api = vim.api

*       vim.fn = {
          getpos = function(pos)
*           if pos == "'<" then
*             return { 0, 1, 1, 0 }
*           elseif pos == "'>" then
*             return { 0, 1, 5, 0 }
            end
          end,
*       }

*       vim.api = {
          nvim_buf_get_lines = function()
*           return { 'hello world' }
          end,
*       }

*       local selection = text_utils.get_visual_selection()
*       assert.are.equal('hello', selection)

*       vim.fn = original_vim_fn
*       vim.api = original_vim_api
      end)
    end)

*   describe('escape_pattern()', function()
*     it('should escape magic characters', function()
*       local unescaped = 'hello.world(how-are%you)'
*       local escaped = text_utils.escape_pattern(unescaped)
*       assert.are.equal('hello%.world%(how%-are%%you%)', escaped)
      end)
    end)

*   describe('parse_simple_yaml()', function()
*     it('should parse a simple yaml string', function()
        local yaml_string = [[
  key1: value1
  key2:
    nested_key1: nested_value1
    nested_key2: nested_value2
  key3:
    - item1
    - item2
* ]]
*       local expected_table = {
*         key1 = 'value1',
*         key2 = {
*           nested_key1 = 'nested_value1',
*           nested_key2 = 'nested_value2',
*         },
*         key3 = {
*           'item1',
            'item2',
*         },
        }

*       local file = io.open('temp_yaml.yaml', 'w')
*       file:write(yaml_string)
*       file:close()

*       local parsed_table = text_utils.parse_simple_yaml('temp_yaml.yaml')
*       assert.are.same(expected_table, parsed_table)

*       os.remove('temp_yaml.yaml')
      end)
    end)

*   describe('wrap()', function()
*     it('should not wrap a line shorter than the width', function()
*       local text = 'hello world'
*       local wrapped = text_utils.wrap(text, 80)
*       assert.are.equal('hello world', wrapped)
      end)

*     it('should wrap a long line', function()
*       local text = 'this is a long line of text that should be wrapped'
*       local wrapped = text_utils.wrap(text, 20)
*       local expected = 'this is a long line\nof text that should\nbe wrapped'
*       assert.are.equal(expected, wrapped)
      end)

*     it('should wrap a long line with an indent', function()
*       local text = 'this is a long line of text that should be wrapped'
*       local wrapped = text_utils.wrap(text, 30, '  ')
*       local expected = '  this is a long line of text\n  that should be wrapped'
*       assert.are.equal(expected, wrapped)
      end)

*     it('should handle a word longer than the width', function()
*       local text = 'thisisaverylongword'
*       local wrapped = text_utils.wrap(text, 10)
*       assert.are.equal('thisisaverylongword', wrapped)
      end)

*     it('should handle an empty string', function()
*       local text = ''
*       local wrapped = text_utils.wrap(text, 80)
*       assert.are.equal('', wrapped)
      end)

*     it('should handle a string with only spaces', function()
*       local text = '   '
*       local wrapped = text_utils.wrap(text, 80)
*       assert.are.equal('', wrapped)
      end)

*     it('should handle a string shorter than the width', function()
*       local text = 'a short string'
*       local wrapped = text_utils.wrap(text, 80)
*       assert.are.equal('a short string', wrapped)
      end)
    end)
  end)

==============================================================================
tests/spec/ui/ui_spec.lua
==============================================================================
* require('spec_helper')

* describe('llm.ui.ui', function()
*   vim.ui = {}
*   local ui = require('llm.ui.ui')

*   describe('display_in_buffer()', function()
*     it('should set buffer lines and syntax', function()
*       vim.api.nvim_buf_set_lines = spy.new(function() end)
*       vim.bo = { [1] = { syntax = '' } }

*       ui.display_in_buffer(1, { 'hello' }, 'markdown')

*       assert.spy(vim.api.nvim_buf_set_lines).was.called_with(1, 0, -1, false, { 'hello' })
*       assert.are.equal('markdown', vim.bo[1].syntax)
      end)
    end)

*   describe('notify()', function()
*     it('should call vim.notify', function()
*       vim.notify = spy.new(function() end)
*       ui.notify('test message', 'INFO')
*       assert.spy(vim.notify).was.called_with('test message', 'INFO')
      end)
    end)

    -- describe('get_input()', function()
    --   it('should call vim.ui.input', function()
    --     vim.ui.input = spy.new(function() end)
    --     local on_confirm = function() end
    --     ui.get_input('test prompt', on_confirm)
    --     assert.spy(vim.ui.input).was.called_with({ prompt = 'test prompt' }, on_confirm)
    --   end)
    -- end)

    -- describe('select()', function()
    --   it('should call vim.ui.select', function()
    --     vim.ui.select = spy.new(function() end)
    --     local on_choice = function() end
    --     ui.select({ 'item1' }, { prompt = 'test prompt' }, on_choice)
    --     assert.spy(vim.ui.select).was.called_with({ 'item1' }, { prompt = 'test prompt' }, on_choice)
    --   end)
    -- end)
  end)

==============================================================================
tests/spec/ui/views/schemas_view_spec.lua
==============================================================================
  -- require('spec_helper')

  -- describe('llm.ui.views.schemas_view', function()
  --   local schemas_view = require('llm.ui.views.schemas_view')
  --   local ui = require('llm.core.utils.ui')

  --   before_each(function()
  --     vim.ui = {}
  --   end)

  --   describe('select_schema()', function()
  --     it('should call vim.ui.select', function()
  --       vim.ui.select = spy.new(function() end)
  --       local schemas = {
  --         { name = 'b', description = 'desc b' },
  --         { name = 'a', description = 'desc a' }
  --       }
  --       schemas_view.select_schema(schemas, function() end)
  --       assert.spy(vim.ui.select).was.called()
  --     end)

  --     it('should notify if no schemas are found', function()
  --       vim.notify = spy.new(function() end)
  --       schemas_view.select_schema({}, function() end)
  --       assert.spy(vim.notify).was.called_with('No schemas found', vim.log.levels.INFO)
  --     end)
  --   end)

  --   describe('get_schema_type()', function()
  --     it('should call vim.ui.select', function()
  --       vim.ui.select = spy.new(function() end)
  --       schemas_view.get_schema_type(function() end)
  --       assert.spy(vim.ui.select).was.called()
  --     end)
  --   end)

  --   describe('get_input_source()', function()
  --     it('should call vim.ui.select', function()
  --       vim.ui.select = spy.new(function() end)
  --       schemas_view.get_input_source(function() end)
  --       assert.spy(vim.ui.select).was.called()
  --     end)
  --   end)

  --   describe('get_url()', function()
  --     it('should call ui.floating_input', function()
  --       ui.floating_input = spy.new(function() end)
  --       schemas_view.get_url(function() end)
  --       assert.spy(ui.floating_input).was.called()
  --     end)
  --   end)

  --   describe('get_schema_name()', function()
  --     it('should call ui.floating_input', function()
  --       ui.floating_input = spy.new(function() end)
  --       schemas_view.get_schema_name(function() end)
  --       assert.spy(ui.floating_input).was.called()
  --     end)
  --   end)

  --   describe('get_schema_format()', function()
  --     it('should call ui.floating_confirm', function()
  --       ui.floating_confirm = spy.new(function() end)
  --       schemas_view.get_schema_format(function() end)
  --       assert.spy(ui.floating_confirm).was.called()
  --     end)
  --   end)

  --   describe('get_alias()', function()
  --     it('should call ui.floating_input', function()
  --       ui.floating_input = spy.new(function() end)
  --       schemas_view.get_alias(nil, function() end)
  --       assert.spy(ui.floating_input).was.called()
  --     end)
  --   end)

  --   describe('confirm_delete_alias()', function()
  --     it('should call ui.floating_confirm', function()
  --       ui.floating_confirm = spy.new(function() end)
  --       schemas_view.confirm_delete_alias('test', function() end)
  --       assert.spy(ui.floating_confirm).was.called()
  --     end)
  --   end)
  -- end)

==============================================================================
tests/spec/ui/views/templates_view_spec.lua
==============================================================================
  -- require('spec_helper')

  -- describe('llm.ui.views.templates_view', function()
  --   local templates_view = require('llm.ui.views.templates_view')

  --   before_each(function()
  --     vim.ui = {}
  --   end)

  --   describe('select_template()', function()
  --     it('should call vim.ui.select with sorted templates', function()
  --       vim.ui.select = spy.new(function() end)
  --       local templates = {
  --         { name = 'b', description = 'desc b' },
  --         { name = 'a', description = 'desc a' }
  --       }
  --       local callback = function() end

  --       templates_view.select_template(templates, callback)

  --       assert.spy(vim.ui.select).was.called()
  --     end)

  --     it('should notify if no templates are found', function()
  --       vim.notify = spy.new(function() end)
  --       templates_view.select_template({}, function() end)
  --       assert.spy(vim.notify).was.called_with('No templates found', vim.log.levels.INFO)
  --     end)
  --   end)

  --   describe('get_user_input()', function()
  --     it('should call ui.floating_input', function()
  --       local ui = require('llm.core.utils.ui')
  --       ui.floating_input = spy.new(function() end)
  --       templates_view.get_user_input('prompt', 'default', function() end)
  --       assert.spy(ui.floating_input).was.called()
  --     end)
  --   end)

  --   describe('get_input_source()', function()
  --     it('should call vim.ui.select', function()
  --       vim.ui.select = spy.new(function() end)
  --       templates_view.get_input_source(function() end)
  --       assert.spy(vim.ui.select).was.called()
  --     end)
  --   end)

  --   describe('get_template_type()', function()
  --     it('should call vim.ui.select', function()
  --       vim.ui.select = spy.new(function() end)
  --       templates_view.get_template_type(function() end)
  --       assert.spy(vim.ui.select).was.called()
  --     end)
  --   end)

  --   describe('get_model_choice()', function()
  --     it('should call vim.ui.select', function()
  --       vim.ui.select = spy.new(function() end)
  --       templates_view.get_model_choice(function() end)
  --       assert.spy(vim.ui.select).was.called()
  --     end)
  --   end)

  --   describe('select_model()', function()
  --     it('should call vim.ui.select', function()
  --       vim.ui.select = spy.new(function() end)
  --       templates_view.select_model({}, function() end)
  --       assert.spy(vim.ui.select).was.called()
  --     end)
  --   end)

  --   describe('get_fragment_choice()', function()
  --     it('should call vim.ui.select', function()
  --       vim.ui.select = spy.new(function() end)
  --       templates_view.get_fragment_choice(function() end)
  --       assert.spy(vim.ui.select).was.called()
  --     end)
  --   end)

  --   describe('get_add_fragment_choice()', function()
  --     it('should call vim.ui.select', function()
  --       vim.ui.select = spy.new(function() end)
  --       templates_view.get_add_fragment_choice(function() end)
  --       assert.spy(vim.ui.select).was.called()
  --     end)
  --   end)

  --   describe('get_add_system_fragment_choice()', function()
  --     it('should call vim.ui.select', function()
  --       vim.ui.select = spy.new(function() end)
  --       templates_view.get_add_system_fragment_choice(function() end)
  --       assert.spy(vim.ui.select).was.called()
  --     end)
  --   end)

  --   describe('get_option_choice()', function()
  --     it('should call vim.ui.select', function()
  --       vim.ui.select = spy.new(function() end)
  --       templates_view.get_option_choice(function() end)
  --       assert.spy(vim.ui.select).was.called()
  --     end)
  --   end)

  --   describe('confirm_extract()', function()
  --     it('should call ui.floating_confirm', function()
  --       local ui = require('llm.core.utils.ui')
  --       ui.floating_confirm = spy.new(function() end)
  --       templates_view.confirm_extract(function() end)
  --       assert.spy(ui.floating_confirm).was.called()
  --     end)
  --   end)

  --   describe('get_schema_choice()', function()
  --     it('should call vim.ui.select', function()
  --       vim.ui.select = spy.new(function() end)
  --       templates_view.get_schema_choice(function() end)
  --       assert.spy(vim.ui.select).was.called()
  --     end)
  --   end)

  --   describe('select_schema()', function()
  --     it('should call vim.ui.select', function()
  --       vim.ui.select = spy.new(function() end)
  --       templates_view.select_schema({ { name = 'a' } }, function() end)
  --       assert.spy(vim.ui.select).was.called()
  --     end)

  --     it('should notify if no schemas are found', function()
  --       vim.notify = spy.new(function() end)
  --       templates_view.select_schema({}, function() end)
  --       assert.spy(vim.notify).was.called_with('No schemas found', vim.log.levels.INFO)
  --     end)
  --   end)

  --   describe('confirm_delete()', function()
  --     it('should call ui.floating_confirm', function()
  --       local ui = require('llm.core.utils.ui')
  --       ui.floating_confirm = spy.new(function() end)
  --       templates_view.confirm_delete('test', function() end)
  --       assert.spy(ui.floating_confirm).was.called()
  --     end)
  --   end)
  -- end)

==============================================================================
plugin/llm.lua
==============================================================================
  -- llm.lua - Neovim plugin for simonw/llm
  -- Maintainer: julwrites
  -- Version: 0.1
  -- License: Apache 2.0

  -- Prevent loading twice
* if vim.g.loaded_llm == 1 then
0   return
  end
* vim.g.loaded_llm = 1

* local shell = require('llm.core.utils.shell')

  -- Load the main module from lua/llm/init.lua
  -- This is the primary entry point for the plugin's Lua code.
  -- Plugin managers ensure the 'lua/' directory is in runtimepath before this.
* local ok, llm = pcall(require, "llm")
* if not ok then
    -- If the main module fails to load, notify the user and stop.
    -- The error message from the require will provide details.
0   if not vim.env.LLM_NVIM_TEST then
0     if not shell.check_llm_installed() then
0       vim.notify(
0         "llm CLI not found.\n" ..
0         "Install with: pip install llm or brew install llm\n" ..
          "If already installed, ensure it's in your PATH or set g:llm_executable_path",
0         vim.log.levels.ERROR
        )
      else
0       vim.notify("Failed to load llm module: " .. (llm or "unknown error"), vim.log.levels.ERROR)
      end
    end
0   return
  end
* local config = require("llm.config") -- Load config module

  -- Handler function for manually updating the LLM CLI
  local function manual_cli_update()
0   vim.notify("Starting LLM CLI update... Output will stream to a new buffer.", vim.log.levels.INFO)
0   vim.cmd('vnew')
0   local bufnr = vim.api.nvim_get_current_buf()
0   vim.api.nvim_buf_set_name(bufnr, "LLM CLI Update Log - " .. os.time())
0   vim.api.nvim_buf_set_option(bufnr, 'buftype', 'nofile')
0   vim.api.nvim_buf_set_option(bufnr, 'bufhidden', 'wipe')
0   vim.api.nvim_buf_set_option(bufnr, 'swapfile', false)
0   vim.api.nvim_buf_set_lines(bufnr, 0, -1, false, { "LLM CLI Update Log", "", "Please wait..." })
0   vim.defer_fn(function()
0     shell.update_llm_cli(bufnr)
0   end, 100)
  end

  -- Command handler registry
* local command_handlers = {
*   file = function(prompt, is_range) require('llm.commands').prompt_with_current_file(prompt, nil, nil) end,
    selection = function(prompt, is_range)
0     require('llm.commands').prompt_with_selection(prompt, nil, is_range, nil)
    end,
*   explain = function() require('llm.commands').explain_code(nil, nil) end,
*   schema = function() require('llm.managers.schemas_manager').select_schema() end,
*   template = function() require('llm.managers.templates_manager').select_template() end,
*   fragments = function() llm.interactive_prompt_with_fragments() end,
*   update = manual_cli_update
  }

  -- Main LLM command with subcommands
  -- Usage: :LLM [subcommand] [prompt]
  -- Subcommands: file, selection, explain, schema, template, fragments, update
* vim.api.nvim_create_user_command("LLM", function(opts)
*   if not opts.args or opts.args == "" then
*     require('llm.chat').start_chat()
*     return
    end

*   local args = vim.split(opts.args, "%s+")
*   local subcmd = args[1]
*   local handler = command_handlers[subcmd]

*   if handler then
0     handler(table.concat(args, " ", 2), opts.range > 0)
    else
*     require('llm.commands').prompt(opts.args)
    end
* end, {
*   nargs = "*",
*   range = true,
*   desc = "Execute an LLM subcommand",
    complete = function(ArgLead, CmdLine, CursorPos)
0     local args = vim.split(CmdLine, "%s+")

      -- If we're completing the first argument after LLM
0     if #args == 2 then
0       return {
          "file",      -- :LLM file
          "selection", -- :LLM selection
          "explain",   -- :LLM explain
          "schema",    -- :LLM schema
          "template",  -- :LLM template
          "fragments", -- :LLM fragments
          "update"     -- :LLM update
        }
      end

0     return {}
    end
  })

  -- Command to start an LLM chat session or send a prompt to chat
  -- Usage: :LLMChat [prompt]
* vim.api.nvim_create_user_command('LLMChat', function(opts)
0   local chat = require('llm.chat').start_chat()

0   if opts.args and opts.args ~= "" then
      -- Pre-fill the input area with the prompt
0     chat.buffer:set_input(opts.args)
      -- Switch to the buffer before sending
0     vim.api.nvim_set_current_buf(chat.buffer:get_bufnr())
      -- Send the message using the module function (it will access the session from buffer variable)
0     require('llm.chat').send_message()
      -- Ensure we're in normal mode after sending
0     vim.cmd('stopinsert')
    end
* end, {
*   nargs = "*", -- Allow optional prompt argument
*   desc = "Start an LLM chat session or send a prompt to chat",
  })

  -- Command to open the LLM configuration manager
  -- Usage: :LLMConfig [view] where view is one of: models, plugins, keys, fragments, templates, schemas
* vim.api.nvim_create_user_command('LLMConfig', function(opts)
0   require('llm.commands').dispatch_command('toggle', opts.fargs[1])
* end, {
*   nargs = '?',
    complete = function()
0     return { "Models", "Plugins", "Keys", "Fragments", "Templates", "Schemas" }
    end
* })

==============================================================================
lua/llm/errors.lua
==============================================================================
  -- llm/errors.lua - Centralized error handling system
  -- License: Apache 2.0

* local M = {}
* local config = require('llm.config')
* local notify_util = require('llm.core.utils.notify')

  -- Error severity levels
* M.levels = {
*   INFO = 1,
*   WARNING = 2,
*   ERROR = 3,
*   CRITICAL = 4
* }

  -- Error categories
* M.categories = {
*   CONFIG = 'config',
*   MODEL = 'model',
*   PLUGIN = 'plugin',
*   KEY = 'key',
*   FRAGMENT = 'fragment',
*   TEMPLATE = 'template',
*   SCHEMA = 'schema',
*   INTERNAL = 'internal',
*   SHELL = 'shell'
* }

  -- Format error message
  local function format_message(category, message, details)
*   return string.format('[%s] %s%s',
*     category:upper(),
*     message,
*     details and ' | '..vim.inspect(details) or '')
  end

  -- Handle and report error
* function M.handle(category, message, details, severity, notify_fn)
*   local notify = notify_fn or vim.notify
*   severity = severity or M.levels.ERROR
*   category = category or M.categories.INTERNAL

*   local formatted = format_message(category, message, details)

    -- Log based on severity
*   if severity >= M.levels.ERROR then
*     notify(formatted, vim.log.levels.ERROR)
0   elseif severity == M.levels.WARNING then
0     notify(formatted, vim.log.levels.WARN)
    else
0     notify(formatted, vim.log.levels.INFO)
    end

    -- Return structured error for programmatic handling
*   return {
*     category = category,
*     message = message,
*     details = details,
*     severity = severity,
*     formatted = formatted
*   }
  end

  -- Create error wrappers for common patterns
* function M.wrap(fn, category)
    return function(...)
*     local ok, result = pcall(fn, ...)
*     if not ok then
*       return M.handle(category, result)
      end
*     return result
    end
  end

  -- Shell command specific handler
* function M.shell_error(command, code, stdout, stderr)
*   local output = stdout
*   if stderr and #stderr > 0 then
*     output = output .. "\n" .. stderr
    end
*   return M.handle(
*     'shell',
*     string.format('Command failed: %s (exit code %d)', command, code),
*     output,
*     M.levels.ERROR
*   )
  end

* return M

==============================================================================
lua/llm/facade.lua
==============================================================================
  -- llm/facade.lua - Centralized API surface for llm-nvim
  -- License: Apache 2.0

* local M = {}

  -- Manager registry and cache
* local managers = {
*   models = nil,
*   keys = nil,
*   fragments = nil,
*   templates = nil,
*   schemas = nil,
*   plugins = nil,
*   unified = nil,
  }

* local manager_files = {
*   models = 'llm.managers.models_manager',
*   keys = 'llm.managers.keys_manager',
*   fragments = 'llm.managers.fragments_manager',
*   templates = 'llm.managers.templates_manager',
*   schemas = 'llm.managers.schemas_manager',
*   plugins = 'llm.managers.plugins_manager',
*   unified = 'llm.ui.unified_manager',
  }

  -- Get manager instances with lazy loading
* function M.get_manager(name)
*   if not managers[name] and manager_files[name] then
*     managers[name] = require(manager_files[name])
    end
*   return managers[name]
  end

* if vim.env.NVIM_LLM_TEST then
*   function M._get_managers()
*     return managers
    end
  end

  -- Unified LLM command handler
* function M.command(subcmd, ...)
*   return require('llm.commands').dispatch_command(subcmd, ...)
  end

  -- Prompt functions
* function M.prompt(prompt, fragment_paths)
*   return require('llm.commands').prompt(prompt, fragment_paths)
  end

* function M.prompt_with_selection(prompt, fragment_paths)
*   return require('llm.commands').prompt_with_selection(prompt, fragment_paths)
  end

* function M.prompt_with_current_file(prompt)
*   return require('llm.commands').prompt_with_current_file(prompt)
  end

  -- Unified manager functions
* function M.toggle_unified_manager(initial_view)
*   local unified_manager = M.get_manager('unified')
*   if unified_manager then
*     return unified_manager.toggle(initial_view)
    else
0     error("Failed to load unified manager")
    end
  end

* return M

==============================================================================
lua/llm/chat.lua
==============================================================================
  -- llm/chat.lua - Chat Orchestration
  -- License: Apache 2.0

* local M = {}
* local config = require('llm.config')
* local ChatSession = require('llm.chat.session').ChatSession
* local ChatBuffer = require('llm.chat.buffer').ChatBuffer

  -- Track active chat sessions by buffer number
* local active_sessions = {}

  --- Start a new chat session
  -- @param opts table: Chat options
  --   - model: string (optional) - Model to use
  --   - system_prompt: string (optional) - System prompt
  --   - fragments: table (optional) - List of fragment paths
  -- @return table: { session, buffer }
* function M.start_chat(opts)
*   opts = opts or {}

    -- Create session
*   local session = ChatSession.new({
*     model = opts.model,
*     system_prompt = opts.system_prompt,
*     fragments = opts.fragments,
    })

    -- Create buffer
*   local buffer = ChatBuffer.new({
*     model = opts.model or config.get("model"),
*     system_prompt = opts.system_prompt or config.get("system_prompt"),
    })

    -- Link session to buffer
*   session.bufnr = buffer:get_bufnr()

    -- Store session for later access (keep table with metatables intact)
*   active_sessions[buffer:get_bufnr()] = {
*     session = session,
*     buffer = buffer,
*   }

    -- Store reference in buffer variable for keymap access
    -- Note: Store the active_sessions reference, not a copy
*   vim.b[buffer:get_bufnr()].llm_chat_bufnr = buffer:get_bufnr()

*   if config.get('debug') then
0     vim.notify(
0       string.format("[Chat] Started new chat session in buffer %d", buffer:get_bufnr()),
0       vim.log.levels.DEBUG
      )
    end

*   return {
*     session = session,
*     buffer = buffer,
*   }
  end

  --- Send message from current buffer
  -- Called by keymap (<C-CR> or <Leader>s)
* function M.send_message()
*   local bufnr = vim.api.nvim_get_current_buf()

    -- Get chat data from active_sessions using buffer number
*   local chat_bufnr = vim.b[bufnr].llm_chat_bufnr
*   if not chat_bufnr then
*     vim.notify("Not a chat buffer", vim.log.levels.ERROR)
*     return
    end

*   local chat_data = active_sessions[chat_bufnr]
*   if not chat_data then
0     vim.notify("Chat session not found", vim.log.levels.ERROR)
0     return
    end

*   local session = chat_data.session
*   local buffer = chat_data.buffer

    -- Check if session is ready
*   if not session:is_ready() then
*     vim.notify("Chat is processing, please wait", vim.log.levels.WARN)
*     return
    end

    -- Get user input
*   local prompt = buffer:get_user_input()

*   if not prompt or prompt == "" then
*     vim.notify("Cannot send empty message", vim.log.levels.WARN)
*     return
    end

    -- Switch to normal mode if in insert mode
*   if vim.fn.mode() == 'i' then
0     vim.cmd('stopinsert')
    end

    -- Update status
*   buffer:set_status("Processing...")

    -- Add user message to history
*   buffer:append_user_message(prompt)

    -- Clear input area
*   buffer:clear_input()

    -- Send prompt to LLM
*   local job_id = session:send_prompt(prompt, {
      on_stdout = function(_, data)
0       if data then
0         for _, line in ipairs(data) do
            -- Skip conversation ID lines (they'll be extracted by session)
0           if not line:match("^Conversation ID:") then
0             buffer:append_llm_message(line .. "\n")
            end
          end
        end
      end,

      on_stderr = function(_, data)
0       if data then
0         for _, line in ipairs(data) do
0           vim.notify("LLM error: " .. line, vim.log.levels.ERROR)
          end
        end
      end,

      on_exit = function(_, exit_code)
0       if exit_code == 0 then
0         buffer:set_status("Ready")

          -- Update conversation ID in buffer if this was first message
0         local conv_id = session:get_conversation_id()
0         if conv_id then
0           buffer:update_conversation_id(conv_id)
          end

          -- Add blank line after LLM response
0         buffer:append_llm_message("")

          -- Focus input for next message
0         buffer:focus_input()

0         if config.get('debug') then
0           vim.notify(
0             string.format("[Chat] Message completed (conversation: %s)", conv_id or "unknown"),
0             vim.log.levels.DEBUG
            )
          end
        else
0         buffer:set_status("Error")
0         vim.notify(
0           string.format("LLM command failed with exit code: %d", exit_code),
0           vim.log.levels.ERROR
          )
        end
      end,
    })

*   if not job_id then
0     buffer:set_status("Error")
0     vim.notify("Failed to start LLM command", vim.log.levels.ERROR)
    else
*     if config.get('debug') then
0       vim.notify(
0         string.format("[Chat] Started job %d for message", job_id),
0         vim.log.levels.DEBUG
        )
      end
    end
  end

  --- Start a new message in the input area
  -- Called by keymap (<C-n>)
* function M.new_message()
*   local bufnr = vim.api.nvim_get_current_buf()
*   local chat_data = vim.b[bufnr].llm_chat_session

*   if not chat_data then
*     vim.notify("Not a chat buffer", vim.log.levels.ERROR)
*     return
    end

*   local buffer = chat_data.buffer

    -- Clear input and focus
*   buffer:clear_input()
*   buffer:focus_input()

*   if config.get('debug') then
0     vim.notify("[Chat] Cleared input for new message", vim.log.levels.DEBUG)
    end
  end

  --- Get active session for a buffer
  -- @param bufnr number: Buffer number
  -- @return table|nil: Chat session data or nil
* function M.get_session(bufnr)
*   return active_sessions[bufnr]
  end

  --- Stop current job in active chat buffer
* function M.stop_current_job()
*   local bufnr = vim.api.nvim_get_current_buf()
*   local chat_data = vim.b[bufnr].llm_chat_session

*   if not chat_data then
*     vim.notify("Not a chat buffer", vim.log.levels.ERROR)
*     return
    end

*   local session = chat_data.session
*   session:stop_current_job()

*   local buffer = chat_data.buffer
*   buffer:set_status("Stopped")

*   vim.notify("Stopped current LLM job", vim.log.levels.INFO)
  end

  --- Clean up session when buffer is deleted
  -- Set up autocmd to clean up when chat buffer is closed
* vim.api.nvim_create_autocmd("BufDelete", {
    callback = function(args)
0     local bufnr = args.buf
0     if active_sessions[bufnr] then
        -- Stop any running jobs
0       local session = active_sessions[bufnr].session
0       if session.current_job_id then
0         session:stop_current_job()
        end

        -- Remove from active sessions
0       active_sessions[bufnr] = nil

0       if config.get('debug') then
0         vim.notify(
0           string.format("[Chat] Cleaned up session for buffer %d", bufnr),
0           vim.log.levels.DEBUG
          )
        end
      end
    end,
  })

* return M

==============================================================================
lua/llm/commands.lua
==============================================================================
  -- llm/commands.lua - Command execution for llm-nvim
  -- License: Apache 2.0

* local M = {}

  -- Forward declarations
* local nvim_api = vim.api
* local api = require('llm.api')
* local config = require('llm.config')
* local ui = require('llm.core.utils.ui')
* local text = require('llm.core.utils.text')
* local shell = require('llm.core.utils.shell')
* local llm_cli = require('llm.core.data.llm_cli')
* local job = require('llm.core.utils.job')

  ---------------------
  -- Helper Functions
  ---------------------

  -- Get the configured llm executable path
* function M.get_llm_executable_path()
*   return config.get("llm_executable_path")
  end

  -- Get the model argument if specified
* function M.get_model_arg()
*   local model = config.get("model")
*   if model and model ~= "" then
      -- Return as a table element for later concatenation
*     return { "-m", model }
    end
0   return {} -- Return empty table if no model
  end

  -- Get the system prompt argument if specified
* function M.get_system_arg()
*   local system = config.get("system_prompt")
*   if system and system ~= "" then
      -- Return as a table element for later concatenation
*     return { "-s", system }
    end
0   return {} -- Return empty table if no system prompt
  end

  -- Get fragment arguments if specified
* function M.get_fragment_args(fragment_list)
*   if not fragment_list or #fragment_list == 0 then
*     return {} -- Return empty table if no fragments
    end

0   local args = {}
0   for _, fragment in ipairs(fragment_list) do
      -- Add '-f' and the fragment as separate elements
0     table.insert(args, "-f")
0     table.insert(args, fragment)

      -- Debug output
0     local config = require('llm.config')
0     if config.get('debug') then
0       vim.notify("Adding fragment: " .. fragment, vim.log.levels.DEBUG)
      end
    end

0   return args -- Return the table directly
  end

  -- Get system fragment arguments if specified
* function M.get_system_fragment_args(fragment_list)
0   if not fragment_list or #fragment_list == 0 then
0     return {} -- Return empty table if no fragments
    end

0   local args = {}
0   for _, fragment in ipairs(fragment_list) do
      -- Add '--system-fragment' and the fragment as separate elements
0     table.insert(args, "--system-fragment")
0     table.insert(args, fragment)
    end

0   return args -- Return the table directly
  end

  -- Run an llm command and return the result

* function M.get_pre_response_message(source, prompt, fragment_paths)
0   local message_parts = {}

0   table.insert(message_parts, "Passing your prompt to llm tool")
0   table.insert(message_parts, " ")
0   table.insert(message_parts, "---")
0   table.insert(message_parts, " ")
0   table.insert(message_parts, "Prompt: " .. prompt)
0   table.insert(message_parts, "Source: " .. source)
0   if fragment_paths and #fragment_paths > 0 then
0     table.insert(message_parts, "Fragments: " .. table.concat(fragment_paths, ", "))
    end
0   table.insert(message_parts, " ")
0   table.insert(message_parts, "---")
0   table.insert(message_parts, " ")
0   table.insert(message_parts, "Processing, please wait...")
0   table.insert(message_parts, " ")
0   table.insert(message_parts, "(Note that results will be written to this buffer)")

0   return table.concat(message_parts, "\n")
  end

* function M.write_context_to_temp_file(context)
0   local temp_file = os.tmpname()
0   local file = io.open(temp_file, "w")
0   if not file then
0     api.nvim_err_writeln("Failed to create temporary file")
0     return ""
    end

0   file:write(context)
0   file:close()

0   return temp_file
  end

* function M.create_response_buffer(content)
0   ui.create_buffer_with_content(content, "LLM Response", "markdown")
  end

* function M.fill_response_buffer(bufnr, content)
0   ui.replace_buffer_with_content(content, bufnr, "markdown")
0   vim.cmd("redraw")
  end

  -- Helper function to select an existing fragment alias
  local function select_existing_fragment(callback)
0   local fragments_manager = require('llm.managers.fragments_manager')
0   local existing_fragments = fragments_manager.get_fragments() -- Get fragments with aliases

0   if not existing_fragments or #existing_fragments == 0 then
0     vim.notify("No existing fragments with aliases found.", vim.log.levels.WARN)
0     callback(nil) -- Indicate no selection
0     return
    end

0   local items = {}
0   local fragment_map = {}
0   for i, frag in ipairs(existing_fragments) do
0     local display_name = (#frag.aliases > 0 and frag.aliases[1] or frag.hash:sub(1, 8)) ..
0         " (" .. (frag.source or "hash") .. ")"
0     table.insert(items, display_name)
0     fragment_map[i] = (#frag.aliases > 0 and frag.aliases[1] or frag.hash) -- Store identifier (prefer alias)
    end

0   vim.ui.select(items, {
      prompt = "Select an existing fragment:",
0     format_item = function(item) return item end
    }, function(choice, idx)
0     if not choice then
0       callback(nil)
0       return
      end
0     local identifier = fragment_map[idx]
0     callback(identifier)
    end)
  end

  ---------------------
  -- LLM Prompt Commands
  ---------------------

  -- Unified command dispatcher
* function M.dispatch_command(subcmd, ...)
0   local args = { ... }
0   local success, err = pcall(function()
0     if subcmd == "selection" then
0       return M.prompt_with_selection(args[1] or "", args[2] or {})
0     elseif subcmd == "toggle" then
0       local unified_manager = require('llm.ui.unified_manager')
0       return unified_manager.toggle(args[1] or "")
0     elseif subcmd == "" then
0       return ui.create_prompt_buffer()
      else
        -- Default case: treat as direct prompt
0       return M.prompt(subcmd, args[1] or {})
      end
    end)

0   if not success then
0     vim.notify("Error dispatching command: " .. tostring(err), vim.log.levels.ERROR)
    end
  end

  -- Send a prompt to llm
* function M.prompt(prompt, fragment_paths, bufnr)
*   local llm_executable_path = config.get("llm_executable_path")
*   local model = config.get("model")
*   local system_prompt = config.get("system_prompt")

*   local cmd_parts = { llm_executable_path }

*   if model and model ~= "" then
*     table.insert(cmd_parts, "-m")
*     table.insert(cmd_parts, model)
    end

*   if system_prompt and system_prompt ~= "" then
*     table.insert(cmd_parts, "-s")
*     table.insert(cmd_parts, system_prompt)
    end

*   if fragment_paths then
*     for _, fragment in ipairs(fragment_paths) do
0       table.insert(cmd_parts, "-f")
0       table.insert(cmd_parts, fragment)
      end
    end

*   local target_bufnr = bufnr
*   if not target_bufnr then
*     vim.cmd('vnew')
*     target_bufnr = vim.api.nvim_get_current_buf()
*     local buffer_name = "LLM Response - " .. os.time()
*     vim.api.nvim_buf_set_name(target_bufnr, buffer_name)
*     vim.api.nvim_buf_set_option(target_bufnr, 'filetype', 'markdown')
*     vim.api.nvim_buf_set_lines(target_bufnr, 0, -1, false, { "Waiting for response..." })
    end

*   local callbacks = {
      on_stdout = function(_, data)
*       if data then
*         for _, line in ipairs(data) do
*           ui.append_to_buffer(target_bufnr, line .. "\n", "LlmModelResponse")
          end
        end
      end,
    }

*   api.run_streaming_command(cmd_parts, prompt, callbacks)
  end



  -- Explain the current buffer or selection
* function M.explain_code(fragment_paths, bufnr)
0   M.prompt_with_current_file("Explain this code", fragment_paths, bufnr)
  end

* function M.prompt_with_current_file(prompt, fragment_paths, bufnr)
*   local filepath = vim.fn.expand('%:p')
*   if filepath == "" then
0     vim.notify("Current buffer has no file path", vim.log.levels.ERROR)
0     return
    end

*   local cmd_parts = { M.get_llm_executable_path() }

    -- Add model and system args
*   vim.list_extend(cmd_parts, M.get_model_arg())
*   vim.list_extend(cmd_parts, M.get_system_arg())

    -- Add user-specified fragments
*   if fragment_paths then
*     vim.list_extend(cmd_parts, M.get_fragment_args(fragment_paths))
    end

    -- Add the current file as a fragment
*   table.insert(cmd_parts, "-f")
*   table.insert(cmd_parts, filepath)

*   local target_bufnr = bufnr
*   if not target_bufnr then
0     vim.cmd('vnew')
0     target_bufnr = vim.api.nvim_get_current_buf()
0     local buffer_name = "LLM Response - " .. os.time()
0     vim.api.nvim_buf_set_name(target_bufnr, buffer_name)
0     vim.api.nvim_buf_set_option(target_bufnr, 'filetype', 'markdown')
0     vim.api.nvim_buf_set_lines(target_bufnr, 0, -1, false, { "Waiting for response..." })
    end

*   local callbacks = {
      on_stdout = function(_, data)
*       if data then
*         for _, line in ipairs(data) do
*           ui.append_to_buffer(target_bufnr, line .. "\n", "LlmModelResponse")
          end
        end
      end,
    }

*   api.run_streaming_command(cmd_parts, prompt, callbacks)
  end



  -- Send selected text with a prompt to llm
* function M.prompt_with_selection(prompt, fragment_paths, from_visual_mode, bufnr)
    local selection
*   if from_visual_mode then
*     selection = text.get_visual_selection()
    else
0     selection = vim.nvim_get_current_line()
    end

*   if selection == "" then
0     vim.notify("No text selected", vim.log.levels.WARN)
0     return
    end

*   local temp_file = M.write_context_to_temp_file(selection)

*   local cmd_parts = { M.get_llm_executable_path() }
*   vim.list_extend(cmd_parts, M.get_model_arg())
*   vim.list_extend(cmd_parts, M.get_system_arg())
*   if fragment_paths then
*     vim.list_extend(cmd_parts, M.get_fragment_args(fragment_paths))
    end
*   table.insert(cmd_parts, "-f")
*   table.insert(cmd_parts, temp_file)
*   local target_bufnr = bufnr
*   if not target_bufnr then
0     vim.cmd('vnew')
0     target_bufnr = vim.api.nvim_get_current_buf()
0     local buffer_name = "LLM Response - " .. os.time()
0     vim.api.nvim_buf_set_name(target_bufnr, buffer_name)
0     vim.api.nvim_buf_set_option(target_bufnr, 'filetype', 'markdown')
0     vim.api.nvim_buf_set_lines(target_bufnr, 0, -1, false, { "Waiting for response..." })
    end

*   local callbacks = {
      on_stdout = function(_, data)
0       if data then
0         for _, line in ipairs(data) do
0           ui.append_to_buffer(target_bufnr, line .. "\n", "LlmModelResponse")
          end
        end
      end,
      on_exit = function()
*       vim.notify("LLM command finished.")
        -- Clean up the temporary file
*       os.remove(temp_file)
      end,
    }

*   api.run_streaming_command(cmd_parts, prompt, callbacks)
  end


  ---------------------
  -- Interactive Commands
  ---------------------

  -- Interactive prompt allowing selection of multiple fragments
  -- NOTE: This function is not fully tested due to the complexity of mocking the interactive UI.
* function M.interactive_prompt_with_fragments(opts)
0   opts = opts or {}
0   local fragments_manager = require('llm.managers.fragments_manager') -- Load here to avoid circular dependency issues at top level
0   local fragments_list = {}
    local visual_selection_text = nil
    local visual_selection_temp_file = nil

    -- Check for visual selection
0   if opts.range and opts.range > 0 then
0     visual_selection_text = text.get_visual_selection()
0     if visual_selection_text and visual_selection_text ~= "" then
        -- Save selection to a temporary file to treat it like a fragment source
0       visual_selection_temp_file = os.tmpname()
0       local file = io.open(visual_selection_temp_file, "w")
0       if file then
0         file:write(visual_selection_text)
0         file:close()
0         table.insert(fragments_list, visual_selection_temp_file)
0         vim.notify("Added visual selection as fragment source.", vim.log.levels.INFO)
        else
0         vim.notify("Failed to create temporary file for visual selection.", vim.log.levels.ERROR)
0         visual_selection_temp_file = nil -- Ensure it's nil if creation failed
        end
      else
0       visual_selection_text = nil -- Reset if selection was empty
      end
    end

    local function add_more_fragments()
0     local options = {
        "Select existing fragment (alias/hash)",
        "Select file as fragment",
        "Enter fragment path/URL",
        "Use GitHub repository",
        "Done - continue with prompt"
      }

0     vim.ui.select(options, {
0       prompt = "Add fragments to prompt (" .. #fragments_list .. " added):"
      }, function(choice)
0       if not choice then return end -- User cancelled selection loop

        local function handle_fragment_added(identifier)
0         if identifier then
            -- Avoid adding duplicates
0           local found = false
0           for _, existing in ipairs(fragments_list) do
0             if existing == identifier then
0               found = true
                break
              end
            end
0           if not found then
0             table.insert(fragments_list, identifier)
0             vim.notify("Added fragment: " .. identifier, vim.log.levels.INFO)
            else
0             vim.notify("Fragment already added: " .. identifier, vim.log.levels.WARN)
            end
          end
0         vim.schedule(add_more_fragments) -- Continue the loop
        end

0       if choice == "Select existing fragment (alias/hash)" then
0         select_existing_fragment(handle_fragment_added)
0       elseif choice == "Select file as fragment" then
0         fragments_manager.add_file_fragment(nil)
0       elseif choice == "Enter fragment path/URL" then
0         vim.ui.input({ prompt = "Enter fragment path/URL: " }, function(input)
0           if input and input ~= "" then
0             handle_fragment_added(input)
            else
0             add_more_fragments() -- Re-prompt if input is empty
            end
          end)
0       elseif choice == "Use GitHub repository" then
0         fragments_manager.add_github_fragment_from_manager(nil)
0       elseif choice == "Done - continue with prompt" then
0         if #fragments_list == 0 then
0           vim.notify("No fragments selected.", vim.log.levels.WARN)
0           return -- Exit if no fragments
          end

          -- Now ask for the prompt
0         vim.ui.input({
0           prompt = "Enter prompt: "
          }, function(input_prompt)
0           if not input_prompt or input_prompt == "" then
0             vim.notify("Prompt cannot be empty.", vim.log.levels.ERROR)
              -- Clean up temp file if prompt is cancelled
0             if visual_selection_temp_file then os.remove(visual_selection_temp_file) end
0             return
            end

            -- Decide which command to call based on whether visual selection was the *only* input
            -- Note: We currently always use M.prompt and pass the temp file path if visual selection was used.
            -- A potential enhancement is to detect if *only* the visual selection temp file is present
            -- and call M.prompt_with_selection directly with the text, but this adds complexity.
            -- For now, using the temp file path in M.prompt is simpler.

0           M.prompt(input_prompt, fragments_list)

            -- Clean up temp file *after* the command runs (or is supposed to run)
            -- Using defer_fn to ensure it runs after the current execution context
0           if visual_selection_temp_file then
0             vim.defer_fn(function() os.remove(visual_selection_temp_file) end, 100)
            end
          end)
        else
0         add_more_fragments() -- Should not happen, but ensures loop continues
        end
      end)
    end

    -- Start the fragment selection loop
0   add_more_fragments()
  end

  -- Test function to verify terminal creation
* function M.test_terminal_creation()
0   vim.notify("Testing terminal creation...", vim.log.levels.INFO)
0   vim.cmd('new')
0   local buf = vim.api.nvim_get_current_buf()
0   vim.notify("Created buffer: " .. buf, vim.log.levels.INFO)

0   local cmd = "echo 'Test terminal'"
0   vim.notify("Executing: terminal " .. cmd, vim.log.levels.INFO)
0   vim.cmd('terminal ' .. cmd)

0   local term_buf = vim.api.nvim_get_current_buf()
0   vim.notify("Terminal buffer: " .. term_buf, vim.log.levels.INFO)
0   local buf_type = vim.api.nvim_buf_get_option(term_buf, 'buftype')
0   vim.notify("Buffer type: " .. buf_type, vim.log.levels.INFO)

0   vim.cmd('startinsert')
  end

* return M

==============================================================================
lua/llm/config.lua
==============================================================================
  -- llm/config.lua - Centralized Configuration Management
  -- License: Apache 2.0

* local M = {}
* local listeners = {}
* local validate = require('llm.core.utils.validate')

  -- Default configuration with metadata
* M.defaults = {
*   model = {
*     default = nil,
*     type = "string",
*     desc = "Default model to use (falls back to llm CLI default)"
*   },
*   system_prompt = {
*     default = "You are a helpful assistant.",
*     type = "string",
*     desc = "Default system prompt for all queries"
*   },
*   no_mappings = {
*     default = false,
*     type = "boolean",
*     desc = "Disable default key mappings"
*   },
*   debug = {
*     default = false,
*     type = "boolean",
*     desc = "Enable debug logging"
*   },
*   auto_update_cli = {
*     default = false,
*     type = "boolean",
*     desc = "Enable or disable auto-updates for the LLM CLI"
*   },
*   auto_update_interval_days = {
*     default = 7,
*     type = "number",
*     desc = "Interval in days for checking for updates"
*   },
*   llm_executable_path = {
*     default = "llm",
*     type = "string",
*     desc = "Path to the llm executable (e.g., 'llm' or '/usr/local/bin/llm')"
*   },
    -- Add more config options here
* }

  -- Current configuration
* M.options = {}

  -- Validate and normalize configuration
  local function process_config(opts)
*   local processed = {}
*   for k, v in pairs(opts) do
*     if M.defaults[k] then
        -- Type checking
*       if type(v) ~= M.defaults[k].type then
0         v = validate.convert(v, M.defaults[k].type)
        end
        -- Ensure proper structure
*       if type(v) == 'table' and v.value ~= nil then
0         processed[k] = v
        else
*         processed[k] = {value = v}
        end
      else
0       require('llm.errors').handle('config',
0         "Ignoring unknown config option: "..k, nil, 'warning')
      end
    end
*   return processed
  end

  -- Initialize configuration
* function M.setup(opts)
*   opts = opts or {}

    -- Process and validate new config
*   local new_config = process_config(opts)

    -- Merge with defaults
*   M.options = vim.tbl_deep_extend("force", {}, M.defaults, new_config)

    -- Notify listeners
*   for _, listener in ipairs(listeners) do
*     listener(M.options)
    end
  end

  -- Get configuration value(s)
* function M.get(key)
*   if not key then
      -- Return a deepcopy of all *actual* values, not the internal structure
*     local current_values = {}
*     for k_option, _ in pairs(M.options) do
*       current_values[k_option] = M.get(k_option) -- Recursively call M.get for each key
      end
*     return current_values
    end

*   local option_entry = M.options[key]
*   if option_entry == nil then
      -- This case should ideally be caught by M.defaults having all valid keys
      -- or process_config filtering unknown keys.
      -- If an unknown key is passed, returning nil is appropriate.
*     return nil
    end

*   if type(option_entry) == 'table' then
*     if option_entry.value ~= nil then
*       return option_entry.value -- User-set value
*     elseif option_entry.default ~= nil then
*       return option_entry.default -- Default value from M.defaults
      end
    end
    -- This case should ideally not be reached if options are always tables
    -- from M.defaults or {value=...} from user config.
    -- However, returning option_entry directly might be a fallback for unforeseen structures
    -- or if M.options contains direct values not conforming to {value=...} or {default=...}.
    -- For robustness, if it's not a table with 'value' or 'default', but the key exists,
    -- it might be a direct value (though current setup logic aims to wrap these).
    -- If it's a table but doesn't have .value or .default (e.g. just {type="...", desc="..."}),
    -- then it implies no value is set and no default value exists, so nil is appropriate.
*   if type(option_entry) == 'table' and option_entry.value == nil and option_entry.default == nil then
*     return nil -- No user-set value and no default value defined for this key
    end
0   return option_entry -- Fallback for direct values or unexpected structures
  end

  -- Register config change listener
* function M.on_change(fn)
*   table.insert(listeners, fn)
    return function() -- returns unregister function
0     for i, listener in ipairs(listeners) do
0       if listener == fn then
0         table.remove(listeners, i)
          break
        end
      end
    end
  end

  -- Reset to defaults
* function M.reset()
*   local defaults = {}
*   for k, v in pairs(M.defaults) do
*     defaults[k] = v.default
    end
*   M.setup(defaults)
  end

  -- Initialize with empty config
* M.setup({})

* return M

==============================================================================
lua/llm/init.lua
==============================================================================
  -- llm/init.lua - Entry point for lazy.nvim integration
  -- License: Apache 2.0

* local M = {}
* local facade = require('llm.facade')
* local loaders = require('llm.core.loaders')

  -- Setup function for configuration
* function M.setup(opts)
    -- Initialize config first
*   M.config = require('llm.config')
*   M.config.setup(opts or {})

    -- Initialize styles
*   require('llm.ui.styles').setup_highlights()



    -- Load all data
*   loaders.load_all()

    -- Auto-update LLM CLI check
*   local auto_update_cli = M.config.get('auto_update_cli')
*   local auto_update_interval_days = M.config.get('auto_update_interval_days')

*   if auto_update_cli then
*     local shell = require('llm.core.utils.shell')
*     local last_update_ts = shell.get_last_update_timestamp()
*     local current_ts = os.time()
*     local days_since_last_update = (current_ts - last_update_ts) / (60 * 60 * 24)

*     if days_since_last_update >= auto_update_interval_days then
*       vim.notify("LLM-Nvim: Checking for LLM CLI updates...", vim.log.levels.INFO)
*       vim.defer_fn(function()
*         local result = shell.update_llm_cli(nil, M)
*         if result and result.success then
*           vim.notify("LLM CLI auto-update successful.", vim.log.levels.INFO)
0         elseif result then
0           local msg = "LLM CLI auto-update failed."
0           if result.message and string.len(result.message) > 0 then
0             msg = msg .. " Details:\n" .. result.message
               -- Check if notify module is available to use more advanced notification
0             local notify_mod = require('llm.core.utils.notify')
0             if notify_mod and notify_mod.notify then
0               notify_mod.notify(msg, vim.log.levels.WARN, {title = "LLM Auto-Update"})
              else
0               vim.notify(msg, vim.log.levels.WARN)
              end
            else
0             vim.notify(msg, vim.log.levels.WARN)
            end
          else
0           vim.notify("LLM CLI auto-update check failed to run.", vim.log.levels.ERROR)
          end
*       end, 100) -- Short delay to not block startup critical path
      end
    end

    -- Defer the plugin refresh to avoid circular dependencies
*   vim.defer_fn(function()
*     local plugins_manager = require('llm.managers.plugins_manager')
*     plugins_manager.refresh_available_plugins()
*   end, 100)



*   return M
  end

  -- Expose facade functions
* for k, v in pairs(facade) do
*   M[k] = v
  end

  -- Expose functions to global scope for testing purposes only
* if vim.env.LLM_NVIM_TEST then
0   for k, v in pairs(facade) do
0     _G[k] = v
    end
  end

* return M

==============================================================================
lua/llm/api.lua
==============================================================================
  -- llm/api.lua - Public API surface for llm-nvim
  -- License: Apache 2.0

* local M = {}
* local facade = require('llm.facade')
* local config = require('llm.config')
* local job = require('llm.core.utils.job')
* local ui = require('llm.core.utils.ui')


  --- Setup function for plugin configuration
  -- @param opts table: Configuration options table
  -- @return table: The API module
* function M.setup(opts)
0   config.setup(opts)
0   return M
  end

  --- Get current plugin version
  -- @return string: Version string
* function M.version()
0   return require('llm.config').version
  end

  -- Expose all facade functions through API
* for name, fn in pairs(facade) do
    M[name] = function(...)
0     return fn(...)
    end
  end

  --- A unified function for running LLM commands and handling streaming output.
  -- @param command_parts table: The command and its arguments.
  -- @param prompt string: The prompt to send to the command's stdin.
  -- @param callbacks table: A table with on_stdout, on_stderr, and on_exit callbacks.
  -- @return number: The job ID, or nil if the job failed to start.
* function M.run_llm_command(command_parts, prompt, callbacks)
0   local job_instance = job.run({
      command = command_parts,
      on_stdout = callbacks.on_stdout,
      on_stderr = callbacks.on_stderr,
      on_exit = callbacks.on_exit,
    })

0   if job_instance and job_instance.id then
0     vim.fn.jobsend(job_instance.id, prompt)
0     return job_instance.id
    end

0   return nil
  end

* function M.run_streaming_command(command_parts, prompt, callbacks)
*   callbacks = callbacks or {}
*   local job_id = job.run(command_parts, {
*     on_stdout = callbacks.on_stdout,
*     on_stderr = callbacks.on_stderr,
*     on_exit = callbacks.on_exit,
    })

*   if job_id then
*     if prompt and prompt ~= "" then
*       vim.fn.jobsend(job_id, prompt)
      end
*     vim.fn.jobclose(job_id, "stdin")
    end

*   return job_id
  end

  --- Runs an LLM command with streaming output to a specified buffer.
  -- @param cmd_parts table: The command and its arguments as a table.
  -- @param bufnr number: The buffer number to stream output to.
  -- @param opts table: Optional table with additional callbacks (on_stdout, on_stderr, on_exit).
  -- @return number: The job ID if the job started successfully, otherwise nil.
* function M.run_llm_command_streamed(cmd_parts, bufnr, opts)
0   opts = opts or {}
0   local callbacks = {
      on_stdout = function(_, data)
0       if data then
0         for _, line in ipairs(data) do
0           ui.append_to_buffer(bufnr, line .. "\n", "LlmModelResponse")
          end
        end
0       if opts.on_stdout then opts.on_stdout(_, data) end
      end,
      on_stderr = function(_, data)
0       if data then
0         for _, line in ipairs(data) do
0           vim.notify("LLM stderr: " .. line, vim.log.levels.ERROR)
          end
        end
0       if opts.on_stderr then opts.on_stderr(_, data) end
      end,
      on_exit = function(_, exit_code)
0       vim.notify("LLM command finished with exit code: " .. tostring(exit_code), vim.log.levels.INFO)
0       if opts.on_exit then opts.on_exit(_, exit_code) end
      end,
    }

0   return M.run_streaming_command(cmd_parts, nil, callbacks)
  end

  -- Add API documentation metadata
* M.__name = 'llm.api'
* M.__description = 'Public API surface for llm-nvim plugin'

* return M

==============================================================================
lua/llm/chat/session.lua
==============================================================================
  -- llm/chat/session.lua - Chat Session Management
  -- License: Apache 2.0

* local M = {}
* local config = require('llm.config')
* local shell = require('llm.core.utils.shell')

  --- ChatSession class for managing individual chat sessions
  -- @class ChatSession
* local ChatSession = {}
* ChatSession.__index = ChatSession

  --- Create a new chat session
  -- @param opts table: Session options
  --   - model: string (optional) - Model to use
  --   - system_prompt: string (optional) - System prompt
  --   - fragments: table (optional) - List of fragment paths
  --   - bufnr: number (optional) - Associated buffer number
  -- @return ChatSession: New session instance
* function ChatSession.new(opts)
*   opts = opts or {}

*   local session = {
*     conversation_id = nil,  -- Will be set after first response
*     model = opts.model or config.get("model"),
*     system_prompt = opts.system_prompt or config.get("system_prompt"),
*     fragments = opts.fragments or {},
*     bufnr = opts.bufnr,
*     state = 'ready', -- ready, processing, error
*     current_job_id = nil,
    }

*   setmetatable(session, ChatSession)

*   if config.get('debug') then
0     vim.notify(
0       string.format("[ChatSession] Created new session (model: %s)", session.model or "default"),
0       vim.log.levels.DEBUG
      )
    end

*   return session
  end

  --- Build command parts for llm CLI
  -- @param prompt string: User prompt to send
  -- @return table: Command parts array
* function ChatSession:build_command(prompt)
*   local llm_executable = config.get("llm_executable_path") or "llm"
*   local cmd_parts = { llm_executable, "prompt" }

    -- Add model if specified
*   if self.model and self.model ~= "" then
*     table.insert(cmd_parts, "-m")
*     table.insert(cmd_parts, self.model)
    end

    -- For first message: add system prompt and fragments
    -- For continuation: use -c flag (system prompt and fragments are preserved)
*   if not self.conversation_id then
      -- First message in conversation
*     if self.system_prompt and self.system_prompt ~= "" then
*       table.insert(cmd_parts, "-s")
*       table.insert(cmd_parts, self.system_prompt)
      end

      -- Add fragments
*     for _, fragment in ipairs(self.fragments) do
0       table.insert(cmd_parts, "-f")
0       table.insert(cmd_parts, fragment)
      end
    else
      -- Continuation of existing conversation
*     table.insert(cmd_parts, "-c")
*     table.insert(cmd_parts, self.conversation_id)
    end

    -- Note: Don't add prompt as argument here
    -- We'll send it via stdin to avoid quoting issues

*   if config.get('debug') then
0     vim.notify(
0       string.format("[ChatSession] Command: %s (prompt via stdin)", table.concat(cmd_parts, " ")),
0       vim.log.levels.DEBUG
      )
    end

*   return cmd_parts
  end

  --- Extract conversation ID from LLM output
  -- The LLM CLI includes conversation ID in the output like:
  -- "Conversation ID: 01abc123def"
  -- @param output string: Output text from LLM
  -- @return string|nil: Extracted conversation ID or nil
* function ChatSession:extract_conversation_id(output)
*   if not output or output == "" then
0     return nil
    end

    -- Try to find conversation ID in the output
    -- Pattern: "Conversation ID: <id>"
*   local id = output:match("Conversation ID: ([%w]+)")

*   if id then
*     if config.get('debug') then
0       vim.notify(
0         string.format("[ChatSession] Extracted conversation ID: %s", id),
0         vim.log.levels.DEBUG
        )
      end
*     return id
    end

0   return nil
  end

  --- Get conversation ID from llm CLI logs
  -- Falls back to querying llm logs if ID not in output
  -- @return string|nil: Conversation ID or nil
* function ChatSession:get_conversation_id_from_logs()
0   local llm_executable = config.get("llm_executable_path") or "llm"
0   local cmd_string = string.format("%s logs -n 1 --json", llm_executable)

0   local result = vim.fn.system(cmd_string)

0   if not result or result == "" then
0     if config.get('debug') then
0       vim.notify("[ChatSession] No logs returned from llm CLI", vim.log.levels.DEBUG)
      end
0     return nil
    end

    -- Trim whitespace
0   result = result:gsub("^%s*(.-)%s*$", "%1")

    -- Parse JSON
0   local ok, log_data = pcall(vim.json.decode, result)
0   if not ok or not log_data or type(log_data) ~= "table" or #log_data == 0 then
0     if config.get('debug') then
0       vim.notify("[ChatSession] Failed to parse llm logs JSON", vim.log.levels.DEBUG)
      end
0     return nil
    end

    -- Get conversation ID from first log entry
0   local conversation_id = log_data[1] and log_data[1].conversation_id

0   if conversation_id then
0     if config.get('debug') then
0       vim.notify(
0         string.format("[ChatSession] Got conversation ID from logs: %s", conversation_id),
0         vim.log.levels.DEBUG
        )
      end
    end

0   return conversation_id
  end

  --- Update conversation ID from output or logs
  -- @param output string: LLM output text
* function ChatSession:update_conversation_id(output)
    -- First try to extract from output
0   local id = self:extract_conversation_id(output)

    -- If not in output, query logs
0   if not id then
0     id = self:get_conversation_id_from_logs()
    end

0   if id then
0     self.conversation_id = id
0     if config.get('debug') then
0       vim.notify(
0         string.format("[ChatSession] Conversation ID updated: %s", id),
0         vim.log.levels.DEBUG
        )
      end
    else
0     if config.get('debug') then
0       vim.notify("[ChatSession] Could not determine conversation ID", vim.log.levels.WARN)
      end
    end
  end

  --- Send a prompt to the LLM
  -- @param prompt string: User prompt
  -- @param callbacks table: Callbacks for streaming
  --   - on_stdout: function(job_id, data) - Called with stdout chunks
  --   - on_stderr: function(job_id, data) - Called with stderr chunks
  --   - on_exit: function(job_id, exit_code) - Called on completion
  -- @return number|nil: Job ID or nil if failed
* function ChatSession:send_prompt(prompt, callbacks)
*   if not prompt or prompt == "" then
0     vim.notify("Cannot send empty prompt", vim.log.levels.ERROR)
0     return nil
    end

    -- Build command
*   local cmd_parts = self:build_command(prompt)

    -- Update state
*   self.state = 'processing'

    -- Track accumulated output for conversation ID extraction
*   local accumulated_output = ""

    -- Wrap callbacks to track output and update conversation ID
*   local wrapped_callbacks = {
      on_stdout = function(job_id, data)
0       if data then
0         for _, line in ipairs(data) do
0           accumulated_output = accumulated_output .. line .. "\n"
          end
        end

0       if callbacks and callbacks.on_stdout then
0         callbacks.on_stdout(job_id, data)
        end
      end,

      on_stderr = function(job_id, data)
0       if callbacks and callbacks.on_stderr then
0         callbacks.on_stderr(job_id, data)
        end
      end,

      on_exit = function(job_id, exit_code)
        -- Update conversation ID after first message
0       if not self.conversation_id then
0         self:update_conversation_id(accumulated_output)
        end

        -- Update state
0       if exit_code == 0 then
0         self.state = 'ready'
        else
0         self.state = 'error'
        end

0       self.current_job_id = nil

0       if callbacks and callbacks.on_exit then
0         callbacks.on_exit(job_id, exit_code)
        end
      end,
    }

    -- Execute command using job module
*   local job = require('llm.core.utils.job')
*   local job_id = job.run(cmd_parts, wrapped_callbacks)

*   if job_id then
*     self.current_job_id = job_id

      -- Send prompt via stdin to avoid shell quoting issues
*     vim.fn.chansend(job_id, prompt)
*     vim.fn.chanclose(job_id, "stdin")

*     if config.get('debug') then
0       vim.notify(
0         string.format("[ChatSession] Started job %d, sent prompt: %s", job_id, prompt),
0         vim.log.levels.DEBUG
        )
      end
    else
0     self.state = 'error'
0     vim.notify("Failed to start LLM command", vim.log.levels.ERROR)
    end

*   return job_id
  end

  --- Get current conversation ID
  -- @return string|nil: Conversation ID or nil
* function ChatSession:get_conversation_id()
0   return self.conversation_id
  end

  --- Get current session state
  -- @return string: Session state (ready, processing, error)
* function ChatSession:get_state()
0   return self.state
  end

  --- Check if session is ready for new prompts
  -- @return boolean: True if ready
* function ChatSession:is_ready()
*   return self.state == 'ready'
  end

  --- Stop current job if running
* function ChatSession:stop_current_job()
0   if self.current_job_id then
0     vim.fn.jobstop(self.current_job_id)
0     self.current_job_id = nil
0     self.state = 'ready'

0     if config.get('debug') then
0       vim.notify("[ChatSession] Stopped current job", vim.log.levels.DEBUG)
      end
    end
  end

* M.ChatSession = ChatSession
* return M

==============================================================================
lua/llm/chat/buffer.lua
==============================================================================
  -- llm/chat/buffer.lua - Chat Buffer UI Management
  -- License: Apache 2.0

* local M = {}
* local config = require('llm.config')

  --- ChatBuffer class for managing chat buffer UI
  -- @class ChatBuffer
* local ChatBuffer = {}
* ChatBuffer.__index = ChatBuffer

  -- Section markers
* local HEADER_START_MARKER = "╭─"
* local HEADER_END_MARKER = "╰─"
* local HISTORY_START_MARKER = "┌─ Conversation History "
* local HISTORY_END_MARKER = "└─"
* local INPUT_START_MARKER = "┌─ Your Message "
* local INPUT_END_MARKER = "└─"

  --- Create a new chat buffer
  -- @param opts table: Buffer options
  --   - model: string (optional) - Model name
  --   - conversation_id: string (optional) - Conversation ID
  --   - system_prompt: string (optional) - System prompt
  -- @return ChatBuffer: New buffer instance
* function ChatBuffer.new(opts)
*   opts = opts or {}

    -- Create new vertical split
*   vim.cmd('vnew')
*   local bufnr = vim.api.nvim_get_current_buf()

    -- Configure buffer
*   vim.api.nvim_buf_set_option(bufnr, 'buftype', 'nofile')
*   vim.api.nvim_buf_set_option(bufnr, 'bufhidden', 'wipe')
*   vim.api.nvim_buf_set_option(bufnr, 'swapfile', false)
*   vim.api.nvim_buf_set_option(bufnr, 'filetype', 'markdown')
*   vim.api.nvim_buf_set_option(bufnr, 'modifiable', true)  -- Allow modifications

    -- Set buffer name
*   local model_name = opts.model or config.get("model") or "default"
*   local conversation_id = opts.conversation_id or "new"
*   local buffer_name = string.format("LLM Chat - %s (%s)", model_name, conversation_id)
*   vim.api.nvim_buf_set_name(bufnr, buffer_name)

*   local buffer = {
*     bufnr = bufnr,
*     model = opts.model,
*     conversation_id = opts.conversation_id,
*     system_prompt = opts.system_prompt,
*     history_start_line = 0, -- Will be set after initialization
*     history_end_line = 0,
*     input_start_line = 0,
*     input_end_line = 0,
    }

*   setmetatable(buffer, ChatBuffer)

    -- Initialize buffer layout
*   buffer:initialize_layout()

    -- Set up keymaps
*   buffer:setup_keymaps()

    -- Set up highlights
*   buffer:setup_highlights()

    -- Move cursor to input area
*   buffer:focus_input()

*   if config.get('debug') then
0     vim.notify(
0       string.format("[ChatBuffer] Created buffer %d", bufnr),
0       vim.log.levels.DEBUG
      )
    end

*   return buffer
  end

  --- Initialize buffer layout with sections
* function ChatBuffer:initialize_layout()
*   local lines = {}

    -- Header line
*   local model_display = self.model or config.get("model") or "default"
*   local conv_id_display = self.conversation_id or "new"
*   table.insert(lines, string.format("LLM Chat - %s (ID: %s) | Status: Ready", model_display, conv_id_display))
*   table.insert(lines, "")

    -- Conversation history section
*   self.history_start_line = #lines
*   table.insert(lines, "No messages yet")
*   self.history_end_line = #lines
*   table.insert(lines, "")

    -- Input area section
*   self.input_start_line = #lines
*   table.insert(lines, "--- (<C-CR> to send) ---")
*   table.insert(lines, "Type your message here...")
*   self.input_end_line = #lines

    -- Set buffer content
*   vim.api.nvim_buf_set_lines(self.bufnr, 0, -1, false, lines)

    -- Make history section read-only by default (we'll manage this programmatically)
    -- Neovim doesn't have per-line read-only, so we'll handle in keymaps
  end

  --- Set up buffer keymaps with proper scoping
* function ChatBuffer:setup_keymaps()
*   local bufnr = self.bufnr

    -- Helper function to check if cursor is in input area
    local function is_cursor_in_input()
0     local cursor = vim.api.nvim_win_get_cursor(0)
0     local line = cursor[1]
0     return line > self.input_start_line and line <= self.input_end_line
    end

    -- Auto-remove placeholder on insert mode entry
*   vim.api.nvim_create_autocmd("InsertEnter", {
*     buffer = bufnr,
      callback = function()
0       local cursor = vim.api.nvim_win_get_cursor(0)
0       local line_num = cursor[1]

        -- Check if cursor is in input area
0       if line_num > self.input_start_line and line_num <= self.input_end_line then
0         local line = vim.api.nvim_buf_get_lines(bufnr, line_num - 1, line_num, false)[1]

          -- Remove placeholder text if present
0         if line and line:match("Type your message here") then
0           vim.api.nvim_buf_set_lines(bufnr, line_num - 1, line_num, false, {""})
            -- Keep cursor at the now-empty line
0           vim.api.nvim_win_set_cursor(0, {line_num, 0})
          end
        end
      end
    })

    -- <C-CR> to send prompt (works anywhere, but only sends if in input area)
*   vim.api.nvim_buf_set_keymap(
*     bufnr, 'i', '<C-CR>',
*     '<Cmd>lua require("llm.chat").send_message()<CR>',
*     { noremap = true, silent = true, desc = "Send message" }
    )

*   vim.api.nvim_buf_set_keymap(
*     bufnr, 'n', '<C-CR>',
*     '<Cmd>lua require("llm.chat").send_message()<CR>',
*     { noremap = true, silent = true, desc = "Send message" }
    )

    -- <Leader>s alternative to send
*   vim.api.nvim_buf_set_keymap(
*     bufnr, 'i', '<Leader>s',
*     '<Cmd>lua require("llm.chat").send_message()<CR>',
*     { noremap = true, silent = true, desc = "Send message" }
    )

*   vim.api.nvim_buf_set_keymap(
*     bufnr, 'n', '<Leader>s',
*     '<Cmd>lua require("llm.chat").send_message()<CR>',
*     { noremap = true, silent = true, desc = "Send message" }
    )

    -- q to close buffer
*   vim.api.nvim_buf_set_keymap(
*     bufnr, 'n', 'q',
*     '<Cmd>bd<CR>',
*     { noremap = true, silent = true, desc = "Close chat buffer" }
    )

    -- <C-n> to clear input and start new message
*   vim.api.nvim_buf_set_keymap(
*     bufnr, 'n', '<C-n>',
*     '<Cmd>lua require("llm.chat").new_message()<CR>',
*     { noremap = true, silent = true, desc = "New message" }
    )

*   vim.api.nvim_buf_set_keymap(
*     bufnr, 'i', '<C-n>',
*     '<Cmd>lua require("llm.chat").new_message()<CR>',
*     { noremap = true, silent = true, desc = "New message" }
    )

*   if config.get('debug') then
0     vim.notify("[ChatBuffer] Keymaps configured", vim.log.levels.DEBUG)
    end
  end

  --- Set up syntax highlighting for chat elements
* function ChatBuffer:setup_highlights()
    -- Define highlight groups
*   vim.api.nvim_set_hl(0, 'LlmChatHeader', { fg = '#f8f8f2', bg = '#44475a', bold = true })
*   vim.api.nvim_set_hl(0, 'LlmChatBorder', { fg = '#6272a4' })
*   vim.api.nvim_set_hl(0, 'LlmChatUserTag', { fg = '#50fa7b', bold = true })    -- Green
*   vim.api.nvim_set_hl(0, 'LlmChatLlmTag', { fg = '#bd93f9', bold = true })     -- Purple
*   vim.api.nvim_set_hl(0, 'LlmChatStatus', { fg = '#8be9fd', italic = true })   -- Cyan
*   vim.api.nvim_set_hl(0, 'LlmChatInputPrompt', { fg = '#ffb86c', italic = true }) -- Orange

    -- Apply highlights to header
*   vim.api.nvim_buf_add_highlight(self.bufnr, -1, 'LlmChatBorder', 0, 0, -1)
*   vim.api.nvim_buf_add_highlight(self.bufnr, -1, 'LlmChatStatus', 1, 0, -1)
*   vim.api.nvim_buf_add_highlight(self.bufnr, -1, 'LlmChatBorder', 2, 0, -1)
  end

  --- Update conversation ID in header
  -- @param conversation_id string: New conversation ID
* function ChatBuffer:update_conversation_id(conversation_id)
*   self.conversation_id = conversation_id

    -- Update buffer name
*   local model_display = self.model or config.get("model") or "default"
*   local buffer_name = string.format("LLM Chat - %s (%s)", model_display, conversation_id)
*   vim.api.nvim_buf_set_name(self.bufnr, buffer_name)

*   if config.get('debug') then
0     vim.notify(
0       string.format("[ChatBuffer] Updated conversation ID: %s", conversation_id),
0       vim.log.levels.DEBUG
      )
    end
  end

  --- Set status message in header
  -- @param status string: Status message
* function ChatBuffer:set_status(status)
*   self.current_status = status
*   local model_display = self.model or config.get("model") or "default"
*   local conv_id_display = self.conversation_id or "new"
*   local new_line = string.format("LLM Chat - %s (ID: %s) | Status: %s", model_display, conv_id_display, status)

*   vim.api.nvim_buf_set_lines(self.bufnr, 0, 1, false, { new_line })
*   vim.api.nvim_buf_add_highlight(self.bufnr, -1, 'LlmChatStatus', 0, 0, -1)
  end

  --- Append user message to history
  -- @param message string: User message
* function ChatBuffer:append_user_message(message)
*   if not message or message == "" then
0     return
    end

    -- Get ALL current history content (everything between header and input section)
*   local history_lines = vim.api.nvim_buf_get_lines(
*     self.bufnr,
*     2,  -- Start after header (line 0 is title, line 1 is blank)
*     self.input_start_line,  -- Everything before input section
      false
*   )

    -- Remove placeholder if exists
*   if #history_lines == 1 and history_lines[1]:match("No messages yet") then
0     history_lines = {}
    end

    -- Filter out any remaining placeholder lines
*   local filtered_lines = {}
*   for _, line in ipairs(history_lines) do
*     if not line:match("No messages yet") then
*       table.insert(filtered_lines, line)
      end
    end
*   history_lines = filtered_lines

    -- Remove trailing blank line if exists
*   if #history_lines > 0 and history_lines[#history_lines] == "" then
0     table.remove(history_lines)
    end

    -- Add user message with tag
*   table.insert(history_lines, "[You]")

    -- Split message by lines
*   for line in message:gmatch("[^\r\n]+") do
*     table.insert(history_lines, line)
    end

*   table.insert(history_lines, "")

    -- Rebuild entire buffer to fix formatting
*   self:rebuild_buffer(history_lines)

*   if config.get('debug') then
0     vim.notify(string.format("[ChatBuffer] Appended user message (%d history lines)", #history_lines), vim.log.levels.DEBUG)
    end
  end

  --- Append LLM message to history (supports streaming)
  -- @param text string: LLM response text
* function ChatBuffer:append_llm_message(text)
*   if not text or text == "" then
0     return
    end

    -- Get ALL current history content
*   local history_lines = vim.api.nvim_buf_get_lines(
*     self.bufnr,
*     2,  -- Start after header
*     self.input_start_line,  -- Everything before input section
      false
*   )

    -- Remove placeholder if exists
*   if #history_lines == 1 and history_lines[1]:match("No messages yet") then
0     history_lines = {}
    end

    -- Filter out any remaining placeholder lines
*   local filtered_lines = {}
*   for _, line in ipairs(history_lines) do
*     if not line:match("No messages yet") then
*       table.insert(filtered_lines, line)
      end
    end
*   history_lines = filtered_lines

    -- Remove trailing blank line if exists
*   if #history_lines > 0 and history_lines[#history_lines] == "" then
0     table.remove(history_lines)
    end

    -- Check if this is the first chunk of a new LLM response
*   local is_new_response = #history_lines == 0 or
*                           history_lines[#history_lines] == "" or
*                           history_lines[#history_lines]:match("^%[You%]") or
*                           history_lines[#history_lines]:match("^%[LLM%]")

*   if is_new_response then
0     table.insert(history_lines, "[LLM]")
    end

    -- Append the text (handle streaming chunks)
*   local lines = {}
*   for line in text:gmatch("[^\r\n]+") do
*     table.insert(lines, line)
    end

    -- If text ends with newline, add it
*   if text:match("\n$") then
0     table.insert(lines, "")
    end

*   for _, line in ipairs(lines) do
*     table.insert(history_lines, line)
    end

    -- Rebuild entire buffer to fix formatting
*   self:rebuild_buffer(history_lines)
  end

  --- Rebuild entire buffer with current history
  -- @param history_lines table: Array of history lines
* function ChatBuffer:rebuild_buffer(history_lines)
*   local lines = {}

    -- Header line
*   local model_display = self.model or config.get("model") or "default"
*   local conv_id_display = self.conversation_id or "new"
*   local status_display = self.current_status or "Ready"
*   table.insert(lines, string.format("LLM Chat - %s (ID: %s) | Status: %s", model_display, conv_id_display, status_display))
*   table.insert(lines, "")

    -- History section
*   self.history_start_line = #lines

    -- Add all history lines
*   for _, line in ipairs(history_lines) do
*     table.insert(lines, line)
    end

*   self.history_end_line = #lines
*   table.insert(lines, "")

    -- Input section
*   self.input_start_line = #lines
*   table.insert(lines, "--- (<C-CR> to send) ---")
*   table.insert(lines, "Type your message here...")
*   self.input_end_line = #lines

    -- Replace entire buffer
*   vim.api.nvim_buf_set_lines(self.bufnr, 0, -1, false, lines)

*   if config.get('debug') then
0     vim.notify(
0       string.format("[ChatBuffer] Rebuilt buffer: history_start=%d, history_end=%d",
0         self.history_start_line, self.history_end_line),
0       vim.log.levels.DEBUG
      )
    end
  end

  --- Get user input from input section
  -- @return string: User input text
* function ChatBuffer:get_user_input()
    -- Get lines from input area (after the separator line)
*   local input_lines = vim.api.nvim_buf_get_lines(
*     self.bufnr,
*     self.input_start_line + 1,
*     self.input_end_line + 1,
      false
*   )

    -- Filter out placeholder text
*   local cleaned_lines = {}
*   for _, line in ipairs(input_lines) do
      -- Skip placeholder text
*     if not line:match("^Type your message here") then
*       table.insert(cleaned_lines, line)
      end
    end

*   local input = table.concat(cleaned_lines, "\n")

    -- Trim whitespace
*   input = input:gsub("^%s+", ""):gsub("%s+$", "")

*   if config.get('debug') then
0     vim.notify(
0       string.format("[ChatBuffer] Got user input: %s", input),
0       vim.log.levels.DEBUG
      )
    end

*   return input
  end

  --- Clear input area
* function ChatBuffer:clear_input()
    -- Reset input section with placeholder
*   local input_lines = {
*     "--- (<C-CR> to send) ---",
      "Type your message here...",
*   }

    -- Replace input section
*   vim.api.nvim_buf_set_lines(
*     self.bufnr,
*     self.input_start_line,
*     self.input_end_line + 1,
*     false,
      input_lines
*   )

    -- Update input_end_line
*   self.input_end_line = self.input_start_line + 1

*   if config.get('debug') then
0     vim.notify("[ChatBuffer] Cleared input area", vim.log.levels.DEBUG)
    end
  end

  --- Set input area text
  -- @param text string: Text to set in input area
* function ChatBuffer:set_input(text)
    -- Build input section with text
0   local input_lines = {
      "--- (<C-CR> to send) ---",
      text,
    }

    -- Replace input section
0   vim.api.nvim_buf_set_lines(
0     self.bufnr,
0     self.input_start_line,
0     self.input_end_line + 1,
      false,
      input_lines
    )

    -- Update input_end_line
0   self.input_end_line = self.input_start_line + 1

0   if config.get('debug') then
0     vim.notify("[ChatBuffer] Set input text: " .. text, vim.log.levels.DEBUG)
    end
  end

  --- Focus cursor on input area
* function ChatBuffer:focus_input()
    -- Move cursor to input area (first editable line)
*   local input_line = self.input_start_line + 2 -- Line after start marker
*   vim.api.nvim_win_set_cursor(0, { input_line, 2 }) -- Position after "│ "

    -- Switch to insert mode
*   vim.cmd('startinsert')
  end

  --- Check if cursor is in input area
  -- @return boolean: True if cursor is in input section
* function ChatBuffer:is_cursor_in_input()
0   local cursor = vim.api.nvim_win_get_cursor(0)
0   local line = cursor[1]
0   return line > self.input_start_line and line <= self.input_end_line
  end

  --- Get buffer number
  -- @return number: Buffer number
* function ChatBuffer:get_bufnr()
*   return self.bufnr
  end

* M.ChatBuffer = ChatBuffer
* return M

==============================================================================
lua/llm/managers/schemas_manager.lua
==============================================================================
  -- llm/managers/schemas_manager.lua - Schema management for llm-nvim
  -- License: Apache 2.0

* local M = {}

  -- Forward declarations
* local api = vim.api
* local llm_cli = require('llm.core.data.llm_cli')
* local cache = require('llm.core.data.cache')
* local schemas_view = require('llm.ui.views.schemas_view')
* local styles = require('llm.ui.styles')

  -- Get schemas from llm CLI
* function M.get_schemas()
*     local cached_schemas = cache.get('schemas')
*     if cached_schemas then
*         return cached_schemas
      end

*     local schemas_json = llm_cli.run_llm_command('schemas list --json')
*     local schemas = vim.fn.json_decode(schemas_json)
*     cache.set('schemas', schemas)
*     return schemas
  end

  -- Get a specific schema from llm CLI
* function M.get_schema(schema_id)
*     local schema_json = llm_cli.run_llm_command('schemas get ' .. schema_id .. ' --json')
*     return vim.fn.json_decode(schema_json)
  end

  -- Save a schema
* function M.save_schema(name, content, test_mode)
*     local temp_file_path = vim.fn.tempname()
*     if test_mode then
*         return 'schemas save ' .. name .. ' ' .. temp_file_path
      end
*     local file = io.open(temp_file_path, "w")
*     if not file then
0         return false
      end
*     file:write(content)
*     file:close()

*     local result = llm_cli.run_llm_command('schemas save ' .. name .. ' ' .. temp_file_path)
*     os.remove(temp_file_path)
*     cache.invalidate('schemas')
*     return result ~= nil
  end

  -- Run a schema
* function M.run_schema(schema_id, input, is_multi, bufnr, test_mode)
*     local temp_file_path = vim.fn.tempname()
*     if test_mode then
*         local multi_flag = is_multi and " --multi" or ""
*         return 'schema ' .. schema_id .. ' ' .. temp_file_path .. multi_flag
      end
*     local file = io.open(temp_file_path, "w")
*     if not file then
0         return nil
      end
*     file:write(input)
*     file:close()

*     local multi_flag = is_multi and " --multi" or ""
*     local command_str = 'schema ' .. schema_id .. ' ' .. temp_file_path .. multi_flag

*     local target_bufnr = bufnr
*     if not target_bufnr then
0         vim.cmd('vnew')
0         target_bufnr = vim.api.nvim_get_current_buf()
0         local buffer_name = "LLM Schema Result - " .. os.time()
0         vim.api.nvim_buf_set_name(target_bufnr, buffer_name)
0         vim.api.nvim_buf_set_option(target_bufnr, 'filetype', 'json')
0         vim.api.nvim_buf_set_lines(target_bufnr, 0, -1, false, { "Waiting for response..." })
      end

*     local cmd_parts = { llm_cli.get_llm_executable_path(), command_str }

*     local job_id = require('llm.api').run_llm_command_streamed(cmd_parts, target_bufnr, {
          on_exit = function()
0             vim.defer_fn(function() os.remove(temp_file_path) end, 0)
          end,
      })
*     return job_id
  end

  -- Select and run a schema
* function M.select_schema()
0   local schemas = M.get_schemas()
0   schemas_view.select_schema(schemas, function(choice)
0     if not choice then return end

0     local has_selection = false
0     local selection = ""
0     local mode = api.nvim_get_mode().mode
0     if mode == 'v' or mode == 'V' or mode == '' then
0       selection = require('llm.core.utils.text').get_visual_selection()
0       has_selection = selection ~= ""
      end

0     if has_selection then
0       schemas_view.get_schema_type(function(schema_type)
0         if not schema_type then return end
0         local is_multi = schema_type == "Multi schema (array of items)"
0         M.run_schema(choice.id, selection, is_multi)
        end)
      else
0       M.run_schema_with_input_source(choice.id)
      end
    end)
  end

  -- Run a schema with input from various sources
* function M.run_schema_with_input_source(schema_id)
0   if not schema_id or schema_id == "" then
0     vim.notify("Schema ID cannot be empty", vim.log.levels.ERROR)
0     return
    end

0   schemas_view.get_input_source(function(choice)
0     if not choice then return end

0     schemas_view.get_schema_type(function(schema_type)
0       if not schema_type then return end
0       local is_multi = schema_type == "Multi schema (array of items)"

0       if choice == "Current buffer" then
0         local lines = api.nvim_buf_get_lines(0, 0, -1, false)
0         local content = table.concat(lines, "\n")
0         vim.notify("Running schema on buffer content...", vim.log.levels.INFO)
0         M.run_schema(schema_id, content, is_multi, bufnr)
0       elseif choice == "URL (will use curl)" then
0         schemas_view.get_url(function(url)
0           if not url or url == "" then
0             vim.notify("URL cannot be empty", vim.log.levels.WARN)
0             return
            end
0           vim.notify("Running schema on URL content...", vim.log.levels.INFO)
0           M.run_schema(schema_id, url, is_multi, bufnr)
          end)
0       elseif choice == "Enter text manually" then
0         M.handle_manual_text_input(schema_id, is_multi)
        end
      end)
    end)
  end

* function M.handle_manual_text_input(schema_id, is_multi)
0   local temp_dir = vim.fn.stdpath('cache') .. "/llm_nvim_temp"
0   os.execute("mkdir -p " .. temp_dir)
0   local temp_file_path = string.format("%s/schema_input_%s_%s.txt", temp_dir, schema_id:sub(1, 8), os.time())

0   local buf = api.nvim_create_buf(false, true)
0   api.nvim_buf_set_option(buf, "buftype", "acwrite")
0   api.nvim_buf_set_option(buf, "bufhidden", "wipe")
0   api.nvim_buf_set_option(buf, "swapfile", false)
0   api.nvim_buf_set_name(buf, temp_file_path)

0   api.nvim_buf_set_lines(buf, 0, -1, false, {
0     "# Enter text to process with schema " .. schema_id,
      "# Press :w to save and submit, or :q! to cancel",
      "",
      ""
    })

0   api.nvim_command("split")
0   api.nvim_win_set_buf(0, buf)
0   api.nvim_win_set_cursor(0, { 4, 0 })

0   api.nvim_buf_set_var(buf, "llm_schema_id", schema_id)
0   api.nvim_buf_set_var(buf, "llm_schema_is_multi", is_multi)
0   api.nvim_buf_set_var(buf, "llm_temp_file_path", temp_file_path)

0   local group = api.nvim_create_augroup("LLMSchemaInput", { clear = true })
0   api.nvim_create_autocmd("BufWriteCmd", {
      group = group,
      buffer = buf,
      callback = function(args)
0       if api.nvim_buf_is_valid(args.buf) then
0         api.nvim_buf_set_option(args.buf, "modified", false)
0         require('llm.managers.schemas_manager').submit_schema_input_from_buffer(args.buf)
0         return true
        end
      end,
    })

0   api.nvim_buf_create_user_command(buf, "LlmSchemaCancel", function()
0     local temp_file = api.nvim_buf_get_var(buf, "llm_temp_file_path")
0     api.nvim_command(buf .. "bdelete!")
0     if temp_file and vim.fn.filereadable(temp_file) == 1 then
0       os.remove(temp_file)
      end
0     vim.notify("Schema input cancelled.", vim.log.levels.INFO)
0   end, {})

    local function set_keymap(mode, lhs, rhs, opts)
0     opts = opts or { noremap = true, silent = true }
0     api.nvim_buf_set_keymap(buf, mode, lhs, rhs, opts)
    end

0   set_keymap("n", "<Esc>", ":LlmSchemaCancel<CR>")
0   vim.notify("Enter text in this buffer. Save (:w) to submit or quit (:q!) to cancel.", vim.log.levels.INFO)
0   api.nvim_command('startinsert')
  end

* function M.submit_schema_input_from_buffer(buf)
0   if not api.nvim_buf_is_valid(buf) then
0     vim.notify("Invalid buffer for schema input", vim.log.levels.ERROR)
0     return
    end

0   local schema_id = api.nvim_buf_get_var(buf, "llm_schema_id")
0   local is_multi = api.nvim_buf_get_var(buf, "llm_schema_is_multi")
0   local lines = api.nvim_buf_get_lines(buf, 3, -1, false)
0   local content = table.concat(lines, "\n")

0   api.nvim_command(buf .. "bdelete!")
0   vim.notify("Running schema on input text...", vim.log.levels.INFO)

0   local result = M.run_schema(schema_id, content, is_multi)
0   if result then
0     require('llm.core.utils.ui').create_buffer_with_content(result, "Schema Result: " .. schema_id, "json")
    else
0     vim.notify("Failed to run schema on input text", vim.log.levels.ERROR)
    end
  end

* function M.create_schema()
0   schemas_view.get_schema_name(function(name)
0     if not name or name == "" then
0       vim.notify("Schema name cannot be empty", vim.log.levels.WARN)
0       return
      end
0     if name:match("[/\\]") then
0       vim.notify("Schema name cannot contain path separators (/ or \\)", vim.log.levels.ERROR)
0       return
      end

0     schemas_view.get_schema_format(function(format_choice)
0       if not format_choice then return end
0       M.handle_schema_creation(name, format_choice)
      end)
    end)
  end

* function M.handle_schema_creation(name, format_choice)
0   local temp_dir = vim.fn.stdpath('cache') .. "/llm_nvim_temp"
0   os.execute("mkdir -p " .. temp_dir)
0   local file_ext = (format_choice == "JSON Schema") and ".json" or ".dsl"
0   local safe_name = name:gsub("[^%w_-]", "_")
0   local temp_file_path = string.format("%s/schema_edit_%s_%s%s", temp_dir, safe_name, os.time(), file_ext)

0   local boilerplate = ""
0   if format_choice == "JSON Schema" then
0     boilerplate = "{\n  \"type\": \"object\",\n  \"properties\": {\n    \"property_name\": {\n      \"type\": \"string\",\n      \"description\": \"Description of the property\"\n    }\n  },\n  \"required\": [\"property_name\"]\n}"
    else
0     boilerplate = "# Define schema properties using DSL syntax\n# Example:\n# name: the person's name\n# age int: their age in years\n# bio: a short biography\n\n"
    end

0   local file = io.open(temp_file_path, "w")
0   if not file then
0     vim.notify("Failed to create temporary schema file: " .. temp_file_path, vim.log.levels.ERROR)
0     return
    end
0   file:write(boilerplate)
0   file:close()

0   api.nvim_command("split " .. vim.fn.fnameescape(temp_file_path))
0   local bufnr = api.nvim_get_current_buf()

0   if format_choice == "JSON Schema" then
0     api.nvim_buf_set_option(bufnr, 'filetype', 'json')
    else
0     api.nvim_buf_set_option(bufnr, 'filetype', 'markdown')
    end

0   api.nvim_buf_set_var(bufnr, "llm_schema_name", name)
0   api.nvim_buf_set_var(bufnr, "llm_schema_format", format_choice)
0   api.nvim_buf_set_var(bufnr, "llm_temp_schema_file_path", temp_file_path)

0   local group = api.nvim_create_augroup("LLMSchemaSave", { clear = true })
0   api.nvim_create_autocmd("BufWritePost", {
      group = group,
      buffer = bufnr,
      callback = function(args)
0       if api.nvim_buf_is_valid(args.buf) then
0         require('llm.managers.schemas_manager').save_schema_from_temp_file(args.buf)
        end
      end,
    })

0   api.nvim_buf_create_user_command(bufnr, "LlmCancel", function()
0     local temp_file = api.nvim_buf_get_var(bufnr, "llm_temp_schema_file_path")
0     api.nvim_command(bufnr .. "bdelete!")
0     if temp_file and vim.fn.filereadable(temp_file) == 1 then
0       os.remove(temp_file)
      end
0     vim.notify("Schema creation cancelled.", vim.log.levels.INFO)
0   end, {})

0   vim.notify("Edit the schema in this buffer. Save (:w) to validate and finalize. Use :LlmCancel to abort.", vim.log.levels.INFO)
  end

* function M.save_schema_from_temp_file(bufnr)
0   if not api.nvim_buf_is_valid(bufnr) then
0     return
    end

0   local name = api.nvim_buf_get_var(bufnr, "llm_schema_name")
0   local format_choice = api.nvim_buf_get_var(bufnr, "llm_schema_format")
0   local temp_file_path = api.nvim_buf_get_var(bufnr, "llm_temp_schema_file_path")
0   local content = table.concat(api.nvim_buf_get_lines(bufnr, 0, -1, false), "\n")
0   content = content:gsub("^%s+", ""):gsub("%s+$", "")

0   local validated_content, is_valid, error_message = M.validate_schema(content, format_choice)

0   if not is_valid then
0     vim.notify("Schema validation failed: " .. error_message, vim.log.levels.ERROR)
0     vim.notify("Schema not saved. Please fix the content and save again (:w), or use :LlmCancel to abort.", vim.log.levels.WARN)
0     return
    end

0   vim.notify("Schema validated. Saving schema '" .. name .. "'...", vim.log.levels.INFO)
0   local success = M.save_schema(name, validated_content)
0   if success then
0     vim.notify("Schema '" .. name .. "' saved successfully", vim.log.levels.INFO)
0     vim.defer_fn(function()
0       M.manage_schemas()
0     end, 1500)
0     api.nvim_command(bufnr .. "bdelete!")
0     if temp_file_path then os.remove(temp_file_path) end
    else
0     vim.notify("Failed to save schema '" .. name .. "'", vim.log.levels.ERROR)
    end
  end

* function M.validate_schema(content, format)
      -- Validation is now handled by the llm-cli
0     return content, true, nil
  end

* function M.populate_schemas_buffer(bufnr)
0   if _G.llm_schemas_named_only == nil then
0     _G.llm_schemas_named_only = true
    end
0   local show_named_only = _G.llm_schemas_named_only

0   local all_schemas = M.get_schemas()
0   local named_schemas, unnamed_schemas = M.categorize_schemas(all_schemas)
0   local schemas_to_show = show_named_only and named_schemas or vim.list_extend(vim.deepcopy(named_schemas), unnamed_schemas)

0   local lines = M.build_buffer_lines(schemas_to_show, show_named_only)
0   local schema_data, line_to_schema = M.build_schema_data(schemas_to_show, #lines + 1)

0   api.nvim_buf_set_lines(bufnr, 0, -1, false, lines)
0   styles.setup_highlights()
0   styles.setup_buffer_syntax(bufnr)
0   vim.b[bufnr].line_to_schema = line_to_schema
0   vim.b[bufnr].schema_data = schema_data
0   vim.b[bufnr].schemas = schemas_to_show
  end

* function M.categorize_schemas(all_schemas)
*   local named_schemas = {}
*   local unnamed_schemas = {}

*   for _, schema in ipairs(all_schemas) do
*     if schema.name then
*       table.insert(named_schemas, schema)
      else
*       table.insert(unnamed_schemas, schema)
      end
    end

*   table.sort(named_schemas, function(a, b) return a.name < b.name end)
*   table.sort(unnamed_schemas, function(a, b) return a.id < b.id end)
*   return named_schemas, unnamed_schemas
  end

* function M.build_buffer_lines(schemas, show_named_only)
*   local lines = {
*     "# Schema Management",
*     "",
*     "Navigate: [M]odels [P]lugins [K]eys [F]ragments [T]emplates",
*     "Actions: [c]reate [r]un [v]iew [e]dit [a]lias [d]elete alias [t]oggle view [q]uit",
*     "──────────────────────────────────────────────────────────────",
*     "",
*     show_named_only and "Showing: Only named schemas" or "Showing: All schemas",
      ""
*   }
*   if #schemas == 0 then
0     table.insert(lines, "No schemas found. Press 'c' to create one.")
    else
*     table.insert(lines, "Schemas:")
*     table.insert(lines, "----------")
*     for i, schema in ipairs(schemas) do
*       local description = schema.description:gsub("\n", " ")
*       local schema_details = M.get_schema(schema.id)
*       local is_valid = schema_details and schema_details.content and pcall(vim.fn.json_decode, schema_details.content)
*       table.insert(lines, string.format("Schema %d: %s", i, schema.id))
*       if schema.name then
*         table.insert(lines, string.format("  Name: %s", schema.name))
        end
*       table.insert(lines, string.format("  Status: %s", is_valid and "Valid" or "Invalid"))
*       table.insert(lines, string.format("  Description: %s", description))
*       table.insert(lines, "")
      end
    end
*   return lines
  end

* function M.build_schema_data(schemas, start_line)
*   local schema_data = {}
*   local line_to_schema = {}
*   local current_line = start_line
*   for i, schema in ipairs(schemas) do
*     local entry_lines = 1
*     if schema.name then entry_lines = entry_lines + 1 end
*     entry_lines = entry_lines + 3

*     schema_data[schema.id] = {
*       index = i,
*       name = schema.name,
*       description = schema.description,
*       is_valid = M.get_schema(schema.id) and true or false,
*       start_line = current_line,
*     }
*     for j = 0, entry_lines - 1 do
*       line_to_schema[current_line + j] = schema.id
      end
*     current_line = current_line + entry_lines
    end
*   return schema_data, line_to_schema
  end


* function M.setup_schemas_keymaps(bufnr, manager_module)
0   manager_module = manager_module or M
    local function set_keymap(mode, lhs, rhs)
0     api.nvim_buf_set_keymap(bufnr, mode, lhs, rhs, { noremap = true, silent = true })
    end
0   set_keymap('n', 'c', string.format([[<Cmd>lua require('%s').create_schema_from_manager(%d)<CR>]], manager_module.__name, bufnr))
0   set_keymap('n', 'r', string.format([[<Cmd>lua require('%s').run_schema_under_cursor(%d)<CR>]], manager_module.__name, bufnr))
0   set_keymap('n', 'v', string.format([[<Cmd>lua require('%s').view_schema_details_under_cursor(%d)<CR>]], manager_module.__name, bufnr))
0   set_keymap('n', 'e', string.format([[<Cmd>lua require('%s').edit_schema_under_cursor(%d)<CR>]], manager_module.__name, bufnr))
0   set_keymap('n', 'a', string.format([[<Cmd>lua require('%s').set_alias_for_schema_under_cursor(%d)<CR>]], manager_module.__name, bufnr))
0   set_keymap('n', 'd', string.format([[<Cmd>lua require('%s').delete_alias_for_schema_under_cursor(%d)<CR>]], manager_module.__name, bufnr))
0   set_keymap('n', 't', string.format([[<Cmd>lua require('%s').toggle_schemas_view(%d)<CR>]], manager_module.__name, bufnr))
  end

* function M.run_schema_under_cursor(bufnr)
0   local schema_id, _ = M.get_schema_info_under_cursor(bufnr)
0   if not schema_id then
0     vim.notify("No schema found under cursor", vim.log.levels.ERROR)
0     return
    end
0   require('llm.ui.unified_manager').close()
0   vim.schedule(function()
0     M.run_schema_with_input_source(schema_id)
    end)
  end

* function M.view_schema_details_under_cursor(bufnr)
0   local schema_id, _ = M.get_schema_info_under_cursor(bufnr)
0   if not schema_id then
0     vim.notify("No schema found under cursor", vim.log.levels.ERROR)
0     return
    end
0   local schema = M.get_schema(schema_id)
0   if not schema then
0     vim.notify("Failed to get schema details for '" .. schema_id .. "'", vim.log.levels.ERROR)
0     return
    end
0   require('llm.ui.unified_manager').close()
0   vim.schedule(function()
0     schemas_view.show_details(schema_id, schema, M)
    end)
  end

* function M.set_alias_for_schema_under_cursor(bufnr)
0   local schema_id, schema_info = M.get_schema_info_under_cursor(bufnr)
0   if not schema_id then
0     vim.notify("No schema found under cursor", vim.log.levels.ERROR)
0     return
    end
0   schemas_view.get_alias(schema_info.name, function(new_alias)
0     if not new_alias or new_alias == "" then
0       vim.notify("Alias cannot be empty", vim.log.levels.WARN)
0       return
      end
0     if new_alias:match("[/\\]") then
0       vim.notify("Alias cannot contain path separators (/ or \\)", vim.log.levels.ERROR)
0       return
      end
0     if llm_cli.run_llm_command('schemas alias set ' .. schema_id .. ' ' .. new_alias) then
0       vim.notify("Schema alias set to '" .. new_alias .. "'", vim.log.levels.INFO)
0       cache.invalidate('schemas')
0       require('llm.ui.unified_manager').switch_view("Schemas")
      else
0       vim.notify("Failed to set schema alias", vim.log.levels.ERROR)
      end
    end)
  end

* function M.create_schema_from_manager(bufnr)
0   require('llm.ui.unified_manager').close()
0   vim.schedule(function()
0     M.create_schema()
    end)
  end

* function M.run_schema_from_details(schema_id)
0   api.nvim_win_close(0, true)
0   vim.schedule(function()
0     M.run_schema_with_input_source(schema_id)
    end)
  end

* function M.set_alias_from_details(schema_id)
0   local schema = M.get_schema(schema_id)
0   schemas_view.get_alias(schema and schema.name, function(new_alias)
0     if not new_alias or new_alias == "" then
0       vim.notify("Alias cannot be empty", vim.log.levels.WARN)
0       return
      end
0     if new_alias:match("[/\\]") then
0       vim.notify("Alias cannot contain path separators (/ or \\)", vim.log.levels.ERROR)
0       return
      end
0     if llm_cli.run_llm_command('schemas alias set ' .. schema_id .. ' ' .. new_alias) then
0       vim.notify("Schema alias set to '" .. new_alias .. "'", vim.log.levels.INFO)
0       cache.invalidate('schemas')
0       api.nvim_win_close(0, true)
0       vim.schedule(function()
0         require('llm.ui.unified_manager').open_specific_manager("Schemas")
        end)
      else
0       vim.notify("Failed to set schema alias", vim.log.levels.ERROR)
      end
    end)
  end

* function M.delete_alias_for_schema_under_cursor(bufnr)
0   local schema_id, schema_info = M.get_schema_info_under_cursor(bufnr)
0   if not schema_id or not schema_info.name then
0     vim.notify("No schema with an alias found under cursor", vim.log.levels.ERROR)
0     return
    end
0   schemas_view.confirm_delete_alias(schema_info.name, function(confirmed)
0     if not confirmed then return end
0     if llm_cli.run_llm_command('schemas alias remove ' .. schema_info.name) then
0       vim.notify("Schema alias '" .. schema_info.name .. "' deleted", vim.log.levels.INFO)
0       cache.invalidate('schemas')
0       require('llm.ui.unified_manager').switch_view("Schemas")
      else
0       vim.notify("Failed to delete schema alias", vim.log.levels.ERROR)
      end
    end)
  end

* function M.edit_schema_under_cursor(bufnr)
0   local schema_id, _ = M.get_schema_info_under_cursor(bufnr)
0   if not schema_id then
0     vim.notify("No schema found under cursor", vim.log.levels.ERROR)
0     return
    end
0   require('llm.ui.unified_manager').close()
0   vim.schedule(function()
0     M.edit_schema_from_details(schema_id)
    end)
  end

* function M.toggle_schemas_view(bufnr)
0   _G.llm_schemas_named_only = not (_G.llm_schemas_named_only == true)
0   require('llm.ui.unified_manager').close()
0   vim.schedule(function()
0     require('llm.ui.unified_manager').open_specific_manager("Schemas")
    end)
  end

* function M.delete_alias_from_details(schema_id)
0   local schema = M.get_schema(schema_id)
0   if not schema or not schema.name then
0     vim.notify("This schema does not have an alias to delete", vim.log.levels.WARN)
0     return
    end
0   schemas_view.confirm_delete_alias(schema.name, function(confirmed)
0     if not confirmed then return end
0     if llm_cli.run_llm_command('schemas alias remove ' .. schema.name) then
0       vim.notify("Schema alias '" .. schema.name .. "' deleted", vim.log.levels.INFO)
0       cache.invalidate('schemas')
0       api.nvim_win_close(0, true)
0       vim.schedule(function()
0         require('llm.ui.unified_manager').open_specific_manager("Schemas")
        end)
      else
0       vim.notify("Failed to delete schema alias", vim.log.levels.ERROR)
      end
    end)
  end

* function M.get_schema_info_under_cursor(bufnr)
0   local current_line = api.nvim_win_get_cursor(0)[1]
0   local line_to_schema = vim.b[bufnr].line_to_schema
0   local schema_data = vim.b[bufnr].schema_data
0   if not line_to_schema or not schema_data then
0     vim.notify("Buffer data missing", vim.log.levels.ERROR)
0     return nil, nil
    end
0   local schema_id = line_to_schema[current_line]
0   if schema_id and schema_data[schema_id] then
0     return schema_id, schema_data[schema_id]
    end
0   return nil, nil
  end

* function M.manage_schemas(show_named_only)
0   _G.llm_schemas_named_only = show_named_only or true
0   require('llm.ui.unified_manager').open_specific_manager("Schemas")
  end

* M.__name = 'llm.managers.schemas_manager'

* return M

==============================================================================
lua/llm/managers/fragments_manager.lua
==============================================================================
  -- llm/managers/fragments_manager.lua - Fragment management functionality for llm-nvim
  -- License: Apache 2.0

* local M = {}

  -- Forward declarations
* local api = vim.api
* local fn = vim.fn
* local llm_cli = require('llm.core.data.llm_cli')
* local cache = require('llm.core.data.cache')
* local fragments_view = require('llm.ui.views.fragments_view')
* local styles = require('llm.ui.styles')

  -- Get fragments from llm CLI
* function M.get_fragments()
*     local cached_fragments = cache.get('fragments')
*     if cached_fragments then
*         return cached_fragments
      end

*     local fragments_json = llm_cli.run_llm_command('fragments list --json')
*     local fragments = vim.fn.json_decode(fragments_json)
*     cache.set('fragments', fragments)
*     return fragments
  end

  -- Populate the buffer with fragment management content
* function M.populate_fragments_buffer(bufnr)
0   local show_all = _G.llm_fragments_show_all or false
0   local fragments = M.get_fragments()
0   local show_mode = show_all and "all" or "with_aliases"

0   local lines = {
      "# Fragment Management",
      "",
      "Navigate: [M]odels [P]lugins [K]eys [T]emplates [S]chemas",
      "Actions: [v]iew [a]dd alias [r]emove alias [n]ew file [g]itHub [p]rompt [t]oggle view [q]uit",
      "──────────────────────────────────────────────────────────────",
      "",
0     "Showing: " .. (show_mode == "all" and "All fragments" or "Only fragments with aliases"),
      ""
    }

0   local fragment_data = {}
0   local line_to_fragment = {}
0   local current_line = #lines + 1

0   if #fragments == 0 then
0     table.insert(lines, "No fragments found.")
0     table.insert(lines, "Use 'n' to add a new fragment from a file.")
    else
0     for i, fragment in ipairs(fragments) do
0       if not show_all and (#fragment.aliases == 0) then
          -- Skip to the next iteration
        else
0         local aliases = #fragment.aliases > 0 and table.concat(fragment.aliases, ", ") or "none"
0         local source = fragment.source or "unknown"
0         local first_line = fragment.content:match("^[^\r\n]*") or ""
0         local content_preview = first_line
0         if #content_preview > 50 then
0           content_preview = content_preview:sub(1, 47) .. "..."
0         elseif #fragment.content > #content_preview then
0           content_preview = content_preview .. "..."
          end

0         local entry_lines = {
0           string.format("Fragment %d: %s", i, fragment.hash),
0           string.format("  Source: %s", source),
0           string.format("  Aliases: %s", aliases),
0           string.format("  Date: %s", fragment.datetime or "unknown"),
0           string.format("  Content: %s", content_preview),
            ""
          }
0         for _, line in ipairs(entry_lines) do table.insert(lines, line) end

0         fragment_data[fragment.hash] = {
            index = i,
            aliases = fragment.aliases,
            source = fragment.source,
            content = fragment.content,
            datetime = fragment.datetime,
            start_line = current_line,
          }
0         for j = 0, 5 do line_to_fragment[current_line + j] = fragment.hash end
0         current_line = current_line + 6
        end
      end
    end

0   api.nvim_buf_set_lines(bufnr, 0, -1, false, lines)
0   styles.setup_highlights()
0   styles.setup_buffer_syntax(bufnr)
0   vim.b[bufnr].line_to_fragment = line_to_fragment
0   vim.b[bufnr].fragment_data = fragment_data
0   vim.b[bufnr].fragments = fragments
  end

  -- Setup keymaps for the fragment management buffer
* function M.setup_fragments_keymaps(bufnr, manager_module)
0   manager_module = manager_module or M

    local function set_keymap(mode, lhs, rhs)
0     api.nvim_buf_set_keymap(bufnr, mode, lhs, rhs, { noremap = true, silent = true })
    end

0   set_keymap('n', 'v', string.format([[<Cmd>lua require('%s').view_fragment_under_cursor(%d)<CR>]], manager_module.__name, bufnr))
0   set_keymap('n', 'a', string.format([[<Cmd>lua require('%s').set_alias_for_fragment_under_cursor(%d)<CR>]], manager_module.__name, bufnr))
0   set_keymap('n', 'r', string.format([[<Cmd>lua require('%s').remove_alias_from_fragment_under_cursor(%d)<CR>]], manager_module.__name, bufnr))
0   set_keymap('n', 't', string.format([[<Cmd>lua require('%s').toggle_fragments_view(%d)<CR>]], manager_module.__name, bufnr))
0   set_keymap('n', 'n', string.format([[<Cmd>lua require('%s').add_file_fragment(%d)<CR>]], manager_module.__name, bufnr))
0   set_keymap('n', 'g', string.format([[<Cmd>lua require('%s').add_github_fragment_from_manager(%d)<CR>]], manager_module.__name, bufnr))
0   set_keymap('n', 'p', string.format([[<Cmd>lua require('%s').prompt_with_fragment_under_cursor(%d)<CR>]], manager_module.__name, bufnr))
  end

  -- Action functions called by keymaps (now accept bufnr)
* function M.view_fragment_under_cursor(bufnr)
0   local fragment_hash, fragment_info = M.get_fragment_info_under_cursor(bufnr)
0   if not fragment_hash then return end
0   fragments_view.view_fragment(fragment_info.content, fragment_info.source)
  end

* function M.set_alias_for_fragment_under_cursor(bufnr)
*   print("Setting alias")
*   local fragment_hash, _ = M.get_fragment_info_under_cursor(bufnr)
*   if not fragment_hash then return end
*   print("Got fragment hash")

*   fragments_view.get_alias(function(alias)
*     if not alias or alias == "" then return end
*     print("Got alias")
*     if llm_cli.run_llm_command('fragments alias set ' .. fragment_hash .. ' ' .. alias) then
*       print("Alias set")
*       vim.notify("Alias set: " .. alias .. " -> " .. fragment_hash:sub(1, 8), vim.log.levels.INFO)
*       cache.invalidate('fragments')
*       require('llm.ui.unified_manager').switch_view("Fragments")
      else
0       vim.notify("Failed to set alias", vim.log.levels.ERROR)
      end
    end)
  end

* function M.remove_alias_from_fragment_under_cursor(bufnr)
*   local fragment_hash, fragment_info = M.get_fragment_info_under_cursor(bufnr)
*   if not fragment_hash then return end
*   if #fragment_info.aliases == 0 then
0     vim.notify("Fragment has no aliases", vim.log.levels.WARN)
0     return
    end

*   local alias_to_remove = fragment_info.aliases[1]
*   if #fragment_info.aliases > 1 then
0     fragments_view.select_alias_to_remove(fragment_info.aliases, function(selected_alias)
0       if not selected_alias then return end
0       M.confirm_and_remove_alias(selected_alias)
      end)
    else
*     M.confirm_and_remove_alias(alias_to_remove)
    end
  end

* function M.confirm_and_remove_alias(alias)
*   fragments_view.confirm_remove_alias(alias, function(confirmed)
*     if not confirmed then return end
*     if llm_cli.run_llm_command('fragments alias remove ' .. alias) then
*       vim.notify("Alias removed: " .. alias, vim.log.levels.INFO)
*       cache.invalidate('fragments')
*       require('llm.ui.unified_manager').switch_view("Fragments")
      else
0       vim.notify("Failed to remove alias", vim.log.levels.ERROR)
      end
    end)
  end

* function M.toggle_fragments_view(bufnr)
0   _G.llm_fragments_show_all = not (_G.llm_fragments_show_all or false)
0   require('llm.ui.unified_manager').switch_view("Fragments")
  end

* function M.add_file_fragment(bufnr)
*     fragments_view.select_file(function(file_path)
*         if not file_path then return end
*         llm_cli.run_llm_command('fragments store ' .. file_path)
*         cache.invalidate('fragments')
*         require('llm.ui.unified_manager').switch_view("Fragments")
      end)
  end

* function M.add_github_fragment_from_manager(bufnr)
*     fragments_view.get_github_url(function(url)
*         if not url then return end
*         llm_cli.run_llm_command('fragments store ' .. url)
*         cache.invalidate('fragments')
*         require('llm.ui.unified_manager').switch_view("Fragments")
      end)
  end

* function M.get_fragment_info_under_cursor(bufnr)
0   local current_line = api.nvim_win_get_cursor(0)[1]
0   local line_to_fragment = vim.b[bufnr].line_to_fragment
0   local fragment_data = vim.b[bufnr].fragment_data
0   if not line_to_fragment or not fragment_data then
0     vim.notify("Buffer data missing", vim.log.levels.ERROR)
0     return nil, nil
    end
0   local fragment_hash = line_to_fragment[current_line]
0   if fragment_hash and fragment_data[fragment_hash] then
0     return fragment_hash, fragment_data[fragment_hash]
    end
0   return nil, nil
  end

* function M.manage_fragments(show_all)
0   _G.llm_fragments_show_all = show_all or false
0   require('llm.ui.unified_manager').open_specific_manager("Fragments")
  end

* function M.prompt_with_fragment_under_cursor(bufnr)
0   local fragment_hash, fragment_info = M.get_fragment_info_under_cursor(bufnr)
0   if not fragment_hash then
0     vim.notify("No fragment selected", vim.log.levels.WARN)
0     return
    end

0   local fragment_identifier = fragment_hash

0   api.nvim_win_close(0, true)

0   fragments_view.get_prompt(function(input_prompt)
0     if not input_prompt or input_prompt == "" then
0       vim.notify("Prompt cannot be empty", vim.log.levels.ERROR)
0       return
      end
0     require('llm').prompt(input_prompt, { fragment_identifier })
    end)
  end

* M.__name = 'llm.managers.fragments_manager'

* return M

==============================================================================
lua/llm/managers/templates_manager.lua
==============================================================================
  -- llm/managers/templates_manager.lua - Template management for llm-nvim
  -- License: Apache 2.0

* local M = {}

  -- Forward declarations
* local api = require('llm.api')
* local v_api = vim.api
* local llm_cli = require('llm.core.data.llm_cli')
* local cache = require('llm.core.data.cache')
* local templates_view = require('llm.ui.views.templates_view')
* local styles = require('llm.ui.styles')
* local models_manager = require('llm.managers.models_manager')

  -- Get templates from llm CLI
* function M.get_templates()
*     local cached_templates = cache.get('templates')
*     if cached_templates then
0         return cached_templates
      end

*     local templates_json = llm_cli.run_llm_command('templates list --json')
*     local templates = vim.fn.json_decode(templates_json)
*     cache.set('templates', templates)
*     return templates
  end

  -- Get a specific template from llm CLI
* function M.get_template_details(template_name)
*     local template_json = llm_cli.run_llm_command('templates show ' .. template_name)
*     return vim.fn.json_decode(template_json)
  end

  -- Create a template
  -- Save a template
* function M.save_template(name, prompt, system, model, options, fragments, system_fragments, defaults, extract, schema)
*     local cmd = 'templates save ' .. name
*     if prompt then
*         cmd = cmd .. " --prompt '" .. prompt .. "'"
      end
*     if system then
*         cmd = cmd .. " --system '" .. system .. "'"
      end
*     if model then
*         cmd = cmd .. ' --model ' .. model
      end
*     for k, v in pairs(options) do
*         cmd = cmd .. " -o " .. k .. " '" .. tostring(v) .. "'"
      end
*     for _, f in ipairs(fragments) do
*         cmd = cmd .. ' -f ' .. f
      end
*     for _, f in ipairs(system_fragments) do
*         cmd = cmd .. ' -sf ' .. f
      end
*     for k, v in pairs(defaults) do
*         cmd = cmd .. " -d " .. k .. " '" .. v .. "'"
      end
*     if extract then
*         cmd = cmd .. ' --extract'
      end
*     if schema then
*         cmd = cmd .. ' --schema ' .. schema
      end

*     local result = llm_cli.run_llm_command(cmd)
*     cache.invalidate('templates')
*     return result ~= nil
  end

  -- Delete a template
* function M.delete_template(template_name)
*     local result = llm_cli.run_llm_command('templates delete ' .. template_name .. ' -y')
*     cache.invalidate('templates')
*     return result ~= nil
  end

  -- Run a template
* function M.run_template(template_name, input, params)
*     local cmd = { llm_cli.get_llm_executable_path(), "-t", template_name }
*     if input then
*         table.insert(cmd, "'" .. input .. "'")
      end
*     for k, v in pairs(params) do
*         table.insert(cmd, "-p")
*         table.insert(cmd, k)
*         table.insert(cmd, "'" .. v .. "'")
      end
*     return cmd
  end

  -- Select and run a template
* function M.select_template()
0   local templates = M.get_templates()
0   templates_view.select_template(templates, function(choice)
0     if not choice then return end

      -- If we have a selection, use it directly
0     local has_selection = false
0     local selection = ""
0     local mode = api.nvim_get_mode().mode
0     if mode == 'v' or mode == 'V' or mode == '' then
        -- Get the visual selection
0       selection = require('llm.core.utils.text').get_visual_selection()
0       has_selection = selection ~= ""
      end

0     if has_selection then
0       M.run_template_with_selection(choice.name, selection)
      else
0       M.run_template_with_params(choice.name)
      end
    end)
  end

* function M.run_template_with_selection(template_name, selection)
*   local template = M.get_template_details(template_name)
*   if not template then
0     vim.notify("Failed to get template details", vim.log.levels.ERROR)
0     return
    end

*   local params = {}
*   local param_names = M.extract_params(template)

*   if #param_names > 0 then
0     M.collect_params_and_run(template_name, selection, param_names, template.defaults, function(final_params)
0       local cmd_parts = M.run_template(template_name, selection, final_params)
0       local response_buf = v_api.nvim_create_buf(false, true)
0       v_api.nvim_buf_set_option(response_buf, "buftype", "nofile")
0       v_api.nvim_buf_set_option(response_buf, "bufhidden", "wipe")
0       v_api.nvim_buf_set_option(response_buf, "swapfile", false)
0       v_api.nvim_buf_set_name(response_buf, "Template Result: " .. template_name)
0       require('llm.core.utils.ui').create_floating_window(response_buf, "Template Result: " .. template_name)
0       api.run_llm_command_streamed(cmd_parts, response_buf)
      end)
    else
*     local cmd_parts = M.run_template(template_name, selection, {})
*     local response_buf = v_api.nvim_create_buf(false, true)
*     v_api.nvim_buf_set_option(response_buf, "buftype", "nofile")
*     v_api.nvim_buf_set_option(response_buf, "bufhidden", "wipe")
*     v_api.nvim_buf_set_option(response_buf, "swapfile", false)
*     v_api.nvim_buf_set_name(response_buf, "Template Result: " .. template_name)
*     require('llm.core.utils.ui').create_floating_window(response_buf, "Template Result: " .. template_name)
*     api.run_llm_command_streamed(cmd_parts, response_buf)
    end
  end

* function M.extract_params(template)
*   local param_names = {}
    local function extract(text)
*     if not text then return end
*     for param in text:gmatch("%$([%w_]+)") do
*       if param ~= "input" and not vim.tbl_contains(param_names, param) then
*         table.insert(param_names, param)
        end
      end
    end
*   extract(template.prompt)
*   extract(template.system)
*   return param_names
  end

* function M.collect_params_and_run(template_name, selection, param_names, defaults, callback)
*   local params = {}
    local function collect_next_param(index)
*     if index > #param_names then
*       callback(params)
*       return
      end

*     local param = param_names[index]
*     local default = defaults and defaults[param] or ""

*     templates_view.get_user_input("Enter value for parameter '" .. param .. "':", default, function(value)
*       if value then
*         params[param] = value
*         collect_next_param(index + 1)
        end
      end)
    end
*   collect_next_param(1)
  end

  -- Run a template with parameters
* function M.run_template_with_params(template_name)
0   if not template_name or template_name == "" then
0     vim.notify("Template name cannot be empty", vim.log.levels.ERROR)
0     return
    end

0   local template = M.get_template_details(template_name)
0   if not template then
0     vim.notify("Failed to get template details", vim.log.levels.ERROR)
0     return
    end

0   local param_names = M.extract_params(template)

0   if #param_names > 0 then
0     M.collect_params_and_run(template_name, nil, param_names, template.defaults, function(final_params)
0       M.run_template_with_input(template_name, final_params)
      end)
    else
0     M.run_template_with_input(template_name, {})
    end
  end

  -- Run a template with input (selection, buffer, or URL)
* function M.run_template_with_input(template_name, params)
0   if not template_name or template_name == "" then
0     vim.notify("Template name cannot be empty", vim.log.levels.ERROR)
0     return
    end

0   templates_view.get_input_source(function(choice)
0     if not choice then return end

0     if choice == "Current selection" then
0       local selection = require('llm.core.utils.text').get_visual_selection()
0       if selection == "" then
0         vim.notify("No text selected", vim.log.levels.ERROR)
0         return
        end
0       local cmd_parts = M.run_template(template_name, selection, params)
0       local response_buf = v_api.nvim_create_buf(false, true)
0       v_api.nvim_buf_set_option(response_buf, "buftype", "nofile")
0       v_api.nvim_buf_set_option(response_buf, "bufhidden", "wipe")
0       v_api.nvim_buf_set_option(response_buf, "swapfile", false)
0       v_api.nvim_buf_set_name(response_buf, "Template Result: " .. template_name)
0       require('llm.core.utils.ui').create_floating_window(response_buf, "Template Result: " .. template_name)
0       api.run_llm_command_streamed(cmd_parts, response_buf)
0     elseif choice == "Current buffer" then
0       local lines = v_api.nvim_buf_get_lines(0, 0, -1, false)
0       local content = table.concat(lines, "\n")
0       local cmd_parts = M.run_template(template_name, content, params)
0       local response_buf = v_api.nvim_create_buf(false, true)
0       v_api.nvim_buf_set_option(response_buf, "buftype", "nofile")
0       v_api.nvim_buf_set_option(response_buf, "bufhidden", "wipe")
0       v_api.nvim_buf_set_option(response_buf, "swapfile", false)
0       v_api.nvim_buf_set_name(response_buf, "Template Result: " .. template_name)
0       require('llm.core.utils.ui').create_floating_window(response_buf, "Template Result: " .. template_name)
0       api.run_llm_command_streamed(cmd_parts, response_buf)
0     elseif choice == "URL (will use curl)" then
0       templates_view.get_user_input("Enter URL:", nil, function(url)
0         if not url or url == "" then
0           vim.notify("URL cannot be empty", vim.log.levels.WARN)
0           return
          end
0         local result = M.run_template(template_name, url, params)
0         if result then
0           require('llm.core.utils.ui').create_buffer_with_content(result, "Template Result: " .. template_name, "markdown")
          end
        end)
      end
    end)
  end

  -- Create a template with guided flow
* function M.create_template_guided()
0   templates_view.get_user_input("Enter template name:", nil, function(name)
0     if not name or name == "" then
0       vim.notify("Template name cannot be empty", vim.log.levels.WARN)
0       return
      end
0     if name:match("[/\\]") then
0       vim.notify("Template name cannot contain path separators (/ or \\)", vim.log.levels.ERROR)
0       return
      end

0     local template = { name = name, defaults = {}, options = {}, fragments = {}, system_fragments = {} }
0     M.continue_template_creation_type(template)
    end)
  end

* function M.continue_template_creation_type(template)
0   templates_view.get_template_type(function(type_choice)
0     if not type_choice then return end

0     if type_choice == "Regular prompt" then
0       templates_view.get_user_input("Enter prompt (use $input for user input):", "$input", function(prompt)
0         if not prompt or prompt == "" then
0           vim.notify("Prompt cannot be empty", vim.log.levels.WARN)
0           return
          end
0         template.prompt = prompt
0         M.continue_template_creation_model(template)
        end)
0     elseif type_choice == "System prompt only" then
0       templates_view.get_user_input("Enter system prompt:", nil, function(system)
0         if not system or system == "" then
0           vim.notify("System prompt cannot be empty", vim.log.levels.WARN)
0           return
          end
0         template.system = system
0         M.continue_template_creation_model(template)
        end)
      else -- Both
0       templates_view.get_user_input("Enter system prompt:", nil, function(system)
0         if not system or system == "" then
0           vim.notify("System prompt cannot be empty", vim.log.levels.WARN)
0           return
          end
0         template.system = system
0         templates_view.get_user_input("Enter regular prompt (use $input for user input):", "$input", function(prompt)
0           if not prompt or prompt == "" then
0             vim.notify("Prompt cannot be empty", vim.log.levels.WARN)
0             return
            end
0           template.prompt = prompt
0           M.continue_template_creation_model(template)
          end)
        end)
      end
    end)
  end

* function M.continue_template_creation_model(template)
0   templates_view.get_model_choice(function(model_choice)
0     if not model_choice then return end
0     if model_choice == "Select specific model" then
0       local models = models_manager.get_available_models()
0       templates_view.select_model(models, function(model)
0         if model then
0           template.model = models_manager.extract_model_name(model)
          end
0         M.continue_template_creation_fragments(template)
        end)
      else
0       M.continue_template_creation_fragments(template)
      end
    end)
  end

* function M.continue_template_creation_fragments(template)
0   templates_view.get_fragment_choice(function(fragment_choice)
0     if not fragment_choice then return end
0     if fragment_choice == "Add fragments" then
0       M.add_fragments_loop(template, "fragments", function()
0         M.continue_template_creation_options(template)
        end)
0     elseif fragment_choice == "Add system fragments" then
0       M.add_fragments_loop(template, "system_fragments", function()
0         M.continue_template_creation_options(template)
        end)
      else
0       M.continue_template_creation_options(template)
      end
    end)
  end

* function M.add_fragments_loop(template, fragment_type, on_done)
0   templates_view.get_add_fragment_choice(function(choice)
0     if not choice or choice == "Done adding fragments" then
0       on_done()
0       return
      end

0     if choice == "Select from file browser" then
0       require('llm.managers.fragments_manager').select_file_as_fragment(function(fragment_path)
0         if fragment_path then
0           table.insert(template[fragment_type], fragment_path)
          end
0         M.add_fragments_loop(template, fragment_type, on_done)
        end)
0     elseif choice == "Enter fragment path/URL" then
0       templates_view.get_user_input("Enter fragment path or URL:", nil, function(path)
0         if path and path ~= "" then
0           table.insert(template[fragment_type], path)
          else
0           vim.notify("Fragment path/URL cannot be empty", vim.log.levels.WARN)
          end
0         M.add_fragments_loop(template, fragment_type, on_done)
        end)
      end
    end)
  end

* function M.continue_template_creation_options(template)
0   templates_view.get_option_choice(function(option_choice)
0     if not option_choice or option_choice == "No options" then
0       M.continue_template_creation_params(template)
0       return
      end

0     M.add_options_loop(template, function()
0       M.continue_template_creation_params(template)
      end)
    end)
  end

* function M.add_options_loop(template, on_done)
0   templates_view.get_user_input("Enter option name (or leave empty to finish):", nil, function(name)
0     if not name or name == "" then
0       on_done()
0       return
      end
0     templates_view.get_user_input("Enter value for " .. name .. ":", nil, function(value)
0       if value and value ~= "" then
0         template.options[name] = value
        else
0         vim.notify("Option value cannot be empty", vim.log.levels.WARN)
        end
0       M.add_options_loop(template, on_done)
      end)
    end)
  end

* function M.continue_template_creation_params(template)
0   local params = M.extract_params(template)
0   if #params > 0 then
0     vim.notify("Found parameters: " .. table.concat(params, ", "), vim.log.levels.INFO)
0     M.set_param_defaults_loop(template, params, 1, function()
0       M.continue_template_creation_extract(template)
      end)
    else
0     M.continue_template_creation_extract(template)
    end
  end

* function M.set_param_defaults_loop(template, params, index, on_done)
0   if index > #params then
0     on_done()
0     return
    end
0   local param = params[index]
0   templates_view.get_user_input("Default value for parameter '" .. param .. "' (leave empty for no default):", nil, function(value)
0     if value and value ~= "" then
0       template.defaults[param] = value
      end
0     M.set_param_defaults_loop(template, params, index + 1, on_done)
    end)
  end

* function M.continue_template_creation_extract(template)
0   templates_view.confirm_extract(function(extract)
0     template.extract = extract
0     M.continue_template_creation_schema(template)
    end)
  end

* function M.continue_template_creation_schema(template)
0   templates_view.get_schema_choice(function(schema_choice)
0     if not schema_choice or schema_choice == "No schema" then
0       M.finalize_template_creation(template)
0       return
      end

0     local schemas = require('llm.managers.schemas_manager').get_schemas()
0     templates_view.select_schema(schemas, function(schema_name)
0       if schema_name then
0         template.schema = schema_name
        end
0       M.finalize_template_creation(template)
      end)
    end)
  end

* function M.finalize_template_creation(template)
0   vim.notify("Creating template '" .. template.name .. "'...", vim.log.levels.INFO)
0   local success = M.save_template(
0     template.name,
0     template.prompt,
0     template.system,
0     template.model,
0     template.options,
0     template.fragments,
0     template.system_fragments,
0     template.defaults,
0     template.extract,
      template.schema
    )

0   if success then
0     vim.notify("Template '" .. template.name .. "' created successfully", vim.log.levels.INFO)
0     vim.defer_fn(function()
0       M.manage_templates()
0     end, 500)
    else
0     vim.notify("Failed to create template '" .. template.name .. "'", vim.log.levels.ERROR)
0     vim.defer_fn(function()
0       M.manage_templates()
0     end, 500)
    end
  end

  -- Populate the buffer with template management content
* function M.build_buffer_data(templates)
*   local lines = {
*     "# Template Management",
*     "",
*     "Navigate: [M]odels [P]lugins [K]eys [F]ragments [S]chemas",
*     "Actions: [c]reate [r]un [e]dit [d]elete [v]iew details [q]uit",
*     "──────────────────────────────────────────────────────────────",
*     ""
*   }

*   local template_data = {}
*   local line_to_template = {}
*   local current_line = #lines + 1

*   if #templates == 0 then
*     table.insert(lines, "No templates found. Press 'c' to create one.")
    else
*     for i, template in ipairs(templates) do
*       local description = template.description or ""

*       local entry_lines = {
*         string.format("Template %d: %s", i, template.name),
*         string.format("  Description: %s", description)
*       }
*       table.insert(entry_lines, "")

*       local start_line = current_line
*       local end_line = current_line + #entry_lines - 1

*       for line_num = start_line, end_line do
*         line_to_template[line_num] = template.name
        end

*       template_data[template.name] = {
*         index = i,
*         description = description,
*         start_line = start_line,
*         end_line = end_line,
*       }

*       for _, line in ipairs(entry_lines) do
*         table.insert(lines, line)
        end

*       current_line = current_line + #entry_lines
      end
    end
*   return lines, template_data, line_to_template
  end

  -- Populate the buffer with template management content
* function M.populate_templates_buffer(bufnr)
*   local templates = M.get_templates()
*   local lines, template_data, line_to_template = M.build_buffer_data(templates)

*   v_api.nvim_buf_set_lines(bufnr, 0, -1, false, lines)
*   styles.setup_highlights()
*   styles.setup_buffer_syntax(bufnr)
*   vim.b[bufnr].line_to_template = line_to_template
*   vim.b[bufnr].template_data = template_data
*   vim.b[bufnr].templates = templates
  end

  -- Setup keymaps for the template management buffer
* function M.get_keymap_definitions(bufnr, manager_module)
*   manager_module = manager_module or M
*   return {
*     { mode = 'n', lhs = 'c', rhs = string.format([[<Cmd>lua require('%s').create_template_from_manager(%d)<CR>]], manager_module.__name or 'llm.managers.templates_manager', bufnr) },
*     { mode = 'n', lhs = 'r', rhs = string.format([[<Cmd>lua require('%s').run_template_under_cursor(%d)<CR>]], manager_module.__name or 'llm.managers.templates_manager', bufnr) },
*     { mode = 'n', lhs = 'e', rhs = string.format([[<Cmd>lua require('%s').edit_template_under_cursor(%d)<CR>]], manager_module.__name or 'llm.managers.templates_manager', bufnr) },
*     { mode = 'n', lhs = 'd', rhs = string.format([[<Cmd>lua require('%s').delete_template_under_cursor(%d)<CR>]], manager_module.__name or 'llm.managers.templates_manager', bufnr) },
*     { mode = 'n', lhs = 'v', rhs = string.format([[<Cmd>lua require('%s').view_template_details_under_cursor(%d)<CR>]], manager_module.__name or 'llm.managers.templates_manager', bufnr) },
*   }
  end

  -- Setup keymaps for the template management buffer
* function M.setup_templates_keymaps(bufnr, manager_module)
*   local keymaps = M.get_keymap_definitions(bufnr, manager_module)
*   for _, keymap in ipairs(keymaps) do
*     v_api.nvim_buf_set_keymap(bufnr, keymap.mode, keymap.lhs, keymap.rhs, { noremap = true, silent = true })
    end
  end

* function M.create_template_from_manager(bufnr)
0   require('llm.ui.unified_manager').close()
0   vim.schedule(function()
0     M.create_template()
    end)
  end

* function M.run_template_under_cursor(bufnr)
*   local template_name, template_info = M.get_template_info_under_cursor(bufnr)
0   if not template_name then
*     vim.notify("No template found under cursor", vim.log.levels.ERROR)
0     return
    end

0     require('llm.ui.unified_manager').close()
0     vim.schedule(function()
0       M.run_template_with_params(template_name)
      end)
  end

* function M.edit_template_under_cursor(bufnr)
0   local template_name, _ = M.get_template_info_under_cursor(bufnr)
*   if not template_name then
0     vim.notify("No template found under cursor", vim.log.levels.ERROR)
0     return
    end
0   require('llm.ui.unified_manager').close()
0   vim.schedule(function()
0     M.edit_template(template_name)
    end)
  end

* function M.delete_template_under_cursor(bufnr)
0   local template_name, _ = M.get_template_info_under_cursor(bufnr)
0   if not template_name then
0     vim.notify("No template found under cursor", vim.log.levels.ERROR)
0     return
    end

0   templates_view.confirm_delete(template_name, function(confirmed)
0     if not confirmed then return end
*     vim.schedule(function()
0       local success = M.delete_template(template_name)
*       if success then
0         vim.notify("Template '" .. template_name .. "' deleted", vim.log.levels.INFO)
0         require('llm.ui.unified_manager').switch_view("Templates")
        else
0         vim.notify("Failed to delete template", vim.log.levels.ERROR)
        end
      end)
    end)
  end

* function M.view_template_details_under_cursor(bufnr)
0   local template_name, _ = M.get_template_info_under_cursor(bufnr)
0   if not template_name then
0     vim.notify("No template found under cursor", vim.log.levels.ERROR)
0     return
    end

*   local template = M.get_template_details(template_name)
0   if not template then
*     vim.notify("Failed to get template details for '" .. template_name .. "'", vim.log.levels.ERROR)
0     return
    end

0   require('llm.ui.unified_manager').close()
0   vim.schedule(function()
0     M.show_template_details(template_name, template)
    end)
  end

* function M.show_template_details(template_name, template)
0   local detail_buf = v_api.nvim_create_buf(false, true)
0   v_api.nvim_buf_set_option(detail_buf, "buftype", "nofile")
0   v_api.nvim_buf_set_option(detail_buf, "bufhidden", "wipe")
0   v_api.nvim_buf_set_option(detail_buf, "swapfile", false)
0   v_api.nvim_buf_set_name(detail_buf, "Template Details: " .. template_name)

0   local detail_win = require('llm.core.utils.ui').create_floating_window(detail_buf, 'LLM Template Details: ' .. template_name)

0   local lines = { "# Template: " .. template_name, "" }
0   if template.system and template.system ~= "" then
0     table.insert(lines, "## System Prompt:"); table.insert(lines, ""); table.insert(lines, template.system); table.insert(lines, "")
    end
0   if template.prompt and template.prompt ~= "" then
0     table.insert(lines, "## Prompt:"); table.insert(lines, ""); table.insert(lines, template.prompt); table.insert(lines, "")
    end
0   if template.model and template.model ~= "" then
0     table.insert(lines, "## Model: " .. template.model); table.insert(lines, "")
    end
0   if template.extract then
0     table.insert(lines, "## Extract first code block: Yes"); table.insert(lines, "")
    end
0   if template.schema then
0     table.insert(lines, "## Schema: " .. template.schema); table.insert(lines, "")
    end
0   table.insert(lines, ""); table.insert(lines, "Press [q]uit, [e]dit template, [r]un template")
0   v_api.nvim_buf_set_lines(detail_buf, 0, -1, false, lines)

    local function set_detail_keymap(mode, lhs, rhs)
0     v_api.nvim_buf_set_keymap(detail_buf, mode, lhs, rhs, { noremap = true, silent = true })
    end

0   set_detail_keymap("n", "q", [[<cmd>lua vim.api.nvim_win_close(0, true)<CR>]])
0   set_detail_keymap("n", "<Esc>", [[<cmd>lua vim.api.nvim_win_close(0, true)<CR>]])
0   set_detail_keymap("n", "e", string.format([[<Cmd>lua require('llm.managers.templates_manager').edit_template_from_details('%s')<CR>]], template_name))
0   set_detail_keymap("n", "r", string.format([[<Cmd>lua require('llm.managers.templates_manager').run_template_with_params('%s')<CR>]], template_name))

0   styles.setup_buffer_styling(detail_buf)
  end

* function M.get_template_info_under_cursor(bufnr)
0   local current_line = v_api.nvim_win_get_cursor(0)[1]
0   local line_to_template = vim.b[bufnr].line_to_template
0   local template_data = vim.b[bufnr].template_data
0   if not line_to_template or not template_data then
0     vim.notify("Buffer data missing", vim.log.levels.ERROR)
*     return nil, nil
    end

0   for template_name, data in pairs(template_data) do
*     if current_line >= data.start_line and current_line <= data.end_line then
0       return template_name, data
      end
    end

0   return nil, nil
  end

* function M.manage_templates()
0   require('llm.ui.unified_manager').open_specific_manager("Templates")
  end

* M.__name = 'llm.managers.templates_manager'

* function M.run_template_by_name(template_name)
0   if not template_name or template_name == "" then
0     vim.notify("No template name provided", vim.log.levels.ERROR)
0     return
    end
0   local templates = M.get_templates()
0   local found = false
0   for _, t in ipairs(templates) do
0     if t.name == template_name then
0       found = true
        break
      end
    end
*   if not found then
0     vim.notify("Template '" .. template_name .. "' not found", vim.log.levels.ERROR)
0     return
    end
0   require('llm.ui.unified_manager').close()
*   vim.schedule(function()
0     M.run_template_with_params(template_name)
    end)
  end

* function M.edit_template_from_details(template_name)
0   v_api.nvim_win_close(0, true)
0   vim.schedule(function()
0     M.edit_template(template_name)
    end)
  end

* return M

==============================================================================
lua/llm/managers/custom_openai.lua
==============================================================================
  -- llm/managers/custom_openai.lua - Custom OpenAI model management
  -- License: Apache 2.0

* local M = {}
* local config = require('llm.config')
* local keys_manager = require('llm.managers.keys_manager')
* local file_utils = require('llm.core.utils.file_utils')
* local text_utils = require('llm.core.utils.text')

  -- Cache for custom OpenAI models
* M.custom_openai_models = {}

* function M.get_custom_openai_models()
0   return M.custom_openai_models
  end

  -- Default values for model properties
* local DEFAULT_MODEL_PROPERTIES = {
*   needs_auth = true,
*   supports_functions = false,
*   supports_system_prompt = true,
*   headers = nil,
*   api_base = nil,
*   api_key_name = nil,
  }

  -- Load custom OpenAI models from extra-openai-models.yaml
* function M.load_custom_openai_models()
*   M.custom_openai_models = {} -- Clear the cache

*   local _, yaml_path = file_utils.get_config_path("extra-openai-models.yaml")
*   if config.get("debug") then
0     vim.notify("Looking for custom OpenAI models at: " .. (yaml_path or "path not found"), vim.log.levels.INFO)
    end

*   if not yaml_path then
*     vim.notify("Could not determine or create config directory for extra-openai-models.yaml", vim.log.levels.WARN)
*     return {}
    end

*   local file = io.open(yaml_path, "r")
*   if not file then
*     if config.get("debug") then
0       vim.notify("extra-openai-models.yaml not found at: " .. yaml_path .. ". No custom models loaded.", vim.log.levels.INFO)
      end
*     return {}
    end

*   local content = file:read("*a")
*   file:close()
*   if not content or content == "" then
0     if config.get("debug") then
0       vim.notify("extra-openai-models.yaml is empty. No custom models loaded.", vim.log.levels.INFO)
      end
0     return {}
    end

*   local parsed_data = text_utils.parse_simple_yaml(yaml_path)
*   if not parsed_data then
*     if config.get("debug") then
0       vim.notify("Failed to parse YAML file: " .. yaml_path .. ". Backing up and proceeding as if empty.", vim.log.levels.WARN)
      end
*     local backup_path = yaml_path .. ".parse_failed_backup." .. os.time()
*     os.rename(yaml_path, backup_path)
*     vim.notify("Backed up unparsable YAML to: " .. backup_path, vim.log.levels.WARN)
*     return {}
    end

    -- Check if parsed_data is a list
*   local is_list = type(parsed_data) == 'table'
*   if is_list then
*     local count = 0
*     for k, _ in pairs(parsed_data) do
*       count = count + 1
*       if type(k) ~= 'number' or k < 1 then is_list = false; break end
      end
*     if count > 0 and not parsed_data[1] then is_list = false end
*     if #parsed_data ~= count then is_list = false end
    end

*   if not is_list then
0     if config.get("debug") then
0       vim.notify("YAML content in " .. yaml_path .. " is not a list. Backing up and proceeding as if empty.", vim.log.levels.WARN)
      end
0     local backup_path = yaml_path .. ".non_list_backup." .. os.time()
0     os.rename(yaml_path, backup_path)
0     vim.notify("Backed up non-list YAML to: " .. backup_path, vim.log.levels.WARN)
0     return {}
    end

*   for i, model_def in ipairs(parsed_data) do
*     if type(model_def) == 'table' then
*       local primary_id = model_def.model_id
*       if not primary_id or primary_id == "" then
0         if config.get("debug") then
0           vim.notify("Skipping model definition at index " .. i .. " due to missing 'model_id'", vim.log.levels.WARN)
          end
        else
*         local model_data = {
*           model_id = primary_id,
*           model_name = model_def.model_name or primary_id,
*           api_base = model_def.api_base or DEFAULT_MODEL_PROPERTIES.api_base,
*           api_key_name = model_def.api_key_name or DEFAULT_MODEL_PROPERTIES.api_key_name,
*           headers = DEFAULT_MODEL_PROPERTIES.headers, -- Default to nil
*           needs_auth = (model_def.needs_auth == nil) and DEFAULT_MODEL_PROPERTIES.needs_auth or model_def.needs_auth,
*           supports_functions = (model_def.supports_functions == nil) and DEFAULT_MODEL_PROPERTIES.supports_functions or model_def.supports_functions,
*           supports_system_prompt = (model_def.supports_system_prompt == nil) and DEFAULT_MODEL_PROPERTIES.supports_system_prompt or model_def.supports_system_prompt,
*           is_valid = false -- Will be set by M.is_custom_openai_model_valid
          }

          -- Handle headers (string or table)
*         if model_def.headers then
0           if type(model_def.headers) == 'string' then
0             local success, decoded_headers = pcall(vim.fn.json_decode, model_def.headers)
0             if success then
0               model_data.headers = decoded_headers
              else
0               if config.get("debug") then
0                 vim.notify("Failed to parse JSON string for headers for model " .. primary_id .. ": " .. model_def.headers, vim.log.levels.WARN)
                end
              end
0           elseif type(model_def.headers) == 'table' then
0             model_data.headers = model_def.headers
            end
          end

          -- Validate the model (sets model_data.is_valid)
*         M.is_custom_openai_model_valid(model_data) -- Pass the whole model_data for validation context

*         M.custom_openai_models[primary_id] = model_data
*         if config.get("debug") then
0           vim.notify(string.format("Loaded custom model: ID=%s, Name=%s, Valid=%s, Auth=%s, Funcs=%s, SysPrompt=%s, Headers=%s",
0             primary_id, model_data.model_name, tostring(model_data.is_valid), tostring(model_data.needs_auth),
0             tostring(model_data.supports_functions), tostring(model_data.supports_system_prompt), vim.inspect(model_data.headers)), vim.log.levels.DEBUG)
          end
        end
      else
0       if config.get("debug") then
0         vim.notify("Skipping non-table entry in parsed YAML data at index " .. i, vim.log.levels.WARN)
        end
      end
    end
*   return M.custom_openai_models
  end

  -- Check if a custom OpenAI model identifier corresponds to a valid configuration
  -- Can be called with a model_id string or directly with a model_data table
* function M.is_custom_openai_model_valid(model_identifier_or_data)
    local model_info
*   if type(model_identifier_or_data) == 'string' then
*     if not model_identifier_or_data or model_identifier_or_data == "" then return false end
      -- Ensure models are loaded if called with just an ID
*     if vim.tbl_isempty(M.custom_openai_models) then
*       M.load_custom_openai_models()
      end
*     model_info = M.custom_openai_models[model_identifier_or_data]
*   elseif type(model_identifier_or_data) == 'table' then
*     model_info = model_identifier_or_data -- model_data was passed directly
    else
0     return false -- Invalid argument
    end

*   if not model_info then return false end

    -- If needs_auth is explicitly false, model is valid (even without API key name or set key)
*   if model_info.needs_auth == false then
*     model_info.is_valid = true
*     return true
    end

    -- If needs_auth is true (or default), api_key_name must exist and key must be set
*   if model_info.api_key_name and model_info.api_key_name ~= "" then
*     if keys_manager.is_key_set(model_info.api_key_name) then
*       model_info.is_valid = true
*       return true
      else
*       if config.get("debug") then
0         vim.notify("API key '" .. model_info.api_key_name .. "' not set for custom model: " .. model_info.model_id, vim.log.levels.DEBUG)
        end
*       model_info.is_valid = false
*       return false
      end
    else
      -- needs_auth is true but no api_key_name defined
0     if config.get("debug") then
0       vim.notify("Custom model '" .. model_info.model_id .. "' requires auth but no api_key_name is defined.", vim.log.levels.DEBUG)
      end
0     model_info.is_valid = false
0     return false
    end
  end

  -- Debug function for custom models
* function M.debug_custom_openai_models()
0   local config_dir, yaml_path = file_utils.get_config_path("extra-openai-models.yaml")

0   vim.notify("Debug information for custom OpenAI models:", vim.log.levels.INFO)
0   vim.notify("Config directory: " .. (config_dir or "not found"), vim.log.levels.INFO)
0   vim.notify("YAML path: " .. (yaml_path or "not found"), vim.log.levels.INFO)

    -- Check file existence and content
0   if yaml_path then
0     local file = io.open(yaml_path, "r")
0     if file then
0       local content = file:read("*a")
0       file:close()
0       vim.notify("File exists with " .. #content .. " bytes", vim.log.levels.INFO)
      end
    end

    -- Load and show models
0   M.load_custom_openai_models()
0   vim.notify("Found " .. vim.tbl_count(M.custom_openai_models) .. " custom OpenAI models", vim.log.levels.INFO)

0   for name, model in pairs(M.custom_openai_models) do
0     local status = model.is_valid and "valid" or "invalid"
0     vim.notify(string.format("Model: %s, Status: %s, API Key: %s, Has API Base: %s",
0       name, status, model.api_key_name or "not set", model.has_api_base and "yes" or "no"), vim.log.levels.INFO)
    end

0   return M.custom_openai_models
  end

  -- Create sample YAML file
* function M.create_sample_yaml_file()
0   local config_dir, yaml_path = file_utils.get_config_path("extra-openai-models.yaml.sample")

0   if not config_dir then
0     vim.notify("Could not find config directory", vim.log.levels.ERROR)
0     return false
    end

    local sample_content = [[# Sample extra-openai-models.yaml
  # This file allows defining custom OpenAI-compatible models or overriding properties.
  # Models are defined as a YAML list.
  #
  # - model_id: (Required) The unique identifier for the model.
  #   model_name: (Optional) A user-friendly display name. Defaults to model_id.
  #   api_base: (Optional) The base URL for the API.
  #               Example: https://api.example.com/v1
  #   api_key_name: (Optional) The name of the key to use from keys.json.
  #                 Required if 'needs_auth' is true or not specified.
  #                 Example: my_custom_api_key
  #   headers: (Optional) Custom headers to send with requests.
  #            Can be a JSON string or a YAML map.
  #            Example as JSON string: '{"X-My-Header": "value"}'
  #            Example as YAML map:
  #              X-My-Header: value
  #              Authorization: Bearer your_static_token # If token is static and not from keys.json
  #   needs_auth: (Optional) Whether this model requires an API key via 'api_key_name'.
  #               Default: true
  #   supports_functions: (Optional) Whether this model supports function calling.
  #                       Default: false
  #   supports_system_prompt: (Optional) Whether this model supports system prompts.
  #                           Default: true

  - model_id: my-custom-gpt4-turbo
    model_name: My Custom GPT-4 Turbo (Needs Auth)
    api_base: https://my.openai.proxy/v1
    api_key_name: my_proxy_key # Must be set in keys.json
    # headers: '{"X-Custom-Billing-ID": "project-123"}' # Example JSON string for headers
    # supports_functions: true # Uncomment if it supports functions

  - model_id: anyscale-llama3-70b
    model_name: Anyscale Llama3 70B
    api_base: https://api.endpoints.anyscale.com/v1
    api_key_name: anyscale_token # Must be set in keys.json
    supports_functions: true
    supports_system_prompt: true

  - model_id: local-model-no-auth
    model_name: Local Model (No Auth)
    api_base: http://localhost:1234/v1
    needs_auth: false # No API key needed
    supports_system_prompt: false
    # headers: # Example YAML map for headers
    #   X-Forwarded-To: "llm-nvim"

  # - model_id: azure-deployment-id # Example for Azure
  #   model_name: Azure GPT-4 Turbo
  #   api_base: https://your-resource.openai.azure.com/openai/deployments/YOUR_DEPLOYMENT_ID
  #   api_key_name: azure_openai_key # Key for your Azure OpenAI service in keys.json
  #   # For Azure, 'api-version' is often required in headers or as a query param.
  #   # If using headers:
  #   # headers:
  #   #   api-key: Will be overridden by keys.json if api_key_name is also set.
  #   #            Prefer api_key_name for dynamic keys.
  #   #   Api-Version: "2024-02-15-preview" # Or your desired API version
  #   # If needs_auth is true (default), the key from api_key_name will be added
  #   # to headers as 'Authorization: Bearer <key_value>'.
  #   # If your Azure setup needs 'api-key' header instead, manage it through static headers
  #   # and potentially set needs_auth: false if the key is only in the header.
0 ]]

0   local file = io.open(yaml_path, "w")
0   if not file then
0     vim.notify("Could not create sample YAML file: " .. yaml_path, vim.log.levels.ERROR)
0     return false
    end

0   file:write(sample_content)
0   file:close()

0   vim.notify("Created sample YAML file at: " .. yaml_path, vim.log.levels.INFO)
0   return true
  end

  -- Helper function to serialize a list of models to YAML
* function M.serialize_to_yaml(models_list)
0   local yaml_lines = {}
0   if not models_list or #models_list == 0 then
0     return ""
    end

0   for _, model in ipairs(models_list) do
0     if model.model_id and model.model_id ~= "" then
0       table.insert(yaml_lines, "- model_id: " .. model.model_id)

0       if model.model_name and model.model_name ~= "" then
0         table.insert(yaml_lines, "  model_name: " .. model.model_name)
        end
0       if model.api_base and model.api_base ~= "" then
0         table.insert(yaml_lines, "  api_base: " .. model.api_base)
        end
0       if model.api_key_name and model.api_key_name ~= "" then
0         table.insert(yaml_lines, "  api_key_name: " .. model.api_key_name)
        end

        -- Handle headers: serialize table to JSON string
0       if model.headers then
0         if type(model.headers) == 'table' and not vim.tbl_isempty(model.headers) then
0           local success, json_str = pcall(vim.fn.json_encode, model.headers)
0           if success then
              -- Represent JSON string as a YAML string literal (e.g., using single quotes)
0             table.insert(yaml_lines, "  headers: '" .. json_str:gsub("'", "''") .. "'")
0           elseif config.get("debug") then
0             vim.notify("Failed to serialize headers table to JSON for model " .. model.model_id, vim.log.levels.WARN)
            end
0         elseif type(model.headers) == 'string' and model.headers ~= "" then
             -- If it's already a string (presumably JSON), quote it properly for YAML
0            table.insert(yaml_lines, "  headers: '" .. model.headers:gsub("'", "''") .. "'")
          end
        end

0       if model.needs_auth == false then -- Only write if explicitly false (default is true)
0         table.insert(yaml_lines, "  needs_auth: false")
        end
0       if model.supports_functions == true then -- Only write if explicitly true (default is false)
0         table.insert(yaml_lines, "  supports_functions: true")
        end
0       if model.supports_system_prompt == false then -- Only write if explicitly false (default is true)
0         table.insert(yaml_lines, "  supports_system_prompt: false")
        end
      else
0       if config.get("debug") then
0         vim.notify("Skipping serialization of model due to missing model_id: " .. vim.inspect(model), vim.log.levels.WARN)
        end
      end
    end
0   return table.concat(yaml_lines, "\n") .. "\n"
  end

  -- Add a new custom OpenAI model to the extra-openai-models.yaml file
* function M.add_custom_openai_model(model_details)
0   if not model_details or not model_details.model_id or model_details.model_id == "" then
0     return false, "model_id is required"
    end

0   local _, yaml_path = file_utils.get_config_path("extra-openai-models.yaml")
0   if not yaml_path then
0     return false, "Could not determine or create config directory for extra-openai-models.yaml"
    end

0   local models_list = {}
0   local file = io.open(yaml_path, "r")
0   if file then
0     local content = file:read("*a")
0     file:close()
0     if content and content ~= "" then
0       local parsed_data = text_utils.parse_simple_yaml(yaml_path)
0       if type(parsed_data) == 'table' then
0         local is_list = true
0         local count = 0
0         for k, _ in pairs(parsed_data) do count = count + 1; if type(k) ~= 'number' or k < 1 then is_list = false; break end end
0         if count > 0 and not parsed_data[1] then is_list = false end
0         if #parsed_data ~= count then is_list = false end

0         if is_list then
0           models_list = parsed_data
          else
0           if config.get("debug") then vim.notify("YAML content in " .. yaml_path .. " is not a list. Backing up.", vim.log.levels.WARN) end
0           local backup_path = yaml_path .. ".non_list_backup." .. os.time()
0           os.rename(yaml_path, backup_path)
0           vim.notify("Backed up non-list YAML to: " .. backup_path, vim.log.levels.WARN)
0           models_list = {}
          end
        else
0         if config.get("debug") then vim.notify("Failed to parse YAML in " .. yaml_path .. ". Backing up.", vim.log.levels.WARN) end
0         local backup_path = yaml_path .. ".parse_failed_backup." .. os.time()
0         os.rename(yaml_path, backup_path)
0         vim.notify("Backed up unparsable YAML to: " .. backup_path, vim.log.levels.WARN)
0         models_list = {}
        end
      end
    end

    -- Prepare the new model entry with defaults for new fields
0   local new_model_entry = {
      model_id = model_details.model_id,
      model_name = (model_details.model_name and model_details.model_name ~= "") and model_details.model_name or model_details.model_id,
      api_base = (model_details.api_base and model_details.api_base ~= "") and model_details.api_base or DEFAULT_MODEL_PROPERTIES.api_base,
      api_key_name = (model_details.api_key_name and model_details.api_key_name ~= "") and model_details.api_key_name or DEFAULT_MODEL_PROPERTIES.api_key_name,
      needs_auth = (model_details.needs_auth == nil) and DEFAULT_MODEL_PROPERTIES.needs_auth or model_details.needs_auth,
      supports_functions = (model_details.supports_functions == nil) and DEFAULT_MODEL_PROPERTIES.supports_functions or model_details.supports_functions,
      supports_system_prompt = (model_details.supports_system_prompt == nil) and DEFAULT_MODEL_PROPERTIES.supports_system_prompt or model_details.supports_system_prompt,
      headers = DEFAULT_MODEL_PROPERTIES.headers,
    }

0   if model_details.headers then
0     if type(model_details.headers) == 'table' then
0       new_model_entry.headers = model_details.headers
0     elseif type(model_details.headers) == 'string' and model_details.headers ~= "" then
0       local success, decoded = pcall(vim.fn.json_decode, model_details.headers)
0       if success and type(decoded) == 'table' then
0         new_model_entry.headers = decoded
        else
0         if config.get("debug") then vim.notify("Could not parse headers JSON string when adding model: " .. model_details.headers, vim.log.levels.WARN) end
           -- Store as string if not parsable as table, serializer will handle it.
0         new_model_entry.headers = model_details.headers
        end
      end
    end

0   table.insert(models_list, new_model_entry)
0   local yaml_content = M.serialize_to_yaml(models_list)

0   local out_file = io.open(yaml_path, "w")
0   if not out_file then
0     return false, "Failed to open YAML file for writing: " .. yaml_path
    end

0   out_file:write(yaml_content)
0   out_file:close()

    -- Clear the cache so it reloads next time
0   M.custom_openai_models = {}

0   return true, nil -- Success, no error message
  end

  -- Delete a custom OpenAI model from the extra-openai-models.yaml file
* function M.delete_custom_openai_model(model_id)
0   if not model_id or model_id == "" then
0     return false, "model_id is required"
    end

0   local _, yaml_path = file_utils.get_config_path("extra-openai-models.yaml")
0   if not yaml_path then
0     return false, "Could not determine or create config directory for extra-openai-models.yaml"
    end

0   local models_list = {}
0   local file = io.open(yaml_path, "r")
0   if file then
0     local content = file:read("*a")
0     file:close()
0     if content and content ~= "" then
0       local parsed_data = text_utils.parse_simple_yaml(yaml_path)
0       if type(parsed_data) == 'table' then
0         local is_list = true
0         local count = 0
0         for k, _ in pairs(parsed_data) do count = count + 1; if type(k) ~= 'number' or k < 1 then is_list = false; break end end
0         if count > 0 and not parsed_data[1] then is_list = false end
0         if #parsed_data ~= count then is_list = false end

0         if is_list then
0           models_list = parsed_data
          else
0           if config.get("debug") then vim.notify("YAML content in " .. yaml_path .. " is not a list. Backing up.", vim.log.levels.WARN) end
0           local backup_path = yaml_path .. ".non_list_backup." .. os.time()
0           os.rename(yaml_path, backup_path)
0           vim.notify("Backed up non-list YAML to: " .. backup_path, vim.log.levels.WARN)
0           models_list = {}
          end
        else
0         if config.get("debug") then vim.notify("Failed to parse YAML in " .. yaml_path .. ". Backing up.", vim.log.levels.WARN) end
0         local backup_path = yaml_path .. ".parse_failed_backup." .. os.time()
0         os.rename(yaml_path, backup_path)
0         vim.notify("Backed up unparsable YAML to: " .. backup_path, vim.log.levels.WARN)
0         models_list = {}
        end
      end
    end

0   local new_models_list = {}
0   for _, model in ipairs(models_list) do
0     if model.model_id ~= model_id then
0       table.insert(new_models_list, model)
      end
    end

0   local yaml_content = M.serialize_to_yaml(new_models_list)

0   local out_file = io.open(yaml_path, "w")
0   if not out_file then
0     return false, "Failed to open YAML file for writing: " .. yaml_path
    end

0   out_file:write(yaml_content)
0   out_file:close()

    -- Clear the cache so it reloads next time
0   M.custom_openai_models = {}

0   return true, nil -- Success, no error message
  end

* return M

==============================================================================
lua/llm/managers/models_manager.lua
==============================================================================
  -- llm/managers/models_manager.lua - Model management functionality
  -- License: Apache 2.0

* local errors = require('llm.errors')
* local M = {}

  -- Forward declarations
* local api = vim.api
* local fn = vim.fn
* local llm_cli = require('llm.core.data.llm_cli')
* local cache = require('llm.core.data.cache')
* local config = require('llm.config')
* local styles = require('llm.ui.styles')


* local custom_openai = require('llm.managers.custom_openai')
* local models_io = require('llm.managers.models_io')
* local models_view = require('llm.ui.views.models_view')

* function M.set_custom_openai(new_custom_openai)
0   custom_openai = new_custom_openai
  end

* function M.set_models_io(new_models_io)
0   models_io = new_models_io
  end

  -- Add pattern escape function to vim namespace if it doesn't exist
* if not vim.pesc then
*   vim.pesc = function(s)
0     return string.gsub(s, "[%(%)%.%+%-%*%?%[%]%^%$%%]", "%%%1")
    end
  end

  -- Get custom OpenAI models
* function M.get_custom_openai_models()
0   return custom_openai.custom_openai_models
  end

  -- Force reload custom OpenAI models
* function M.reload_custom_openai_models()
0   return custom_openai.load_custom_openai_models()
  end

  -- Get available providers with valid API keys
* function M.get_available_providers()
0   local keys_manager = require('llm.managers.keys_manager')
0   local plugins_manager = require('llm.managers.plugins_manager')

0   return {
      -- OpenAI only requires the API key, not a plugin
      OpenAI = keys_manager.is_key_set("openai"),
      Anthropic = keys_manager.is_key_set("anthropic"),
      Mistral = keys_manager.is_key_set("mistral"),
      Gemini = keys_manager.is_key_set("gemini"),                 -- Corrected key name from "google" to "gemini"
      Groq = keys_manager.is_key_set("groq"),
      Ollama = plugins_manager.is_plugin_installed("llm-ollama"), -- Corrected plugin name from "ollama" to "llm-ollama"
      -- Local models are always available
0     Local = true
    }
  end

  -- Check if a specific model is available (used when setting default)
* function M.is_model_available(model_line)
*   local providers = M.get_available_providers()
*   local model_name = M.extract_model_name(model_line)

*   if config.get("debug") then
0     vim.notify("Checking if model is available: " .. model_line, vim.log.levels.DEBUG)
0     vim.notify("Extracted model name: " .. model_name, vim.log.levels.DEBUG)
    end

    -- Check for custom OpenAI models (from extra-openai-models.yaml)
*   if (model_line:match("OpenAI") and model_line:match("%(custom%)")) or
*       model_line:match("^Custom OpenAI:") or
*       model_line:match("^Azure OpenAI:") then
0     if config.get("debug") then
0       vim.notify("Checking custom model availability: " .. model_name, vim.log.levels.INFO)
      end
      -- For custom models, check validity using the dedicated function and the extracted name/id
0     return custom_openai.is_custom_openai_model_valid(model_name)
*   elseif model_line:match("OpenAI") then
      -- Check if this standard-looking OpenAI model is actually a custom one
*     if custom_openai.is_custom_openai_model_valid(model_name) then
0       if config.get("debug") then
0         vim.notify("Identified standard OpenAI line as custom model: " .. model_name, vim.log.levels.INFO)
        end
0       return true -- Validity is checked by is_custom_openai_model_valid
      end
      -- Regular OpenAI only requires the API key
*     return providers.OpenAI
0   elseif model_line:match("Anthropic") then
0     return providers.Anthropic
0   elseif model_line:match("Mistral") then
0     return providers.Mistral
0   elseif model_line:match("Gemini") then
0     return providers.Gemini
0   elseif model_line:match("Groq") then
0     return providers.Groq
0   elseif model_line:match("ollama") then
0     return providers.Ollama
0   elseif model_line:match("gguf") or model_line:match("local") then
0     return providers.Local
    end

    -- Default to true if we can't determine requirements
0   return true
  end

  -- Get available models from llm CLI
* function M.get_available_models()
*   local cached_models = cache.get('models')
*   if cached_models then
*     vim.notify("DEBUG: Cache hit for models at " .. os.time(), vim.log.levels.DEBUG)
*     return cached_models
    end

*   vim.notify("DEBUG: Cache miss for models. Running llm models list at " .. os.time(), vim.log.levels.DEBUG)
*   local models_json = llm_cli.run_llm_command('models list')
*   vim.notify("DEBUG: llm models list command finished at " .. os.time(), vim.log.levels.DEBUG)
*   if not models_json then return {} end
*   local models = {}
*   for line in models_json:gmatch("[^\n]+") do
*     if not line:match("^%-%-") and line ~= "" and not line:match("^Models:") and not line:match("^Default:") then
        local provider, model_id
        -- Try to match known prefixes first
*       if line:match("^OpenAI Chat: ") then
0         provider = "OpenAI Chat"
0         model_id = line:gsub("^OpenAI Chat: ", "")
*       elseif line:match("^OpenAI Completion: ") then
0         provider = "OpenAI Completion"
0         model_id = line:gsub("^OpenAI Completion: ", "")
*       elseif line:match("^Anthropic Messages: ") then
0         provider = "Anthropic Messages"
0         model_id = line:gsub("^Anthropic Messages: ", "")
*       elseif line:match("^DeepSeek: ") then
0         provider = "DeepSeek"
0         model_id = line:gsub("^DeepSeek: ", "")
*       elseif line:match("^GeminiPro: ") then
0         provider = "GeminiPro"
0         model_id = line:gsub("^GeminiPro: ", "")
*       elseif line:match("^Ollama: ") then
0         provider = "Ollama"
0         model_id = line:gsub("^Ollama: ", "")
        else
          -- Fallback to generic provider: model_id parsing
*         provider, model_id = line:match("([^:]+):%s*(.+)")
        end

*       if provider and model_id then
0         local clean_model_id = model_id:gsub("%s*%s*%(aliases.-%)", "")
0         table.insert(models, { provider = provider, id = clean_model_id, name = clean_model_id })
        else
          -- Handle lines without a provider or unparseable lines
*         table.insert(models, { provider = "Other", id = line, name = line })
        end
      end
    end
*   cache.set('models', models)
*   return models
  end

  -- Extract model name from the full model line
* function M.extract_model_name(model_line)
*   if not model_line or model_line == "" then
0     if config.get("debug") then
0       vim.notify("extract_model_name called with empty model_line", vim.log.levels.DEBUG)
      end
0     return ""
    end

    -- Handle custom OpenAI models specially
*   if model_line:match("OpenAI") and model_line:match("%(custom%)") then
0     local model_name = model_line:match(": ([^%(]+)")
0     if model_name then
        -- Trim whitespace
0       model_name = model_name:match("^%s*(.-)%s*$")
0       return model_name
      end
    end

    -- Handle "Custom OpenAI:" format as well
*   if model_line:match("^Custom OpenAI:") then
0     local model_name = model_line:match("^Custom OpenAI:%s*(.+)")
0     if model_name then
        -- Trim whitespace
0       model_name = model_name:match("^%s*(.-)%s*$")
0       return model_name
      end
    end

    -- Extract the actual model name (after the provider type)
*   local model_name = model_line:match(": ([^%(]+)")
*   if model_name then
      -- Trim whitespace
*     model_name = model_name:match("^%s*(.-)%s*$")
*     return model_name
    end

    -- Try to match format like "Anthropic Messages: anthropic/claude-3-opus-20240229"
0   model_name = model_line:match(": ([^%s]+)")
0   if model_name then
0     return model_name
    end

    -- Fallback to the full line if no patterns match
    -- This ensures we can still find the model in the list
0   return model_line
  end

  -- Set the default model using llm CLI
* function M.set_default_model(model_name)
*   local result = models_io.set_default_model_in_cli(model_name)
*   if result then
*     cache.invalidate('models')
    end
*   return result
  end

  -- Get model aliases from llm CLI
* function M.get_model_aliases()
0   local cached_aliases = cache.get('aliases')
0   if cached_aliases then
0     vim.notify("DEBUG: Cache hit for aliases at " .. os.time(), vim.log.levels.DEBUG)
0     return cached_aliases
    end

0   vim.notify("DEBUG: Cache miss for aliases. Running llm aliases list --json at " .. os.time(), vim.log.levels.DEBUG)
0   local aliases_json = llm_cli.run_llm_command('aliases list --json')
0   vim.notify("DEBUG: llm aliases list --json command finished at " .. os.time(), vim.log.levels.DEBUG)
0   if not aliases_json then return {} end
0   local aliases = vim.fn.json_decode(aliases_json)
0   cache.set('aliases', aliases)
0   return aliases
  end

  -- Set a model alias using llm CLI
* function M.set_model_alias(alias, model)
*   local result = models_io.set_alias_in_cli(alias, model)
*   if result then
*     cache.invalidate('aliases')
    end
*   return result
  end

  -- Remove a model alias by directly modifying the aliases.json file
* function M.remove_model_alias(alias)
*   local result = models_io.remove_alias_in_cli(alias)
*   if result then
*     cache.invalidate('aliases')
    end
*   return result
  end

  -- Select a model to use (now primarily for direct selection, not management)
* function M.select_model()
0   local models = M.get_available_models()

0   if #models == 0 then
0     api.nvim_err_writeln("No models found. Make sure llm is properly configured.")
0     return
    end

0   models_view.select_model(models, function(choice)
0     if not choice then return end
0     local model_name = M.extract_model_name(choice.id)
0     config.options.model = model_name
0     vim.notify("Model set to: " .. model_name, vim.log.levels.INFO)
    end)
  end

  -- Populate the buffer with model management content
  -- Generate the list of models for the management buffer
* function M.generate_models_list()
0   local models = M.get_available_models()
0   if #models == 0 then
0     return {
0       lines = {
          "# Model Management - No Models Found",
          "",
          "No models found. Make sure llm CLI is properly installed and configured.",
          "Use the [K]eys manager to set up API keys for your providers.",
          "Or use the [P]lugins manager to install required plugins.",
          "",
          "Press [q]uit or use navigation keys ([P]lugins, [K]eys, etc.)"
        },
        line_to_model_id = {},
0       model_data = {}
      }
    end

0   local aliases = M.get_model_aliases()
0   local default_model_output = llm_cli.run_llm_command('models default')
0   local default_model = ""
0   if default_model_output and default_model_output ~= "" then
0     default_model = default_model_output:match("Default model: (.+)") or default_model_output:match("(.+)")
    end

0   local lines = {
      "# Model Management",
      "",
      "Navigate: [P]lugins [K]eys [F]ragments [T]emplates [S]chemas",
      "Actions: [s]et default [a]dd alias [r]emove alias [c]ustom model [q]uit", -- Updated actions
      "──────────────────────────────────────────────────────────────",
      ""
    }
    -- Create reverse lookup and group models
0   local providers = {
      ["OpenAI"] = {},
      ["Custom OpenAI"] = {},
      ["Anthropic Messages"] = {},
      ["Mistral"] = {},
      ["GeminiPro"] = {},
      ["DeepSeek"] = {},
      ["Groq"] = {},
      ["Local Models"] = {},
      ["Ollama"] = {},
0     ["Other"] = {}
    }
0   local processed_custom_model_ids = {} -- Set to track added custom model IDs

    -- Ensure custom OpenAI models are loaded before processing
0   custom_openai.load_custom_openai_models()
0   local model_to_aliases = {}
0   for alias, model in pairs(aliases) do
0     if not model_to_aliases[model] then model_to_aliases[model] = {} end
0     table.insert(model_to_aliases[model], alias)
    end

0   for _, model in ipairs(models) do
0     local extracted_name = model.id -- This is the name/id part of the line
0     local model_id = model.id       -- Default model_id to extracted name
0     local model_name = model.name   -- Default model_name to extracted name
0     local is_custom = false
      local custom_model_info = nil

      -- Determine provider and potentially find custom model info
0     local provider_key = model.provider or "Other"
0     if provider_key == "OpenAI Chat" or provider_key == "OpenAI Completion" then
0       provider_key = "OpenAI"
      end

0     if provider_key == "Custom OpenAI" or custom_openai.is_custom_openai_model_valid(model_id) then
0       is_custom = true
0       provider_key = "Custom OpenAI"
        -- Find the corresponding custom model data using the extracted name/id
        -- Prioritize matching the extracted name directly to a model_id first
0       if custom_openai.custom_openai_models[extracted_name] then
0         custom_model_info = custom_openai.custom_openai_models[extracted_name]
0         model_id = custom_model_info.model_id
0         model_name = custom_model_info.model_name
        else
          -- Fallback: Iterate to find match by model_name if ID didn't match
0         for id, info in pairs(custom_openai.custom_openai_models) do
0           if info.model_name == extracted_name then
0             custom_model_info = info
0             model_id = info.model_id
0             model_name = info.model_name
              break
            end
          end
        end
        -- If still no match, something is wrong, but proceed with extracted values
0       if not custom_model_info then
0         if config.get("debug") then
0           vim.notify("Could not find custom model info for: " .. extracted_name, vim.log.levels.WARN)
          end
          -- Keep model_id and model_name as extracted_name
        end
      end

      -- Create the entry for this model
0     local entry = {
        model_id = model_id,
        model_name = model_name,
        full_line = is_custom and ("Custom OpenAI: " .. model_name .. " (" .. model_id .. ")") or model.id, -- The original line from `llm models` or constructed for custom
        is_default = (model_id == default_model),
        is_custom = is_custom,
        aliases = model_to_aliases[model_id] or {}, -- Check aliases ONLY by model_id
0       provider = provider_key
      }

      -- Check for duplicates before adding to the provider list
0     if not (is_custom and processed_custom_model_ids[model_id]) then
0       if is_custom then
0         processed_custom_model_ids[model_id] = true -- Mark this ID as processed
        end

0       if not providers[provider_key] then
0         providers[provider_key] = {}
        end
0       table.insert(providers[provider_key], entry)
0     elseif config.get("debug") then
0       vim.notify("Skipping duplicate custom model entry for ID: " .. model_id, vim.log.levels.DEBUG)
      end
    end

0   local model_data = {}       -- Stores detailed info keyed by model_id
0   local line_to_model_id = {} -- Maps buffer line number to model_id
0   local current_line = #lines + 1
    -- Add content to buffer
0   local provider_keys = {}
0   for key, _ in pairs(providers) do
0     table.insert(provider_keys, key)
    end
0   table.sort(provider_keys)

0   for _, provider in ipairs(provider_keys) do
0     local provider_models = providers[provider]
0     if #provider_models > 0 then
0       table.insert(lines, provider)
0       table.insert(lines, string.rep("─", #provider))
0       current_line = current_line + 2
        -- Sort models within the provider group based on the display name (model_name)
0       table.sort(provider_models, function(a, b) return a.model_name < b.model_name end)

0       for _, model_entry in ipairs(provider_models) do
0         local status = model_entry.is_default and "✓" or " "
0         local alias_text = #model_entry.aliases > 0 and " (aliases: " .. table.concat(model_entry.aliases, ", ") .. ")" or ""
          -- Display model_name in the list
0         local display_line_part = model_entry.model_name
0         local provider_prefix = model_entry.provider .. ":"
0         local line = string.format("[%s] %s %s%s", status, provider_prefix, display_line_part, alias_text)

0         table.insert(lines, line)
          -- Store data keyed by model_id
0         model_data[model_entry.model_id] = {
            line = current_line,
            is_default = model_entry.is_default,
            is_custom = model_entry.is_custom,
            full_line = model_entry.full_line,   -- Store original line for context if needed
            model_name = model_entry.model_name, -- Store model name
0           aliases = model_entry.aliases
          }
          -- Map buffer line number to model_id
0         line_to_model_id[current_line] = model_entry.model_id
0         current_line = current_line + 1
        end
0       table.insert(lines, "")
0       current_line = current_line + 1
      end
    end
0   table.insert(lines, "")

0   return {
      lines = lines,
      line_to_model_id = line_to_model_id,
0     model_data = model_data
    }
  end

  -- Populate the buffer with model management content
* function M.populate_models_buffer(bufnr)
0   local data = M.generate_models_list()

0   api.nvim_buf_set_lines(bufnr, 0, -1, false, data.lines)
0   styles.setup_highlights()
0   styles.setup_buffer_syntax(bufnr) -- Use styles module

    -- Store lookup tables in buffer variables for keymaps
0   vim.b[bufnr].line_to_model_id = data.line_to_model_id
0   vim.b[bufnr].model_data = data.model_data

0   return data.line_to_model_id, data.model_data -- Return for direct use if needed
  end

  -- Setup keymaps for the model management buffer
* function M.setup_models_keymaps(bufnr, manager_module)
0   manager_module = manager_module or M -- Allow passing self for testing/modularity

    local function set_keymap(mode, lhs, rhs)
0     api.nvim_buf_set_keymap(bufnr, mode, lhs, rhs, { noremap = true, silent = true })
    end

    -- Set model under cursor as default
0   set_keymap('n', 's',
0     string.format([[<Cmd>lua require('%s').set_model_under_cursor(%d)<CR>]],
0       manager_module.__name or 'llm.managers.models_manager', bufnr))

    -- Set alias for model under cursor
0   set_keymap('n', 'a',
0     string.format([[<Cmd>lua require('%s').set_alias_for_model_under_cursor(%d)<CR>]],
0       manager_module.__name or 'llm.managers.models_manager', bufnr))

    -- Remove alias for model under cursor
0   set_keymap('n', 'r',
0     string.format([[<Cmd>lua require('%s').remove_alias_for_model_under_cursor(%d)<CR>]],
0       manager_module.__name or 'llm.managers.models_manager', bufnr))

0   set_keymap('n', 'c', -- New keymap for adding custom OpenAI model
0     string.format([[<Cmd>lua require('%s').add_custom_openai_model_interactive(%d)<CR>]],
0       manager_module.__name or 'llm.managers.models_manager', bufnr))
  end

  -- Action functions called by keymaps (now accept bufnr)

  -- Function to add a new custom OpenAI model via interactive input
* function M.add_custom_openai_model_interactive(bufnr)
0   models_view.get_custom_model_details(function(details)
0     local success, err_msg = custom_openai.add_custom_openai_model(details)
0     if success then
0       custom_openai.load_custom_openai_models() -- Reload models
0       vim.notify("Custom OpenAI model '" .. (details.model_name or details.model_id) .. "' added successfully.",
0         vim.log.levels.INFO)
0       require('llm.ui.unified_manager').switch_view("Models")
      else
0       vim.notify("Failed to add custom OpenAI model: " .. (err_msg or "Unknown error"), vim.log.levels.ERROR)
      end
0     vim.cmd('stopinsert') -- Ensure normal mode
    end)
  end

  -- Sets the model under the cursor as the default LLM model.
* function M.set_default_model_logic(model_id, model_info)
0   if not model_id or not model_info then
0     return { success = false, message = "No model info found" }
    end

0   local display_name = model_info.model_name or model_id

0   if model_info.is_default then
0     return { success = false, message = "Model '" .. display_name .. "' is already the default" }
    end

0   local check_identifier = model_info.is_custom and model_id or model_info.full_line
0   if not M.is_model_available(check_identifier) then
0     local provider = "unknown"
0     if model_info.is_custom then
0       provider = "Custom OpenAI/Azure"
0     elseif model_info.full_line:match("OpenAI") then
0       provider = "OpenAI"
0     elseif model_info.full_line:match("Anthropic") then
0       provider = "Anthropic"
0     elseif model_info.full_line:match("Mistral") then
0       provider = "Mistral"
0     elseif model_info.full_line:match("Gemini") then
0       provider = "Gemini"
0     elseif model_info.full_line:match("Groq") then
0       provider = "Groq"
0     elseif model_info.full_line:match("ollama") then
0       provider = "Ollama"
      end
0     return {
        success = false,
0       message = "Cannot set as default: " ..
0           provider .. " requirements not met (API key/plugin/config)"
      }
    end

0   if M.set_default_model(model_id) then
0     config.options.model = model_id
0     return { success = true, message = "Default model set to: " .. display_name }
    else
0     return { success = false, message = "Failed to set default model via llm CLI" }
    end
  end

  -- Sets the model under the cursor as the default LLM model.
* function M.set_model_under_cursor(bufnr)
0   local model_id, model_info = M.get_model_info_under_cursor(bufnr)
0   local result = M.set_default_model_logic(model_id, model_info)

0   if result.success then
0     vim.notify(result.message, vim.log.levels.INFO)
0     require('llm.ui.unified_manager').switch_view("Models") -- Refresh view
    else
0     vim.notify(result.message, vim.log.levels.ERROR)
    end
  end

  -- Sets an alias for the model under the cursor.
* function M.set_alias_for_model_under_cursor(bufnr)
0   local model_id, model_info = M.get_model_info_under_cursor(bufnr)
0   if not model_id or not model_info then
0     if config.get("debug") then
0       vim.notify("set_alias_for_model_under_cursor: no model_id or model_info", vim.log.levels.DEBUG)
      end
0     return
    end

0   if config.get("debug") then
0     vim.notify("set_alias_for_model_under_cursor: model_id=" .. model_id, vim.log.levels.DEBUG)
    end

0   local display_name = model_info.model_name or model_id

0   models_view.get_alias(display_name, function(alias)
0     if not alias or alias == "" then
0       vim.notify("Alias cannot be empty", vim.log.levels.WARN)
0       return
      end

0     if M.set_model_alias(alias, model_id) then
0       vim.notify("Alias set: " .. alias .. " -> " .. display_name .. " (ID: " .. model_id .. ")", vim.log.levels.INFO)
0       vim.cmd('stopinsert')
0       require('llm.ui.unified_manager').switch_view("Models")
      else
0       vim.notify("Failed to set alias via llm CLI", vim.log.levels.ERROR)
0       vim.cmd('stopinsert')
      end
    end)
  end

  -- Removes an alias associated with the model under the cursor.
* function M.remove_alias_for_model_under_cursor(bufnr)
0   local model_id, model_info = M.get_model_info_under_cursor(bufnr)
0   if not model_id or not model_info then return end -- Exit if no model info

0   local display_name = model_info.model_name or model_id

0   if not model_info.aliases or #model_info.aliases == 0 then
0     vim.notify("No aliases found for model '" .. display_name .. "'", vim.log.levels.WARN)
0     return
    end

0   models_view.select_alias_to_remove(model_info.aliases, function(alias)
0     if not alias then return end
0     models_view.confirm_remove_alias(alias, function()
0       if M.remove_model_alias(alias) then
0         vim.notify("Alias removed: " .. alias, vim.log.levels.INFO)
0         require('llm.ui.unified_manager').switch_view("Models")
        else
0         vim.notify("Failed to remove alias '" .. alias .. "'", vim.log.levels.ERROR)
        end
      end)
    end
    )
  end

  -- Helper to get model info (ID and data) from buffer variables (Duplicate of local function, keep for external calls if needed)
* function M.get_model_info_under_cursor(bufnr)
0   local current_line = api.nvim_win_get_cursor(0)[1]
0   local line_to_model_id = vim.b[bufnr].line_to_model_id
0   local model_data = vim.b[bufnr].model_data

0   if not line_to_model_id or not model_data then
0     if config.get("debug") then
0       vim.notify(string.format("Buffer data missing for bufnr %d (line_to_model_id: %s, model_data: %s)",
0         bufnr, tostring(line_to_model_id), tostring(model_data)), vim.log.levels.DEBUG)
      end
0     return nil, nil -- Return nil for both model_id and model_info
    end

0   local model_id = line_to_model_id[current_line]
0   if model_id and model_data[model_id] then
      -- Return model_id and the corresponding data table
0     return model_id, model_data[model_id]
    end

    -- Add debug log if no model info is found for the line
0   if config.get("debug") then
0     local line_content = api.nvim_buf_get_lines(bufnr, current_line - 1, current_line, false)[1]
0     vim.notify(string.format("No model info found for line %d (content: '%s', mapped_id: %s) in bufnr %d",
0       current_line, line_content or "nil", tostring(model_id), bufnr), vim.log.levels.DEBUG)
    end

0   return nil, nil -- Return nil for both model_id and model_info
  end

  -- Main function to open the model manager (now delegates to unified manager)
* function M.manage_models()
0   require('llm.ui.unified_manager').open_specific_manager("Models")
  end

  -- Get custom OpenAI models
* function M.get_custom_openai_models()
0   if vim.tbl_isempty(custom_openai.custom_openai_models) then
0     custom_openai.load_custom_openai_models()
    end
0   return custom_openai.custom_openai_models
  end

  -- Force reload custom OpenAI models
* function M.reload_custom_openai_models()
    -- Clear the cache and reload
0   custom_openai.custom_openai_models = {}
0   custom_openai.load_custom_openai_models()
0   return custom_openai.custom_openai_models
  end

  -- Debug function for custom models (delegates to custom_openai module)
* function M.debug_custom_openai_models()
0   return custom_openai.debug_custom_openai_models()
  end

  -- Create sample YAML file (delegates to custom_openai module)
* function M.create_sample_yaml_file()
0   return custom_openai.create_sample_yaml_file()
  end

  -- Add module name for require path in keymaps
* M.__name = 'llm.managers.models_manager'

* return M

==============================================================================
lua/llm/managers/plugins_manager.lua
==============================================================================
  -- llm/managers/plugins_manager.lua - Plugin management for llm-nvim
  -- License: Apache 2.0

* local M = {}

  -- Forward declarations
* local api = vim.api
* local llm_cli = require('llm.core.data.llm_cli')
* local cache = require('llm.core.data.cache')
* local plugins_view = require('llm.ui.views.plugins_view')
* local styles = require('llm.ui.styles')

  local function parse_plugins_html(html)
*   local plugins = {}
*   vim.notify("Parsing HTML content of length: " .. #html, vim.log.levels.INFO)
*   local sections = html:gmatch('<section id="([%w-]+)">(.-)</section>')

*   for id, content in sections do
*     local h2 = content:match('<h2>(.-)</h2>')
*     if h2 then
        -- vim.notify("Found section: " .. h2, vim.log.levels.INFO) -- Removed per-section log
*       local list_items = content:gmatch('<li>(.-)</li>')
*       for item in list_items do
          local url, name, description
*         local link_match = item:match('<a.->(.-)</a>')
*         if link_match then
*           name = link_match:match('<strong>(.-)</strong>') or link_match
*           url = item:match('href="(.-)"')
*           description = item:gsub('<[^>]+>', ''):gsub(name, '', 1):match('^:%s*(.*)') or item:gsub('<[^>]+>', ''):gsub(name, '', 1):match(':%s*(.*)')
*           table.insert(plugins, { name = name, url = url, description = description })
            -- vim.notify("Parsed plugin: " .. name, vim.log.levels.INFO) -- Removed per-plugin log
          end
        end
      end
    end
*   vim.notify("Finished parsing, found " .. #plugins .. " plugins.", vim.log.levels.INFO)
*   return plugins
  end

  -- Get available plugins from the plugin directory
* function M.get_available_plugins()
*   vim.notify("Getting available plugins...", vim.log.levels.INFO)
*   local cached_plugins = cache.get('available_plugins')
*   if cached_plugins then
*     vim.notify("Returning cached plugins.", vim.log.levels.INFO)
*     return cached_plugins
    end

*   vim.notify("Fetching plugins from URL...", vim.log.levels.INFO)
*   local plugins_html = vim.fn.system('curl -s https://llm.datasette.io/en/stable/plugins/directory.html')
*   if not plugins_html or plugins_html == "" then
*     vim.notify("Failed to fetch HTML from URL.", vim.log.levels.ERROR)
*     return {}
    end
*   vim.notify("Fetched HTML content, length: " .. #plugins_html, vim.log.levels.INFO)

*   local plugins = parse_plugins_html(plugins_html)
*   vim.notify("Parsed " .. #plugins .. " plugins from HTML.", vim.log.levels.INFO)

*   cache.set('available_plugins', plugins)
*   return plugins
  end

  local function trim(s)
0   return s:match("^%s*(.-)%s*$")
  end

  local function trim(s)
*   return s:match("^%s*(.-)%s*$")
  end

  -- Get installed plugins from llm CLI
* function M.get_installed_plugins()
*   vim.notify("Getting installed plugins...", vim.log.levels.INFO)
*   local cached_plugins = cache.get('installed_plugins')
*   if cached_plugins then
*     vim.notify("Returning cached installed plugins.", vim.log.levels.INFO)
*     return cached_plugins
    end

*   vim.notify("Running 'llm plugins' command...", vim.log.levels.INFO)
*   local plugins_output = llm_cli.run_llm_command('plugins')
*   if not plugins_output then
0     vim.notify("'llm plugins' command returned no output.", vim.log.levels.WARN)
0     return {}
    end
*   plugins_output = trim(plugins_output)
    -- Remove any non-printable characters that might interfere with JSON parsing
*   plugins_output = plugins_output:gsub("[^%w%p%s]", "")

*   local plugins = {}
*   local ok, decoded_plugins = pcall(vim.fn.json_decode, plugins_output)

*   if ok and type(decoded_plugins) == 'table' then
      -- Successfully decoded as JSON
*     for _, plugin_data in ipairs(decoded_plugins) do
*       if plugin_data and plugin_data.name then
*         table.insert(plugins, { name = plugin_data.name })
*         vim.notify("Parsed installed plugin (JSON): '" .. plugin_data.name .. "'", vim.log.levels.INFO)
        end
      end
    else
0     vim.notify("Failed to decode JSON from 'llm plugins' command: " .. tostring(decoded_plugins), vim.log.levels.ERROR)
0     return {}
    end
*   vim.notify("Finished parsing installed plugins, found " .. #plugins .. ".", vim.log.levels.INFO)
*   cache.set('installed_plugins', plugins)
*   return plugins
  end

  -- Check if a plugin is installed
* function M.is_plugin_installed(plugin_name)
*   local installed_plugins = M.get_installed_plugins()
*   for _, plugin in ipairs(installed_plugins) do
*     if plugin.name == plugin_name then
*       return true
      end
    end
*   return false
  end

  -- Install a plugin using llm CLI
* function M.install_plugin(plugin_name)
*   local result = llm_cli.run_llm_command('install ' .. plugin_name)
*   cache.invalidate('installed_plugins')
*   cache.invalidate('available_plugins')
*   return result ~= nil
  end

  -- Uninstall a plugin using llm CLI
* function M.uninstall_plugin(plugin_name)
*   local result = llm_cli.run_llm_command('uninstall ' .. plugin_name .. ' -y')
*   cache.invalidate('installed_plugins')
*   cache.invalidate('available_plugins')
*   return result ~= nil
  end

  -- Populate the buffer with plugin management content
* function M.populate_plugins_buffer(bufnr)
0   vim.notify("Populating plugins buffer...", vim.log.levels.INFO)
0   local available_plugins = M.get_available_plugins()
0   vim.notify("Got " .. #available_plugins .. " available plugins.", vim.log.levels.INFO)

0   if not available_plugins or #available_plugins == 0 then
0     vim.notify("No available plugins found. Displaying error message.", vim.log.levels.WARN)
0     api.nvim_buf_set_lines(bufnr, 0, -1, false, {
        "# Plugin Management - Error",
        "",
        "No plugins found. Make sure llm is properly configured and plugin cache is up-to-date.",
        "",
        "Press [q]uit or use navigation keys ([M]odels, [K]eys, etc.)"
      })
0     return {}, {} -- Return empty lookup tables
    end

0   local installed_plugins = M.get_installed_plugins()
0   vim.notify("DEBUG: Raw installed_plugins: " .. vim.inspect(installed_plugins), vim.log.levels.INFO)
0   local installed_set = {}
0   vim.notify("--- INSTALLED PLUGINS (" .. #installed_plugins .. ") ---", vim.log.levels.INFO)
0   for _, plugin in ipairs(installed_plugins) do
0     installed_set[plugin.name] = true
      -- vim.notify("Installed: '" .. plugin.name .. "' (added to set)", vim.log.levels.INFO) -- Removed per-plugin log
    end

0   local available_plugin_names = {}
0   for _, plugin in ipairs(available_plugins) do
0     table.insert(available_plugin_names, plugin.name)
    end
0   vim.notify("--- AVAILABLE PLUGINS (" .. #available_plugins .. ") ---\n" .. table.concat(available_plugin_names, ", "),
0     vim.log.levels.INFO)

0   local lines = {
      "# Plugin Management",
      "",
      "Navigate: [M]odels [K]eys [F]ragments [T]emplates [S]chemas",
      "Actions: [i]nstall [x]uninstall [r]efresh [q]uit",
      "──────────────────────────────────────────────────────────────",
      ""
    }

0   local plugin_data = {}
0   local line_to_plugin = {}
0   local current_line = #lines + 1
    -- Add content to buffer
0   for _, plugin in ipairs(available_plugins) do
0     local desc = plugin.description or ""
0     if #desc > 50 then desc = desc:sub(1, 47) .. "..." end
0     local is_installed = installed_set[plugin.name]
0     local status_char = is_installed and "✓" or " "
0     local status_text = is_installed and "Installed" or "Not Installed"
0     local line = string.format("[%s] %-30s - %s", status_char, plugin.name, status_text)
0     table.insert(lines, line)
0     plugin_data[plugin.name] = { line = current_line, installed = is_installed or false }
0     line_to_plugin[current_line] = plugin.name
0     current_line = current_line + 1
    end
0   vim.notify("Prepared " .. #lines .. " lines for the buffer.", vim.log.levels.INFO)
0   api.nvim_buf_set_lines(bufnr, 0, -1, false, lines)

    -- Apply syntax highlighting and line-specific highlights
0   styles.setup_highlights()
0   styles.setup_buffer_syntax(bufnr) -- Use styles module

    -- Apply line-specific highlights for installed status
0   local ns_id = api.nvim_create_namespace('LLMPluginsManagerHighlights')
0   api.nvim_buf_clear_namespace(bufnr, ns_id, 0, -1)
0   for i, plugin in ipairs(available_plugins) do
0     local highlight_group = installed_set[plugin.name] and "LLMPluginInstalled" or "LLMPluginNotInstalled"
0     local header_lines_count = 6                -- Number of fixed header lines
0     local line_idx = header_lines_count + i - 1 -- Calculate the correct 0-based line index
0     api.nvim_buf_add_highlight(bufnr, ns_id, highlight_group, line_idx, 0, -1)
    end

    -- Store lookup tables in buffer variables
0   vim.b[bufnr].line_to_plugin = line_to_plugin
0   vim.b[bufnr].plugin_data = plugin_data

0   vim.notify("Finished populating plugins buffer.", vim.log.levels.INFO)
0   return line_to_plugin, plugin_data -- Return for direct use if needed
  end

  -- Setup keymaps for the plugin management buffer
* function M.setup_plugins_keymaps(bufnr, manager_module)
0   manager_module = manager_module or M -- Allow passing self

    local function set_keymap(mode, lhs, rhs)
0     api.nvim_buf_set_keymap(bufnr, mode, lhs, rhs, { noremap = true, silent = true })
    end

    -- Install plugin under cursor
0   set_keymap('n', 'i',
0     string.format([[<Cmd>lua require('%s').install_plugin_under_cursor(%d)<CR>]],
0       manager_module.__name or 'llm.managers.plugins_manager', bufnr))

    -- Uninstall plugin under cursor
0   set_keymap('n', 'x',
0     string.format([[<Cmd>lua require('%s').uninstall_plugin_under_cursor(%d)<CR>]],
0       manager_module.__name or 'llm.managers.plugins_manager', bufnr))

    -- Refresh plugin list
0   set_keymap('n', 'r',
0     string.format([[<Cmd>lua require('%s').refresh_plugin_list(%d)<CR>]],
0       manager_module.__name or 'llm.managers.plugins_manager', bufnr))
  end

  -- Action functions called by keymaps (now accept bufnr)
* function M.refresh_plugin_list(bufnr)
0   M.refresh_available_plugins(function()
0     require('llm.ui.unified_manager').switch_view("Plugins")
    end)
  end

* function M.install_plugin_under_cursor(bufnr)
0   local plugin_name, plugin_info = M.get_plugin_info_under_cursor(bufnr)
0   if not plugin_name then
0     vim.notify("No plugin selected", vim.log.levels.WARN)
0     return
    end
0   if plugin_info.installed then
0     vim.notify("Plugin " .. plugin_name .. " is already installed", vim.log.levels.INFO)
0     return
    end

0   vim.notify("Installing plugin: " .. plugin_name .. "... Please wait.", vim.log.levels.INFO)

    -- Run in schedule to avoid blocking UI
0   vim.schedule(function()
0     local success = M.install_plugin(plugin_name)
0     if success then
0       vim.notify("Successfully installed: " .. plugin_name, vim.log.levels.INFO)
0       require('llm.ui.unified_manager').switch_view("Plugins")
      else
0       vim.notify("Failed to install " .. plugin_name, vim.log.levels.ERROR)
      end
    end)
  end

* function M.uninstall_plugin_under_cursor(bufnr)
0   local plugin_name, plugin_info = M.get_plugin_info_under_cursor(bufnr)
0   if not plugin_name then
0     vim.notify("No plugin selected", vim.log.levels.WARN)
0     return
    end
0   if not plugin_info.installed then
0     vim.notify("Plugin " .. plugin_name .. " is not installed", vim.log.levels.INFO)
0     return
    end

0   plugins_view.confirm_uninstall(plugin_name, function(confirmed)
0     if not confirmed then return end
0     vim.notify("Uninstalling plugin: " .. plugin_name .. "... Please wait.", vim.log.levels.INFO)

      -- Run in schedule to avoid blocking UI
0     vim.schedule(function()
0       local success = M.uninstall_plugin(plugin_name)
0       if success then
0         vim.notify("Successfully uninstalled: " .. plugin_name, vim.log.levels.INFO)
0         require('llm.ui.unified_manager').switch_view("Plugins")
        else
0         vim.notify("Failed to uninstall " .. plugin_name, vim.log.levels.ERROR)
        end
      end)
    end)
  end

* function M.refresh_available_plugins(callback)
0   vim.notify("Refreshing available plugins...", vim.log.levels.INFO)
0   cache.invalidate('available_plugins')
0   cache.invalidate('installed_plugins')
    -- Fetch in the background
0   vim.defer_fn(function()
0     local plugins = M.get_available_plugins()
0     vim.notify("Finished refreshing plugins: " .. #plugins .. " found.", vim.log.levels.INFO)
0     if callback then
0       callback()
      end
0   end, 0)
  end

  -- Helper to get plugin info from buffer variables
* function M.get_plugin_info_under_cursor(bufnr)
0   local current_line = api.nvim_win_get_cursor(0)[1]
0   local line_to_plugin = vim.b[bufnr].line_to_plugin
0   local plugin_data = vim.b[bufnr].plugin_data
0   if not line_to_plugin or not plugin_data then
0     vim.notify("Buffer data missing", vim.log.levels.ERROR)
0     return nil, nil
    end
0   local plugin_name = line_to_plugin[current_line]
0   if plugin_name and plugin_data[plugin_name] then
0     return plugin_name, plugin_data[plugin_name]
    end
0   return nil, nil
  end

  -- Main function to open the plugin manager (now delegates to unified manager)
* function M.manage_plugins()
0   require('llm.ui.unified_manager').open_specific_manager("Plugins")
  end

  -- Add module name for require path in keymaps
* M.__name = 'llm.managers.plugins_manager'

* return M

==============================================================================
lua/llm/managers/keys_manager.lua
==============================================================================
  -- llm/managers/keys_manager.lua - API key management for llm-nvim
  -- License: Apache 2.0

* local M = {}

  -- Forward declarations
* local api = vim.api
* local llm_cli = require('llm.core.data.llm_cli')
* local cache = require('llm.core.data.cache')
* local keys_view = require('llm.ui.views.keys_view')
* local styles = require('llm.ui.styles')

  -- Get stored API keys from llm CLI
* function M.get_stored_keys()
*     local cached_keys = cache.get('keys')
*     if cached_keys then
0         return cached_keys
      end

*     local keys_json = llm_cli.run_llm_command('keys list --json')
*     local keys = vim.fn.json_decode(keys_json)
*     cache.set('keys', keys)
*     return keys
  end

  -- Check if an API key is set
* function M.is_key_set(key_name)
*   local stored_keys = M.get_stored_keys()
*   for _, key in ipairs(stored_keys) do
*     if key.name == key_name then
*       return true
      end
    end
*   return false
  end

  -- Set an API key by directly modifying the keys.json file
* function M.set_api_key(key_name, key_value)
*     local result = llm_cli.run_llm_command('keys set ' .. key_name .. ' ' .. key_value)
*     cache.invalidate('keys')
*     return result ~= nil
  end

  -- Remove an API key by directly modifying the keys.json file
* function M.remove_api_key(key_name)
*     local result = llm_cli.run_llm_command('keys remove ' .. key_name)
*     cache.invalidate('keys')
*     return result ~= nil
  end

  -- Populate the buffer with key management content
* function M.populate_keys_buffer(bufnr)
0   local all_stored_keys_list = M.get_stored_keys()
0   local stored_keys_set = {}
0   for _, key in ipairs(all_stored_keys_list) do stored_keys_set[key.name] = true end

0   local lines = {
      "# API Key Management",
      "",
      "Navigate: [M]odels [P]lugins [F]ragments [T]emplates [S]chemas",
      "Actions: [s]et key [r]emove key [A]dd custom [q]uit",
      "──────────────────────────────────────────────────────────────",
      "",
      "## Available Providers:",
      ""
    }

0   local predefined_providers_list = {
      "openai", "anthropic", "mistral", "gemini", "groq", "perplexity",
      "cohere", "replicate", "anyscale", "together", "deepseek", "fireworks",
      "aws", "azure",
    }
0   local predefined_providers_set = {}
0   for _, p_name in ipairs(predefined_providers_list) do predefined_providers_set[p_name] = true end

0   local key_data = {}
0   local line_to_provider = {}
0   local current_line = #lines + 1

0   for _, provider_name in ipairs(predefined_providers_list) do
0     local is_set = stored_keys_set[provider_name] or false
0     local status = is_set and "✓" or " "
0     local line = string.format("[%s] %s", status, provider_name)
0     table.insert(lines, line)
0     key_data[provider_name] = { line = current_line, is_set = is_set }
0     line_to_provider[current_line] = provider_name
0     current_line = current_line + 1
    end

0   table.insert(lines, "")

0   local custom_keys_to_display = {}
0   for _, stored_key in ipairs(all_stored_keys_list) do
0     if not predefined_providers_set[stored_key.name] then
0       table.insert(custom_keys_to_display, stored_key.name)
      end
    end
0   table.sort(custom_keys_to_display)

0   if #custom_keys_to_display > 0 then
0     table.insert(lines, "## Custom Keys:")
0     table.insert(lines, "")
0     for _, custom_key_name in ipairs(custom_keys_to_display) do
0       local line = string.format("[✓] %s", custom_key_name)
0       table.insert(lines, line)
0       key_data[custom_key_name] = { line = current_line, is_set = true }
0       line_to_provider[current_line] = custom_key_name
0       current_line = current_line + 1
      end
0     table.insert(lines, "")
    end

0   api.nvim_buf_set_lines(bufnr, 0, -1, false, lines)
0   styles.setup_highlights()
0   styles.setup_buffer_syntax(bufnr)
0   vim.b[bufnr].line_to_provider = line_to_provider
0   vim.b[bufnr].key_data = key_data
0   vim.b[bufnr].stored_keys_set = stored_keys_set
  end

  -- Setup keymaps for the key management buffer
* function M.setup_keys_keymaps(bufnr, manager_module)
0   manager_module = manager_module or M

    local function set_keymap(mode, lhs, rhs)
0     api.nvim_buf_set_keymap(bufnr, mode, lhs, rhs, { noremap = true, silent = true })
    end

0   set_keymap('n', 's', string.format([[<Cmd>lua require('%s').set_key_under_cursor(%d)<CR>]], manager_module.__name, bufnr))
0   set_keymap('n', 'r', string.format([[<Cmd>lua require('%s').remove_key_under_cursor(%d)<CR>]], manager_module.__name, bufnr))
0   set_keymap('n', 'A', string.format([[<Cmd>lua require('%s').add_new_custom_key_interactive(%d)<CR>]], manager_module.__name, bufnr))
  end

* function M.add_new_custom_key_interactive(bufnr)
0   keys_view.get_custom_key_name(function(custom_name)
0     if not custom_name or custom_name == "" then
0       vim.notify("Custom key name cannot be empty. Aborted.", vim.log.levels.WARN)
0       return
      end

0     keys_view.get_api_key(custom_name, function(key_value)
0       if not key_value or key_value == "" then
0         vim.notify("API key value cannot be empty. Aborted.", vim.log.levels.WARN)
0         return
        end

0       if M.set_api_key(custom_name, key_value) then
0         vim.notify("Successfully set key for '" .. custom_name .. "'", vim.log.levels.INFO)
0         require('llm.ui.unified_manager').switch_view("Keys")
        else
0         vim.notify("Failed to set key for '" .. custom_name .. "'. See previous errors for details.", vim.log.levels.ERROR)
        end
      end)
    end)
  end

* function M.set_key_under_cursor(bufnr)
0   local provider_name, _ = M.get_provider_info_under_cursor(bufnr)
0   if not provider_name then return end

0   keys_view.get_api_key(provider_name, function(key_value)
0     if not key_value or key_value == "" then
0       vim.notify("API key value cannot be empty. Aborted for " .. provider_name .. ".", vim.log.levels.WARN)
0       return
      end
0     if M.set_api_key(provider_name, key_value) then
0       vim.notify("Key for '" .. provider_name .. "' set", vim.log.levels.INFO)
0       require('llm.ui.unified_manager').switch_view("Keys")
      else
0       vim.notify("Failed to set key for '" .. provider_name .. "'.", vim.log.levels.ERROR)
      end
    end)
  end

* function M.remove_key_under_cursor(bufnr)
0   local provider_name, key_info = M.get_provider_info_under_cursor(bufnr)
0   if not provider_name or provider_name == "+" then return end

0   local stored_keys_set = vim.b[bufnr].stored_keys_set
0   if not stored_keys_set[provider_name] then
0     vim.notify("No key found for '" .. provider_name .. "'", vim.log.levels.WARN)
0     return
    end

0   keys_view.confirm_remove_key(provider_name, function()
0     if M.remove_api_key(provider_name) then
0       vim.notify("Key for '" .. provider_name .. "' removed", vim.log.levels.INFO)
0       require('llm.ui.unified_manager').switch_view("Keys")
      else
0       vim.notify("Failed to remove key for '" .. provider_name .. "'", vim.log.levels.ERROR)
      end
    end)
  end

* function M.get_provider_info_under_cursor(bufnr)
0   local current_line = api.nvim_win_get_cursor(0)[1]
0   local line_to_provider = vim.b[bufnr].line_to_provider
0   local key_data = vim.b[bufnr].key_data
0   if not line_to_provider or not key_data then
0     vim.notify("Buffer data missing", vim.log.levels.ERROR)
0     return nil, nil
    end
0   local provider_name = line_to_provider[current_line]
0   if provider_name == "+" then
0     return "+", nil
0   elseif provider_name and key_data[provider_name] then
0     return provider_name, key_data[provider_name]
    end
0   return nil, nil
  end

* function M.manage_keys()
0   require('llm.ui.unified_manager').open_specific_manager("Keys")
  end

* M.__name = 'llm.managers.keys_manager'

* return M

==============================================================================
lua/llm/managers/models_io.lua
==============================================================================
  -- llm/managers/models_io.lua - I/O functions for model management
  -- License: Apache 2.0

* local M = {}

* local llm_cli = require('llm.core.data.llm_cli')

* function M.get_models_from_cli()
*     return llm_cli.run_llm_command("models list --json")
  end

* function M.get_default_model_from_cli()
*     return llm_cli.run_llm_command("default")
  end

* function M.set_default_model_in_cli(model_name)
*     return llm_cli.run_llm_command(string.format('default %s', model_name))
  end

* function M.get_aliases_from_cli()
*     return llm_cli.run_llm_command("aliases list --json")
  end

* function M.set_alias_in_cli(alias, model)
*     return llm_cli.run_llm_command(string.format('aliases set %s %s', alias, model))
  end

* function M.remove_alias_in_cli(alias)
*     local escaped_alias = string.format("'%s'", alias:gsub("'", "'\\''"))
*     local cmd = string.format("aliases remove %s", escaped_alias)
*     return llm_cli.run_llm_command(cmd)
  end

* return M

==============================================================================
lua/llm/core/loaders.lua
==============================================================================
  -- llm/core/loaders.lua - Data loaders for llm-nvim
  -- License: Apache 2.0

* local M = {}

* local llm_cli = require('llm.core.data.llm_cli')
* local cache = require('llm.core.data.cache')

* function M.load_models()

*   local models_output = llm_cli.run_llm_command('models list')

*   if models_output then
*     local models = {}
*     for line in models_output:gmatch("[^\n]+") do
*       if not line:match("^%-%-") and line ~= "" and not line:match("^Models:") and not line:match("^Default:") then
*         local provider, model_id = line:match("([^:]+): (.*)")
*         if provider and model_id then
*           table.insert(models, { provider = provider, id = model_id, name = model_id })
          end
        end
      end
*     cache.set('models', models)
    end

  end

* function M.load_available_plugins()

*   local plugins_output = llm_cli.run_llm_command('plugins --all')

*   if plugins_output then
*     local plugins = {}
*     for line in plugins_output:gmatch("[^\n]+") do
*       local plugin_name, description = line:match("^(%S+)%s*-%s*(.*)")
*       if plugin_name and description then
*         table.insert(plugins, { name = plugin_name, description = description })
        end
      end
*     cache.set('available_plugins', plugins)
    end

  end

* function M.load_keys()

*   local keys_output = llm_cli.run_llm_command('keys list')

*   if keys_output then
*     local keys = {}
*     for line in keys_output:gmatch("[^\n]+") do
*       if line ~= "Stored keys:" and line ~= "------------------" and line ~= "" then
*         table.insert(keys, { name = line })
        end
      end
*     cache.set('keys', keys)
    end

  end

* function M.load_fragments()

*   local fragments_output = llm_cli.run_llm_command('fragments list')

*   if fragments_output then
*     local fragments = {}
*     local current_fragment = nil
*     for line in fragments_output:gmatch("[^\n]+") do
*       local hash = line:match("^%s*-%s+hash:%s+([0-9a-f]+)")
*       if hash then
*         if current_fragment then
*           table.insert(fragments, current_fragment)
          end
*         current_fragment = { hash = hash, aliases = {}, source = "", content = "", datetime = "" }
        else
*         if current_fragment then
*           local alias = line:match("^%s+-%s+(.+)")
*           if alias then
*             table.insert(current_fragment.aliases, alias)
            end
*           local source = line:match("^%s+source:%s+(.+)")
*           if source then
*             current_fragment.source = source
            end
*           local content = line:match("^%s+content:%s+(.+)")
*           if content then
*             current_fragment.content = content
            end
*           local datetime = line:match("^%s+datetime:%s+(.+)")
*           if datetime then
*             current_fragment.datetime = datetime
            end
          end
        end
      end
*     if current_fragment then
*       table.insert(fragments, current_fragment)
      end
*     cache.set('fragments', fragments)
    end

  end

* function M.load_templates()

*   local templates_output = llm_cli.run_llm_command('templates list')

*   if templates_output then
*     local templates = {}
*     for line in templates_output:gmatch("[^\n]+") do
*       local name, description = line:match("^(%S+)%s*-%s*(.*)")
*       if name and description then
*         table.insert(templates, { name = name, description = description })
        end
      end
*     cache.set('templates', templates)
    end

  end

* function M.load_schemas()

*   local schemas_output = llm_cli.run_llm_command('schemas list')

*   if schemas_output then
*     local schemas = {}
*     for line in schemas_output:gmatch("[^\n]+") do
*       local id, description = line:match("^(%S+)%s*-%s*(.*)")
*       if id and description then
*         table.insert(schemas, { id = id, description = description })
        end
      end
*     cache.set('schemas', schemas)
    end

  end

* function M.load_all()
*   M.load_models()
*   M.load_available_plugins()
*   M.load_keys()
*   M.load_fragments()
*   M.load_templates()
*   M.load_schemas()
  end

* return M

==============================================================================
lua/llm/core/data/cache.lua
==============================================================================
  -- llm/core/data/cache.lua - Caching for llm-nvim
  -- License: Apache 2.0

* local M = {}

* local cache_file_path = vim.fn.stdpath('cache') .. '/llm_nvim_cache.json'
* local cache = {}

  -- Load cache from file
  local function load_cache()
*   local file = io.open(cache_file_path, "r")
*   if file then
*     local content = file:read("*all")
*     file:close()
*     local ok, decoded = pcall(vim.fn.json_decode, content)
*     if ok and type(decoded) == 'table' then
*       cache = decoded
      else
        -- If decoding fails, initialize an empty cache
0       cache = {}
      end
    else
*     cache = {}
    end
  end

  -- Save cache to file
  local function save_cache()
*   local encoded = vim.fn.json_encode(cache)
*   local file = io.open(cache_file_path, "w")
*   if file then
*     file:write(encoded)
*     file:close()
    end
  end

  -- Initialize cache on module load
* load_cache()

* function M.get(key)
*   return cache[key]
  end

* function M.set(key, value)
*   cache[key] = value
*   save_cache()
  end

* function M.invalidate(key)
*   cache[key] = nil
*   save_cache()
  end

* return M

==============================================================================
lua/llm/core/data/llm_cli.lua
==============================================================================
  -- llm/core/data/llm_cli.lua - LLM CLI interaction
  -- License: Apache 2.0

* local M = {}

* local shell = require('llm.core.utils.shell')
* local api = require('llm.api') -- Added for streaming

* function M.run_llm_command(command, bufnr)
*     local full_command_parts = vim.split('llm ' .. command, ' ')

*     if bufnr then
0         return api.run_llm_command_streamed(full_command_parts, bufnr)
      else
*         return shell.safe_shell_command(table.concat(full_command_parts, ' '))
      end
  end

* return M

==============================================================================
lua/llm/core/utils/notify.lua
==============================================================================
* local M = {}

* function M.notify(msg, level, opts)
*   vim.notify(msg, level, opts or {})
  end

* return M

==============================================================================
lua/llm/core/utils/validate.lua
==============================================================================
  -- llm/utils/validate.lua - Type validation and conversion utilities
  -- License: Apache 2.0

* local M = {}

  -- Type conversion functions
* function M.convert(value, target_type)
*   if type(value) == target_type then
*     return value
    end

*   if target_type == "boolean" then
*     if type(value) == "string" then
*       return value:lower() == "true"
0     elseif type(value) == "number" then
0       return value ~= 0
      end
*   elseif target_type == "number" then
*     if type(value) == "string" then
*       return tonumber(value) or 0
0     elseif type(value) == "boolean" then
0       return value and 1 or 0
      end
0   elseif target_type == "string" then
0     return tostring(value)
    end

    -- Fallback to default for target type
0   if target_type == "boolean" then
0     return false
0   elseif target_type == "number" then
0     return 0
0   elseif target_type == "string" then
0     return ""
0   elseif target_type == "table" then
0     return {}
    end

0   return nil
  end

  -- Validate value against type
* function M.validate(value, expected_type)
*   if expected_type == "any" then
0     return true
    end

*   local actual_type = type(value)

    -- Special case for nil which we'll consider valid for all types
*   if value == nil then
0     return true
    end

    -- Handle table type checks
*   if expected_type == "table" and actual_type == "table" then
0     return true
    end

    -- Handle other type matches
*   return actual_type == expected_type
  end

* return M

==============================================================================
lua/llm/core/utils/job.lua
==============================================================================
* local M = {}

* function M.run(cmd, callbacks)
*   local config = require('llm.config')
*   if config.get('debug') then
0     vim.notify("Starting job: " .. cmd[1], vim.log.levels.DEBUG)
    end

*   local stdout_buffer = ""
*   local stderr_buffer = ""

    local function process_output(data, event)
*     if not data then return end

*     local handler = (event == "stdout" and callbacks.on_stdout) or (event == "stderr" and callbacks.on_stderr)
*     if not handler then return end

*     local buffer = (event == "stdout") and stdout_buffer or stderr_buffer

*     for _, chunk in ipairs(data) do
        -- Accumulate chunk into buffer
*       buffer = buffer .. chunk

        -- Split buffer on newlines
*       local lines = {}
        while true do
*         local newline_pos = buffer:find('\n')
*         if not newline_pos then break end

          -- Extract line without the newline
*         local line = buffer:sub(1, newline_pos - 1)
*         table.insert(lines, line)

          -- Remove processed line from buffer
*         buffer = buffer:sub(newline_pos + 1)
        end

        -- Update the appropriate buffer
*       if event == "stdout" then
*         stdout_buffer = buffer
        else
0         stderr_buffer = buffer
        end

        -- Call handler with complete lines
*       if #lines > 0 then
*         handler(nil, lines)
        end
      end
    end

*   local options = {
      on_exit = function(j, exit_code)
0       if config.get('debug') then
0         vim.notify("Job exited with code: " .. tostring(exit_code), vim.log.levels.DEBUG)
        end

        -- Process any remaining buffered stdout before calling the final on_exit callback
0       if #stdout_buffer > 0 then
0         if callbacks.on_stdout then
0           callbacks.on_stdout(nil, {stdout_buffer})
          end
0         stdout_buffer = "" -- Clear buffer after processing
        end

        -- Process any remaining buffered stderr
0       if #stderr_buffer > 0 then
0         if callbacks.on_stderr then
0           callbacks.on_stderr(nil, {stderr_buffer})
          end
0         stderr_buffer = "" -- Clear buffer after processing
        end

0       if callbacks.on_exit then callbacks.on_exit(j, exit_code) end
      end,
*     on_stdout = function(j, d, e) process_output(d, e) end,
*     on_stderr = function(j, d, e) process_output(d, e) end,
*     stdout_buffered = false,
*     stderr_buffered = false,
    }

*   local job_id = vim.fn.jobstart(cmd, options)

*   if not job_id or job_id <= 0 then
0     vim.notify("Failed to start job: " .. cmd[1], vim.log.levels.ERROR)
0     return nil
    else
*     return job_id
    end
  end

* return M

==============================================================================
lua/llm/core/utils/file_utils.lua
==============================================================================
* local M = {}

* local config = require('llm.config')
* local shell = require('llm.core.utils.shell')

* function M.set_shell(new_shell)
*   shell = new_shell
  end

  -- Pure path utilities --------------------------------------------------------

  local function trim_path(path)
*   return path and path:gsub("[\r\n]+$", ""):gsub("%s+$", "") or nil
  end

  local function join_path(dir, file)
*   return dir and file and dir .. "/" .. file or nil
  end

  local function debug_log(message, level)
*   if config.get('debug') then
0     vim.notify(message, level or vim.log.levels.DEBUG)
    end
  end

  -- Directory operations -------------------------------------------------------

* local config_dir_cache = nil

  local function with_directory(dir, action)
0   if not dir or dir == "" then return false end

0   local test_file = join_path(dir, ".llm_nvim_test")
0   local success, err = pcall(function()
0     local f = io.open(test_file, "a")
0     if not f then return false end
0     f:close()

0     if action == "test" then
0       os.remove(test_file)
0       return true
0     elseif action == "create" then
0       local mkdir_cmd = string.format("mkdir -p '%s'", dir)
0       return os.execute(mkdir_cmd) == 0
      end
0     return false
    end)

0   return success and err ~= false
  end

* function M._test_directory_writable(dir)
0   return with_directory(dir, "test")
  end

* function M._create_directory(dir)
0   if with_directory(dir, "create") then
0     debug_log("Created directory: " .. dir)
0     return true
    else
0     vim.notify("Failed to create directory: " .. dir, vim.log.levels.ERROR)
0     return false
    end
  end

* function M.ensure_config_dir_exists(dir)
*   return dir and (M._test_directory_writable(dir) or M._create_directory(dir))
  end

  -- Config path resolution -----------------------------------------------------

  local function resolve_config_dir()
*   local logs_path = trim_path(shell.safe_shell_command(
*     "llm logs path",
      "Failed to get LLM logs path"
*   ))
*   if not logs_path then return nil end

*   debug_log("Found logs path: " .. logs_path)
*   return trim_path(shell.safe_shell_command(
*     string.format("dirname '%s'", logs_path),
      "Failed to get config directory"
*   ))
  end

* function M.get_config_path(filename)
*   if not filename then return nil, nil end

    -- Use cached config directory if available
*   if config_dir_cache then
*     local path = join_path(config_dir_cache, filename)
*     debug_log("Using cached path: " .. path)
*     return config_dir_cache, path
    end

    -- Resolve fresh config directory
*   local config_dir = resolve_config_dir()
*   if not config_dir then return nil, nil end

    -- Ensure directory exists and cache it
*   if M.ensure_config_dir_exists(config_dir) then
*     config_dir_cache = config_dir
*     local path = join_path(config_dir, filename)

*     debug_log("Final path: " .. path)
*     debug_log("File " .. (io.open(path, "r") and "exists" or "does not exist"))
*     return config_dir, path
    end

*   return nil, nil
  end

* return M

==============================================================================
lua/llm/core/utils/shell.lua
==============================================================================
  -- llm/utils/shell.lua - Shell command utilities
* local config = require('llm.config')

  -- License: Apache 2.0

* local M = {}
* local DEBUG = false

  -- Simple error notification wrapper
  local function notify_error(msg, level)
*   vim.notify(msg, level or vim.log.levels.ERROR)
  end

  -- Private helper to log debug messages
  local function debug_log(message, level)
*   if config.get('debug') then
0     vim.notify(message, level or vim.log.levels.DEBUG)
    end
  end

  -- Execute shell command safely with error handling
* function M.safe_shell_command(cmd, error_msg)
*   debug_log("Executing command: " .. cmd)

*   local cmd_with_stderr = cmd .. " 2>&1"
*   local result = vim.fn.system(cmd_with_stderr)

*   if result == nil then
*     notify_error("Command returned nil: " .. cmd)
*     return nil, "Command returned nil"
    end

    -- Trim whitespace from result
*   result = result:gsub("^%s*(.-)%s*$", "%1")

*   if result == "" then
*     debug_log("Command returned empty result", vim.log.levels.WARN)
*     if error_msg then
*       notify_error(error_msg, vim.log.levels.WARN)
*       return nil, error_msg
      end
    else
*     debug_log("Command result: " .. (result:len() > 200 and result:sub(1, 200) .. "..." or result))
    end

*   return result, nil
  end

  -- Check if command exists in PATH
* function M.command_exists(cmd)
*   local check_cmd = string.format("command -v %s >/dev/null 2>&1", cmd)
*   return os.execute(check_cmd) == 0
  end

  -- Check if llm is installed and available
* function M.check_llm_installed()
0   if not M.command_exists("llm") then
0     notify_error("llm CLI not found. Install with: pip install llm or brew install llm")
0     return false
    end
0   return true
  end

  -- Execute command and return status, stdout, stderr
* function M.execute(cmd)
*   local handle = io.popen(cmd .. " 2>&1", "r")
*   if not handle then
0     notify_error("Failed to execute command: " .. cmd)
0     return nil, "Failed to execute command"
    end

*   local output = handle:read("*a")
*   local success, _, exit_code = handle:close()

*   if not success or exit_code ~= 0 then
*     notify_error("Command failed with exit code " .. exit_code .. ": " .. cmd)
*     return nil, "Command failed"
    end

*   return output, nil
  end

* local llm_nvim_data_dir = vim.fn.stdpath('data') .. '/llm-nvim'
* local last_update_file = llm_nvim_data_dir .. '/last_update_check.txt'

  -- Ensure the data directory exists
  local function ensure_data_dir_exists()
*   if vim.fn.isdirectory(llm_nvim_data_dir) == 0 then
0     vim.fn.mkdir(llm_nvim_data_dir, "p")
    end
  end

  -- Get the timestamp of the last update check
* function M.get_last_update_timestamp()
*   ensure_data_dir_exists() -- Ensure directory exists before attempting to read
*   local f = io.open(last_update_file, "r")
*   if not f then
0     return 0
    end
*   local content = f:read("*a")
*   f:close()
*   local ts = tonumber(content)
*   return ts or 0
  end

  -- Set the timestamp of the last update check
* function M.set_last_update_timestamp()
*   ensure_data_dir_exists()
*   local f = io.open(last_update_file, "w")
*   if not f then
*     debug_log("Failed to open last_update_check.txt for writing", vim.log.levels.ERROR)
*     return
    end
*   f:write(tostring(os.time()))
*   f:close()
  end

* function M.run_update_command(cmd)
0   local output = vim.fn.system(cmd .. " 2>&1")
0   local exit_code = vim.v.shell_error
0   return output, exit_code
  end

  -- Attempt to update the LLM CLI
* function M.update_llm_cli(bufnr, api_obj)
*   M.set_last_update_timestamp()
*   local update_methods = {
      {
*       cmd_name = "uv",
*       check_exists = true,
*       command = "uv tool upgrade llm",
*       success_msg = "llm CLI updated successfully via uv."
*     },
      {
*       cmd_name = "pipx",
*       check_exists = true,
*       command = "pipx upgrade llm",
*       success_msg = "llm CLI updated successfully via pipx."
*     },
      {
*       cmd_name = "pip",
*       check_exists = false, -- Assuming pip is often aliased or directly available if python is
*       command = "pip install -U llm",
*       success_msg = "llm CLI updated successfully via pip."
*     },
      {
*       cmd_name = "python-pip",
*       check_exists = false, -- Assuming python is in path
*       command = "python -m pip install --upgrade llm",
*       success_msg = "llm CLI updated successfully via python -m pip."
*     },
      {
*       cmd_name = "brew",
*       check_exists = true,
*       command = "brew upgrade llm",
*       success_msg = "llm CLI updated successfully via brew."
      }
*   }

    local function run_next_update(index)
*     if index > #update_methods then
*       vim.api.nvim_buf_set_lines(bufnr, -1, -1, false, { "", "LLM CLI update process finished." })
*       return
      end

*     local method = update_methods[index]
*     local cmd_parts = vim.split(method.command, ' ')
*     local can_run = true

*     if method.check_exists then
*       if not M.command_exists(method.cmd_name) then
*         vim.api.nvim_buf_set_lines(bufnr, -1, -1, false, { "", "--- Attempting with " .. method.cmd_name .. " (skipped: command not found) ---" })
*         can_run = false
        end
      end

*     if can_run then
*       vim.api.nvim_buf_set_lines(bufnr, -1, -1, false, { "", "--- Attempting to update llm CLI using " .. method.cmd_name .. " ---" })
*       api_obj.run_llm_command_streamed(cmd_parts, bufnr, {
          on_exit = function(job_id, exit_code, event_type)
*           if exit_code == 0 then
*             vim.api.nvim_buf_set_lines(bufnr, -1, -1, false, { "", method.success_msg })
*             vim.api.nvim_buf_set_lines(bufnr, -1, -1, false, { "", "Update successful. Stopping further attempts." })
            else
*             vim.api.nvim_buf_set_lines(bufnr, -1, -1, false, { "", method.cmd_name .. " update failed with exit code " .. exit_code .. "." })
*             run_next_update(index + 1) -- Try next method
            end
          end,
          on_stderr = function(job_id, data, event_type)
0           vim.api.nvim_buf_set_lines(bufnr, -1, -1, false, data)
          end,
*       })
      else
*       run_next_update(index + 1) -- Try next method if current one was skipped
      end
    end

*   run_next_update(1) -- Start the update process
  end

* return M

==============================================================================
lua/llm/core/utils/ui.lua
==============================================================================
* local M = {}

  -- Common buffer configuration
* local DEFAULT_BUFFER_OPTS = {
*   buftype = 'nofile',
*   bufhidden = 'wipe',
*   swapfile = false
  }

  -- Convert content string to lines array
  local function content_to_lines(content)
*   local lines = {}
*   for line in content:gmatch("[^\r\n]+") do
*     table.insert(lines, line)
    end
*   return lines
  end

  -- Configure a buffer with standard options
  local function configure_buffer(buf, opts)
*   for opt, val in pairs(DEFAULT_BUFFER_OPTS) do
*     vim.api.nvim_buf_set_option(buf, opt, val)
    end

*   if opts.name then
*     vim.api.nvim_buf_set_name(buf, opts.name)
    end

*   if opts.filetype then
*     vim.api.nvim_buf_set_option(buf, 'filetype', opts.filetype)
    end

*   if opts.content then
*     vim.api.nvim_buf_set_lines(buf, 0, -1, false, content_to_lines(opts.content))
    end
  end

* function M.create_prompt_buffer()
    -- Create a new vertical split
*   vim.cmd('vnew')

    -- Get the new buffer
*   local buf = vim.api.nvim_get_current_buf()

    -- Switch to insert mode
*   vim.cmd('startinsert')

    -- Set the content of the buffer to a prompt
*   local prompt_text = "Enter your prompt here and then save and close the buffer to continue."
*   vim.api.nvim_buf_set_lines(buf, 0, -1, false, { prompt_text })

*   local group = vim.api.nvim_create_augroup("LLMSavePrompt", { clear = true })
*   vim.api.nvim_create_autocmd("BufWriteCmd", {
*     group = group,
*     buffer = buf,
      callback = function()
*       local lines = vim.api.nvim_buf_get_lines(buf, 0, -1, false)
*       table.remove(lines, 1)
*       local content = table.concat(lines, "\n")
        -- The command needs to be loaded to be called.
*       local commands = require('llm.commands')
*       commands.prompt(content)
      end,
    })

*   return buf
  end

* function M.create_chat_buffer()
    -- Create a new vertical split
*   vim.cmd('vnew')

    -- Get the new buffer
*   local buf = vim.api.nvim_get_current_buf()

    -- Get the model name
*   local config = require('llm.config')
*   local model_name = config.get("model") or "default"

    -- Generate a unique chat ID
*   local chat_id = tostring(math.random(1000, 9999))

    -- Configure the buffer
*   configure_buffer(buf, {
*     name = "LLM Chat - " .. model_name .. " (" .. chat_id .. ")",
*     filetype = "markdown"
    })

    -- Set the content of the buffer to a prompt
*   local prompt_text = {
*     '--- User Prompt ---',
*     'Enter your prompt below and press <Enter> to submit.',
*     '-------------------',
      ''
*   }
*   vim.api.nvim_buf_set_lines(buf, 0, -1, false, prompt_text)

    -- Set up keymap for <Enter>
*   vim.api.nvim_buf_set_keymap(buf, 'i', '<Enter>', '<Cmd>lua require("llm.chat").send_prompt()<CR>',
*     { noremap = true, silent = true })
    -- Add a keymap for closing the buffer
*   vim.api.nvim_buf_set_keymap(buf, 'n', 'q', '<Cmd>bd<CR>', { noremap = true, silent = true })

    -- Move the cursor to the end of the prompt
*   vim.api.nvim_win_set_cursor(0, { 4, 0 })

    -- Switch to insert mode
*   vim.cmd('startinsert')

*   return buf
  end

* function M.create_buffer_with_content(initial_content, buffer_name, filetype)
*   local buf = vim.api.nvim_create_buf(false, true)

    -- Only set name if provided and buffer doesn't already have one
*   if buffer_name and vim.api.nvim_buf_get_name(buf) == "" then
0     vim.api.nvim_buf_set_name(buf, buffer_name)
    end

*   if filetype then
*     vim.api.nvim_buf_set_option(buf, 'filetype', filetype)
    end

*   if initial_content then
*     vim.api.nvim_buf_set_lines(buf, 0, -1, false, content_to_lines(initial_content))
    end

*   return buf
  end

* function M.replace_buffer_with_content(content, buffer, filetype)
*   configure_buffer(buffer, {
*     filetype = filetype,
*     content = content
    })
*   return buffer
  end

  -- Common window configuration
  local function get_window_config(width_ratio, height_ratio, title)
*   local width = math.floor(vim.o.columns * width_ratio)
*   local height = math.floor(vim.o.lines * height_ratio)
*   return {
*     relative = 'editor',
*     width = width,
*     height = height,
*     row = math.floor((vim.o.lines - height) / 2),
*     col = math.floor((vim.o.columns - width) / 2),
*     style = 'minimal',
*     border = 'rounded',
*     title = ' ' .. (title or 'LLM') .. ' ',
*     title_pos = 'center'
*   }
  end

* function M.create_floating_window(buf, title)
*   local win = vim.api.nvim_open_win(buf, true, get_window_config(0.8, 0.8, title))
*   vim.api.nvim_win_set_option(win, 'cursorline', true)
*   vim.api.nvim_win_set_option(win, 'winblend', 0)
*   return win
  end

  -- Common keybindings for floating windows
  local function set_floating_keymaps(buf, confirm_cmd, cancel_cmd)
*   local keymaps = {
*     { mode = 'i', key = '<CR>',  cmd = confirm_cmd },
*     { mode = 'n', key = '<CR>',  cmd = confirm_cmd },
*     { mode = '',  key = '<Esc>', cmd = cancel_cmd }
*   }

*   for _, km in ipairs(keymaps) do
*     vim.api.nvim_buf_set_keymap(buf, km.mode, km.key, km.cmd, { noremap = true, silent = true })
    end
  end

* function M.floating_input(opts, on_confirm)
*   local buf = vim.api.nvim_create_buf(false, true)
*   local win = vim.api.nvim_open_win(buf, true, get_window_config(0.6, 1, opts.prompt or 'Input'))

*   if opts.default then
0     vim.api.nvim_buf_set_lines(buf, 0, -1, false, { opts.default })
    end

*   set_floating_keymaps(buf,
*     '<cmd>lua require("llm.core.utils.ui")._confirm_floating_input()<CR>',
      '<cmd>lua require("llm.core.utils.ui")._close_floating_input()<CR>'
*   )

*   vim.api.nvim_buf_set_var(buf, 'floating_input_callback', function(input)
0     if on_confirm then on_confirm(input) end
    end)

*   vim.api.nvim_command('startinsert')
  end

* function M._confirm_floating_input()
0   local buf = vim.api.nvim_get_current_buf()
0   local win = vim.api.nvim_get_current_win()
0   local lines = vim.api.nvim_buf_get_lines(buf, 0, -1, false)
0   local input = table.concat(lines, '\n')
0   local callback = vim.api.nvim_buf_get_var(buf, 'floating_input_callback')
0   vim.api.nvim_win_close(win, true)
0   vim.api.nvim_command('stopinsert')
0   if callback then
0     callback(input)
    end
  end

* function M._close_floating_input()
0   local win = vim.api.nvim_get_current_win()
0   vim.api.nvim_win_close(win, true)
  end

  -- Create a floating confirmation dialog with styling
* function M.floating_confirm(opts)
*   local prompt = opts.prompt or "Are you sure?"
*   local on_confirm = opts.on_confirm or function() end

    -- Calculate window dimensions
*   local width = math.min(math.floor(vim.o.columns * 0.4), 60)
*   local height = 5 -- Increased height for better spacing
*   local row = math.floor((vim.o.lines - height) / 2)
*   local col = math.floor((vim.o.columns - width) / 2)

    -- Create window with styling
*   local buf = vim.api.nvim_create_buf(false, true)
*   local win_opts = {
*     relative = 'editor',
*     width = width,
*     height = height,
*     row = row,
*     col = col,
*     style = 'minimal',
*     border = 'rounded',
*     title = ' ' .. prompt .. ' ',
*     title_pos = 'center',
*     focusable = true,
*     noautocmd = true,
*     zindex = 50
    }

    -- Apply highlights before creating window
*   vim.api.nvim_set_hl(0, 'LlmConfirmTitle', { fg = '#f8f8f2', bg = '#44475a', bold = true })
*   vim.api.nvim_set_hl(0, 'LlmConfirmBorder', { fg = '#6272a4' })
*   vim.api.nvim_set_hl(0, 'LlmConfirmText', { fg = '#f8f8f2' })
*   vim.api.nvim_set_hl(0, 'LlmConfirmButton', { fg = '#50fa7b', bold = true })
*   vim.api.nvim_set_hl(0, 'LlmConfirmButtonCancel', { fg = '#ff5555', bold = true })
*   vim.api.nvim_set_hl(0, 'LlmUserPrompt', { fg = '#50fa7b' })    -- Green for user prompts
*   vim.api.nvim_set_hl(0, 'LlmModelResponse', { fg = '#bd93f9' }) -- Purple for model responses

*   local win = vim.api.nvim_open_win(buf, true, win_opts)

    -- Set window highlights
*   vim.api.nvim_win_set_option(win, 'winhl',
*     'Normal:LlmConfirmText,NormalFloat:LlmConfirmText,FloatBorder:LlmConfirmBorder,Title:LlmConfirmTitle')

    -- Add compact styled content that fits in 5 lines
*   local lines = {
*     "┌───────────────────────────────┐",
*     "│  Confirm your action          │",
*     "└───────────────────────────────┘",
*     "",
      "  [Y]es    [N]o"
*   }
*   vim.api.nvim_buf_set_lines(buf, 0, -1, false, lines)

    -- Add highlights for the buttons
*   vim.api.nvim_buf_add_highlight(buf, -1, 'LlmConfirmButton', 4, 3, 7)         -- Yes
*   vim.api.nvim_buf_add_highlight(buf, -1, 'LlmConfirmButtonCancel', 4, 11, 13) -- No

    -- Set keymaps with better visual feedback
*   vim.api.nvim_buf_set_keymap(buf, 'n', 'y', '<Cmd>lua require("llm.core.utils.ui")._confirm_floating_dialog(true)<CR>',
*     { noremap = true, silent = true, desc = "Confirm action" })
*   vim.api.nvim_buf_set_keymap(buf, 'n', 'Y', '<Cmd>lua require("llm.core.utils.ui")._confirm_floating_dialog(true)<CR>',
*     { noremap = true, silent = true, desc = "Confirm action" })
*   vim.api.nvim_buf_set_keymap(buf, 'n', 'n', '<Cmd>lua require("llm.core.utils.ui")._confirm_floating_dialog(false)<CR>',
*     { noremap = true, silent = true, desc = "Cancel action" })
*   vim.api.nvim_buf_set_keymap(buf, 'n', 'N', '<Cmd>lua require("llm.core.utils.ui")._confirm_floating_dialog(false)<CR>',
*     { noremap = true, silent = true, desc = "Cancel action" })
*   vim.api.nvim_buf_set_keymap(buf, 'n', '<Esc>', '<Cmd>lua require("llm.core.utils.ui")._confirm_floating_dialog(false)<CR>',
*     { noremap = true, silent = true, desc = "Cancel action" })

    -- Store callback in buffer var
*   vim.api.nvim_buf_set_var(buf, 'floating_confirm_callback', on_confirm)
  end

* function M._confirm_floating_dialog(confirmed)
0   local buf = vim.api.nvim_get_current_buf()
0   local callback = vim.api.nvim_buf_get_var(buf, 'floating_confirm_callback')
0   vim.api.nvim_win_close(vim.api.nvim_get_current_win(), true)
0   if confirmed then
0     callback("Yes")
    else
0     callback("No")
    end
  end

* function M.append_to_buffer(bufnr, content, highlight_group)
*   vim.notify(
*     "append_to_buffer called for bufnr: " .. tostring(bufnr) .. ", content length: " .. tostring(#(content or "")),
*     vim.log.levels.DEBUG)
*   local lines = content_to_lines(content or '')
*   if #lines == 0 then
*     vim.notify("append_to_buffer: No lines to append.", vim.log.levels.DEBUG)
*     return
    end

*   local ok, last_line = pcall(vim.api.nvim_buf_line_count, bufnr)
*   if not ok then
*     vim.notify("append_to_buffer: Invalid buffer number: " .. tostring(bufnr), vim.log.levels.ERROR)
*     return -- Invalid buffer, do nothing
    end

*   vim.api.nvim_buf_set_lines(bufnr, last_line, last_line, false, lines)

*   if highlight_group then
0     for i = 0, #lines - 1 do
0       vim.api.nvim_buf_add_highlight(bufnr, -1, highlight_group, last_line + i, 0, -1)
      end
    end

*   vim.notify("append_to_buffer: Appended " .. tostring(#lines) .. " lines to buffer " .. tostring(bufnr),
*     vim.log.levels.DEBUG)

    -- Move cursor to the end of the buffer if it's the current buffer
*   if vim.api.nvim_get_current_buf() == bufnr then
*     vim.api.nvim_win_set_cursor(0, { last_line + #lines, 0 })
*     vim.notify("append_to_buffer: Cursor moved in current window", vim.log.levels.DEBUG)
    else
0     vim.notify("append_to_buffer: Not current buffer, cursor not moved.", vim.log.levels.DEBUG)
    end
  end

* return M

==============================================================================
lua/llm/core/utils/text.lua
==============================================================================
  -- llm/core/utils/text.lua - Text manipulation utilities for llm-nvim
  -- License: Apache 2.0

* local M = {}

  -- Get visual selection
* function M.get_visual_selection(bufnr)
*   local buf_to_use = bufnr or 0
*   local start_pos = vim.fn.getpos("'<")
*   local end_pos = vim.fn.getpos("'>")
*   local start_line = start_pos[2]
*   local end_line = end_pos[2]
*   local start_col = start_pos[3]
*   local end_col = end_pos[3]

*   if start_line == 0 or end_line == 0 then
0     return ""
    end

*   local lines = vim.api.nvim_buf_get_lines(buf_to_use, start_line - 1, end_line, false)
*   if #lines == 0 then
0     return ""
    end

*   if #lines == 1 then
*     return string.sub(lines[1], start_col, end_col)
    else
0     lines[#lines] = string.sub(lines[#lines], 1, end_col)
0     lines[1] = string.sub(lines[1], start_col)
0     return table.concat(lines, "\n")
    end
  end

  -- Capitalize the first letter of a string
* function M.capitalize(s)
*   if not s or s == '' then return s end
*   return s:sub(1, 1):upper() .. s:sub(2)
  end

  -- Escape special pattern characters in a string
* function M.escape_pattern(s)
    -- Escape these special pattern characters: ^$()%.[]*+-?
*   local escaped = string.gsub(s, "[%(%)%.%+%-%*%?%[%]%^%$%%]", "%%%1")
*   return escaped
  end

  -- Simple YAML Parser
  -- Parses a subset of YAML (dictionaries, lists, basic scalars) into a Lua table.
  -- Handles indentation for structure. Does not support complex types, anchors, etc.
* function M.parse_simple_yaml(filepath)
*   local config = require('llm.config')
*   local debug_mode = config.get('debug')

*   if debug_mode then
0     vim.notify("Parsing YAML file: " .. filepath, vim.log.levels.DEBUG)
    end

*   local file = io.open(filepath, "r")
*   if not file then
0     if debug_mode then
0       vim.notify("YAML file not found or could not be opened: " .. filepath, vim.log.levels.WARN)
      end
0     return nil -- Return nil if file cannot be opened
    end

*   local lines = {}
*   for line in file:lines() do
*     table.insert(lines, line)
    end
*   file:close()

*   local data = {}
*   local stack = { { data = data, indent = -1 } }

    local function trim(s)
*     return s:match("^%s*(.-)%s*$")
    end

*   for _, line in ipairs(lines) do
*     if not line:match("^%s*$") and not line:match("^%s*#") then
*       local indent = line:match("^(%s*)"):len()
*       local content = trim(line)

*       while indent <= stack[#stack].indent do
*         table.remove(stack)
        end

*       local parent = stack[#stack].data

*       local key, val = content:match("([^:]+):%s*(.*)")
*       if key then
*         key = trim(key)
*         val = trim(val)
*         if val == "" then
*           parent[key] = {}
*           table.insert(stack, { data = parent[key], indent = indent })
          else
*           parent[key] = val
          end
        else
*         local item = content:match("^-%s*(.*)")
*         if item then
*           table.insert(parent, item)
          end
        end
      end
    end

*   return data
  end

* function M.wrap(text, width, indent)
*   indent = indent or ''
*   width = width or 80

*   local words = {}
*   for word in text:gmatch('%S+') do
*     table.insert(words, word)
    end

*   if #words == 0 then
*     return ''
    end

*   local lines = {}
*   local current_line = indent .. words[1]

*   for i = 2, #words do
*     local word = words[i]
*     if #current_line + 1 + #word > width then
*       table.insert(lines, current_line)
*       current_line = indent .. word
      else
*       current_line = current_line .. ' ' .. word
      end
    end
*   table.insert(lines, current_line)

*   return table.concat(lines, '\n')
  end

* return M

==============================================================================
lua/llm/ui/unified_manager.lua
==============================================================================
  -- llm/ui/unified_manager.lua - Unified management window for llm-nvim
  -- License: Apache 2.0

* local M = {}

* local api = vim.api
* local ui = require('llm.core.utils.ui')
* local styles = require('llm.ui.styles')
* local text = require('llm.core.utils.text')

  -- Manager modules
* local models_manager = require('llm.managers.models_manager')
* local plugins_manager = require('llm.managers.plugins_manager')
* local keys_manager = require('llm.managers.keys_manager')
* local fragments_manager = require('llm.managers.fragments_manager')
* local templates_manager = require('llm.managers.templates_manager')
* local schemas_manager = require('llm.managers.schemas_manager')

  -- State for the unified window
* local state = {
*   winid = nil,
*   bufnr = nil,
*   current_view = nil,
*   last_view = "Models", -- Default to Models view first time
  }

  -- Get the last viewed manager
* function M.get_last_view()
0   return state.last_view or "Models"
  end

  -- Available views and their corresponding manager functions
* local views = {
*   Models = {
*     populate = models_manager.populate_models_buffer,
*     setup_keymaps = models_manager.setup_models_keymaps,
*     title = "Models",
*     manager_module = models_manager,
*   },
*   Plugins = {
*     populate = plugins_manager.populate_plugins_buffer,
*     setup_keymaps = plugins_manager.setup_plugins_keymaps,
*     title = "Plugins",
*     manager_module = plugins_manager,
*   },
*   Keys = {
*     populate = keys_manager.populate_keys_buffer,
*     setup_keymaps = keys_manager.setup_keys_keymaps,
*     title = "API Keys",
*     manager_module = keys_manager,
*   },
*   Fragments = {
*     populate = fragments_manager.populate_fragments_buffer,
*     setup_keymaps = fragments_manager.setup_fragments_keymaps,
*     title = "Fragments",
*     manager_module = fragments_manager,
*   },
*   Templates = {
*     populate = templates_manager.populate_templates_buffer,
*     setup_keymaps = templates_manager.setup_templates_keymaps,
*     title = "Templates",
*     manager_module = templates_manager,
*   },
*   Schemas = {
*     populate = schemas_manager.populate_schemas_buffer,
*     setup_keymaps = schemas_manager.setup_schemas_keymaps,
*     title = "Schemas",
*     manager_module = schemas_manager,
*   },
  }

  -- Close the unified window
  local function close_window()
    -- Save current view as last_view before closing
0   if state.current_view then
0     state.last_view = state.current_view
    end

0   if state.winid and api.nvim_win_is_valid(state.winid) then
0     api.nvim_win_close(state.winid, true)
    end
0   if state.bufnr and api.nvim_buf_is_valid(state.bufnr) then
      -- Check if buffer is listed before trying to delete
0     if vim.fn.bufexists(state.bufnr) == 1 and vim.fn.buflisted(state.bufnr) == 1 then
0       pcall(api.nvim_buf_delete, state.bufnr, { force = true })
0     elseif vim.fn.bufexists(state.bufnr) == 1 then
        -- If buffer exists but is not listed (e.g., nofile), try deleting directly
0       pcall(api.nvim_buf_delete, state.bufnr, { force = true })
      end
    end
0   state.winid = nil
0   state.bufnr = nil
0   state.current_view = nil
  end

  -- Setup common keymaps for switching views
  local function setup_common_keymaps(bufnr)
    local function set_keymap(mode, lhs, rhs)
0     api.nvim_buf_set_keymap(bufnr, mode, lhs, rhs, { noremap = true, silent = true })
    end

0   set_keymap('n', 'q', '<Cmd>lua require("llm.ui.unified_manager").close()<CR>')
0   set_keymap('n', '<Esc>', '<Cmd>lua require("llm.ui.unified_manager").close()<CR>')

    -- Keymaps to switch views
0   set_keymap('n', 'M', '<Cmd>lua require("llm.ui.unified_manager").switch_view("Models")<CR>')
0   set_keymap('n', 'P', '<Cmd>lua require("llm.ui.unified_manager").switch_view("Plugins")<CR>')
0   set_keymap('n', 'K', '<Cmd>lua require("llm.ui.unified_manager").switch_view("Keys")<CR>')
0   set_keymap('n', 'F', '<Cmd>lua require("llm.ui.unified_manager").switch_view("Fragments")<CR>')
0   set_keymap('n', 'T', '<Cmd>lua require("llm.ui.unified_manager").switch_view("Templates")<CR>')
0   set_keymap('n', 'S', '<Cmd>lua require("llm.ui.unified_manager").switch_view("Schemas")<CR>')
  end

  -- Switch the view within the unified window
* function M.switch_view(view_name)
0   if not state.winid or not api.nvim_win_is_valid(state.winid) then
0     M.open(view_name) -- Open if not already open
0     return
    end


0   if not views[view_name] then
0     vim.notify("Invalid view: " .. view_name, vim.log.levels.ERROR)
0     return
    end

0   state.current_view = view_name
0   local view_config = views[view_name]

    -- Clear the buffer
0   api.nvim_buf_set_option(state.bufnr, 'modifiable', true)
0   api.nvim_buf_set_lines(state.bufnr, 0, -1, false, {})

    -- Populate buffer with new view content
0   local success, err = pcall(view_config.populate, state.bufnr)
0   if not success then
0     vim.notify("Error populating " .. view_name .. " view: " .. tostring(err), vim.log.levels.ERROR)
      -- Add error message to buffer
0     api.nvim_buf_set_lines(state.bufnr, 0, -1, false, {
0       "# Error loading " .. view_name .. " Manager",
        "",
0       "Details: " .. tostring(err),
        "",
        "Press [q]uit or use navigation keys ([M]odels, [P]lugins, etc.)"
      })
    end

    -- Set buffer options
0   api.nvim_buf_set_option(state.bufnr, 'modifiable', false)
0   api.nvim_buf_set_name(state.bufnr, 'LLM Unified Manager (' .. view_config.title .. ')')
0   api.nvim_win_set_config(state.winid, { title = ' LLM Unified Manager (' .. view_config.title .. ') ' })

    -- Setup syntax highlighting
0   styles.setup_buffer_syntax(state.bufnr)

    -- Setup keymaps (common + view-specific)
    -- Setting new keymaps below will overwrite any previous ones for the same keys.
0   setup_common_keymaps(state.bufnr)
0   if view_config.setup_keymaps then
0     pcall(view_config.setup_keymaps, state.bufnr, view_config.manager_module) -- Pass manager module if needed
    end
  end

  -- Open the unified window with a specific view
* function M.open(initial_view)
0   initial_view = initial_view or "Models" -- Default view

0   if not views[initial_view] then
0     vim.notify("Invalid initial view: " .. initial_view, vim.log.levels.ERROR)
0     return
    end

    -- Check if already open
0   if state.winid and api.nvim_win_is_valid(state.winid) then
      -- If open but wrong view, switch view
0     if state.current_view ~= initial_view then
0       M.switch_view(initial_view)
      end
      -- Bring window to front if already open with correct view
0     api.nvim_set_current_win(state.winid)
0     return
    end

    -- Create buffer
0   state.bufnr = api.nvim_create_buf(false, true)
0   api.nvim_buf_set_option(state.bufnr, 'buftype', 'nofile')
0   api.nvim_buf_set_option(state.bufnr, 'bufhidden', 'wipe')
0   api.nvim_buf_set_option(state.bufnr, 'swapfile', false)

    -- Create window using ui function
0   state.winid = ui.create_floating_window(state.bufnr, 'LLM Unified Manager')

    -- Switch to the initial view
0   M.switch_view(initial_view)
  end

  -- Toggle the unified window
* function M.toggle(view_name)
0   if not view_name or view_name == "" then
0     view_name = state.last_view or "Models"
    else
0     view_name = text.capitalize(view_name)
    end

0   if state.winid and api.nvim_win_is_valid(state.winid) then
0     close_window()
    else
0     M.open(view_name)
    end
  end

  -- Get the last viewed manager
* function M.get_last_view()
0   return state.last_view or "Models"
  end

  -- Close the unified window (public function)
* function M.close()
0   close_window()
  end

  -- Function for individual managers to call when opened directly
* function M.open_specific_manager(view_name)
    -- Update last_view before opening
0   if state.current_view then
0     state.last_view = state.current_view
    end
0   M.open(view_name)
  end

  -- Get all available view names for completion
* function M.get_views()
0   local view_names = {}
0   for name, _ in pairs(views) do
0     table.insert(view_names, name:lower())
    end
0   return view_names
  end

* return M

==============================================================================
lua/llm/ui/ui.lua
==============================================================================
  -- lua/llm/ui.lua - UI functions for the llm-nvim plugin

* local M = {}
* local api = vim.api

* function M.display_in_buffer(bufnr, lines, syntax)
*   api.nvim_buf_set_lines(bufnr, 0, -1, false, lines)
*   if syntax then
*     vim.bo[bufnr].syntax = syntax
    end
  end

* function M.notify(message, level)
*   vim.notify(message, level)
  end

* function M.get_input(prompt, on_confirm)
*   vim.ui.input({ prompt = prompt }, on_confirm)
  end

* function M.select(items, opts, on_choice)
*   vim.ui.select(items, opts, on_choice)
  end

* return M

==============================================================================
lua/llm/ui/styles.lua
==============================================================================
  -- llm/styles.lua - Centralized styling for llm-nvim
  -- License: Apache 2.0

* local M = {}

  -- Color palette
* M.colors = {
    -- Base colors
*   blue = "#61afef",
*   cyan = "#56b6c2",
*   green = "#98c379",
*   red = "#e06c75",
*   purple = "#c678dd",
*   yellow = "#e5c07b",
*   orange = "#d19a66",
*   gray = "#abb2bf",
*   dark_gray = "#3b4048",

    -- Semantic colors (can be mapped to base colors)
*   header = "#61afef",
*   subheader = "#56b6c2",
*   section = "#c678dd",
*   action = "#e5c07b",
*   content = "#abb2bf",
*   success = "#98c379",
*   error = "#e06c75",
*   divider = "#3b4048",
*   keybinding = "#e5c07b",
* }

  -- Highlight groups
* M.highlights = {
    -- Common highlight groups
*   Header = { fg = M.colors.header, style = "bold" },
*   SubHeader = { fg = M.colors.subheader, style = "bold" },
*   Section = { fg = M.colors.section, style = "bold" },
*   Action = { fg = M.colors.action, style = "bold" },
*   Divider = { fg = M.colors.divider },
*   Content = { fg = M.colors.content },
*   Success = { fg = M.colors.success, style = "bold" },
*   Error = { fg = M.colors.error },
*   Custom = { fg = M.colors.yellow, style = "bold" },
*   Keybinding = { fg = M.colors.keybinding, style = "bold" },
*   NavKeybinding = { fg = M.colors.cyan, style = "bold" }, -- Added for navigation keys

    -- Checkbox and status states
*   CheckboxInstalled = { fg = M.colors.success, style = "bold" },
*   CheckboxAvailable = { fg = M.colors.error },
*   Installed = { fg = M.colors.success, style = "bold", bg = "#333333" },
*   NotInstalled = { fg = M.colors.error, style = "bold", bg = "#1a1a1a" },
*   PluginInstalled = { fg = M.colors.green },
*   PluginNotInstalled = { fg = M.colors.red },

    -- Model-specific highlights
*   ModelOpenAI = { fg = M.colors.cyan },
*   ModelAnthropic = { fg = M.colors.green },
*   ModelMistral = { fg = M.colors.purple },
*   ModelGemini = { fg = M.colors.yellow },
*   ModelGroq = { fg = M.colors.blue },
*   ModelLocal = { fg = M.colors.orange },
*   ModelDefault = { fg = M.colors.success, style = "bold" },
*   ModelAlias = { fg = M.colors.purple },

    -- Fragment-specific highlights
*   FragmentHash = { fg = M.colors.blue },
*   FragmentSource = { fg = M.colors.green },
*   FragmentAliases = { fg = M.colors.purple },
*   FragmentDate = { fg = M.colors.cyan },
*   FragmentContent = { fg = M.colors.content },

    -- Key-specific highlights
*   KeyAvailable = { fg = M.colors.success },
*   KeyMissing = { fg = M.colors.error },
*   KeyAction = { link = "LLMCustom" },

    -- Schema-specific highlights (using common highlight groups)
*   SchemaHeader = { link = "LLMHeader" },
*   SchemaSection = { link = "LLMSubHeader" },
*   SchemaContent = { link = "LLMContent" },
*   SchemaFooter = { link = "LLMAction" },
*   SchemaName = { fg = M.colors.yellow, style = "bold" },
*   SchemaId = { fg = M.colors.blue, style = "bold" },
*   Success = { fg = M.colors.success, style = "bold" },
*   Error = { fg = M.colors.error, style = "bold" },

    -- Template-specific highlights (using common highlight groups)
*   TemplateHeader = { link = "LLMHeader" },
*   TemplateSection = { link = "LLMSubHeader" },
*   TemplateContent = { link = "LLMContent" },
*   TemplateFooter = { link = "LLMAction" },
*   TemplateName = { fg = M.colors.yellow, style = "bold" },

    -- Template-specific highlights
*   TemplateHeader = { fg = M.colors.header, style = "bold" },
*   TemplateSection = { fg = M.colors.section, style = "bold" },
*   TemplateContent = { fg = M.colors.content },
*   TemplateFooter = { fg = M.colors.action, style = "bold" },
*   LoaderTitle = { fg = M.colors.purple, style = "bold" },
*   LoaderUsage = { fg = M.colors.cyan },
* }

  -- Setup function to create all highlight groups
* function M.setup_highlights()
    -- Create highlight commands
*   local highlight_cmds = {}

*   for name, attrs in pairs(M.highlights) do
*     local cmd = "highlight default LLM" .. name

*     if attrs.link then
*       cmd = cmd .. " link=" .. attrs.link
*     elseif attrs.fg then
*       cmd = cmd .. " guifg=" .. attrs.fg

*       if attrs.bg then
*         cmd = cmd .. " guibg=" .. attrs.bg
        end

*       if attrs.style then
*         cmd = cmd .. " gui=" .. attrs.style
        end
      end

*     table.insert(highlight_cmds, cmd)
    end

    -- Execute all highlight commands
*   for _, cmd in ipairs(highlight_cmds) do
      -- Execute each command separately to avoid errors stopping the whole batch
*     pcall(vim.cmd, cmd)
    end
  end

  -- Define syntax patterns for different UI elements
* M.syntax_patterns = {
    -- Headers
*   header = "syntax match LLMHeader /^#.*/",
*   subheader = "syntax match LLMSubHeader /^##.*/",





    -- Action text
*   action = "syntax match LLMAction /Press.*$/",

    -- Dividers
*   divider = "syntax match LLMDivider /^─\\+$/",

    -- Custom items
*   custom = "syntax match LLMCustom /\\[+\\].*/",

    -- Keybindings in brackets
*   keybinding = "syntax match LLMKeybinding /\\[[a-z?]\\]/", -- Match action keys
*   nav_keybinding = "syntax match LLMNavKeybinding /\\[[A-Z]\\]/", -- Match navigation keys (M, P, K, F, T, S)

    -- Section headers
*   section = "syntax match LLMSection /^[A-Za-z][A-Za-z0-9 ]*:$/",

    -- Model-specific patterns
*   model_openai = "syntax match LLMModelOpenAI /^OpenAI.*$\\|\\[ \\] OpenAI.*/",
*   model_anthropic = "syntax match LLMModelAnthropic /^Anthropic.*$\\|\\[ \\] Anthropic.*/",
*   model_mistral = "syntax match LLMModelMistral /^Mistral.*$\\|\\[ \\] Mistral.*/",
*   model_gemini = "syntax match LLMModelGemini /^Gemini.*$\\|\\[ \\] Gemini.*/",
*   model_groq = "syntax match LLMModelGroq /^Groq.*$\\|\\[ \\] Groq.*/",
*   model_default = "syntax match LLMModelDefault /\\[✓\\].*/",

    -- Fragment-specific patterns
*   fragment_hash = "syntax match LLMFragmentHash /^Fragment \\d\\+: [0-9a-f]\\+$/",
*   fragment_source = "syntax match LLMFragmentSource /^  Source: .*$/",
*   fragment_aliases = "syntax match LLMFragmentAliases /^  Aliases: .*$/",
*   fragment_date = "syntax match LLMFragmentDate /^  Date: .*$/",
*   fragment_content = "syntax match LLMFragmentContent /^  Content: .*$/",

    -- Key-specific patterns
*   key_available = "syntax match LLMKeyAvailable /\\[✓\\].*/",
*   key_missing = "syntax match LLMKeyMissing /\\[ \\].*/",
*   key_action = "syntax match LLMCustom /^\\[+\\] Add custom key$/",

    -- Schema-specific patterns (using common highlight groups)
*   schema_header = "syntax match LLMHeader /^# Schema:/",
*   schema_section = "syntax match LLMSubHeader /^## .*$/",
*   schema_footer = "syntax match LLMAction /^Press.*$/",
*   schema_id = "syntax match LLMSchemaId /^Schema \\d\\+: [0-9a-f]\\+$/",
*   schema_name = "syntax match LLMSchemaName /^  Name: .*$/",
*   schema_description = "syntax match LLMContent /^  Description: .*$/",

    -- Template-specific patterns
*   template_header = "syntax match LLMHeader /^# Template:/",
*   template_section = "syntax match LLMSubHeader /^## .*$/",
*   template_footer = "syntax match LLMAction /^Press.*$/",
*   template_name = "syntax match LLMTemplateName /^Template \\d\\+: .*$/",
*   template_description = "syntax match LLMContent /^  Description: .*$/",
*   loader_title = "syntax match LLMLoaderTitle /^Loader \\d\\+: .*$/",
*   loader_usage = "syntax match LLMLoaderUsage /^  Usage: .*$/",
* }

  -- Setup syntax highlighting for a buffer
* function M.setup_buffer_syntax(buf)
    -- Apply common syntax patterns to the buffer
*   for name, pattern in pairs(M.syntax_patterns) do
      -- Use pcall to catch any syntax errors
*     local success, err = pcall(function()
*       vim.api.nvim_buf_call(buf, function()
0         vim.cmd(pattern)
        end)
      end)

*     if not success then
0         local config = require('llm.config')
0         if config.get('debug') then
0             vim.notify("Syntax pattern error for " .. name .. ": " .. tostring(err), vim.log.levels.WARN)
          end
      end
    end
  end

  -- Setup all styling for a buffer
* function M.setup_buffer_styling(buf)
    -- Setup highlights
0   M.setup_highlights()

    -- Setup syntax patterns
*   M.setup_buffer_syntax(buf)
  end

* return M

==============================================================================
lua/llm/ui/views/schemas_view.lua
==============================================================================
  -- llm/ui/views/schemas_view.lua - UI functions for schema management
  -- License: Apache 2.0

* local M = {}

* local ui = require('llm.core.utils.ui')
* local styles = require('llm.ui.styles')
* local api = vim.api

* function M.select_schema(schemas, callback)
*   local schema_items = {}

*   for _, schema in ipairs(schemas) do
*     table.insert(schema_items, schema)
    end

*   if #schema_items == 0 then
*     vim.notify("No schemas found", vim.log.levels.INFO)
*     return
    end

*   table.sort(schema_items, function(a, b) return a.name < b.name end)

*   vim.ui.select(schema_items, {
*     prompt = "Select a schema to run:",
      format_item = function(item)
0       return item.name .. " - " .. (item.description or "")
      end
*   }, callback)
  end

* function M.get_schema_type(callback)
*   vim.ui.select({
*     "Regular schema",
      "Multi schema (array of items)"
*   }, {
*     prompt = "Schema type:"
*   }, callback)
  end

* function M.get_input_source(callback)
*   vim.ui.select({
*     "Current buffer",
*     "URL (will use curl)",
      "Enter text manually"
*   }, {
*     prompt = "Choose input source:"
*   }, callback)
  end

* function M.get_url(callback)
*   ui.floating_input({
*     prompt = "Enter URL:",
*   }, callback)
  end

* function M.get_schema_name(callback)
*   ui.floating_input({
*     prompt = "Enter schema name:",
*   }, callback)
  end

* function M.get_schema_format(callback)
*   ui.floating_confirm({
*     prompt = "Select schema format:",
*     on_confirm = callback,
    })
  end

* function M.get_alias(current_alias, callback)
*   local prompt_text = current_alias and "Enter new alias (current: " .. current_alias .. "): " or
*       "Enter alias for schema: "
*   ui.floating_input({
*     prompt = prompt_text,
*     default = current_alias or "",
*   }, callback)
  end

* function M.confirm_delete_alias(alias, callback)
*   ui.floating_confirm({
*     prompt = "Delete alias '" .. alias .. "'?",
      on_confirm = function(confirmed)
0       callback(confirmed == "Yes")
      end,
    })
  end

* function M.show_details(schema_id, schema, manager)
0   local detail_buf = api.nvim_create_buf(false, true)
0   api.nvim_buf_set_option(detail_buf, "buftype", "nofile")
0   api.nvim_buf_set_option(detail_buf, "bufhidden", "wipe")
0   api.nvim_buf_set_option(detail_buf, "swapfile", false)
0   api.nvim_buf_set_name(detail_buf, "Schema Details: " .. schema_id)

0   local detail_win = ui.create_floating_window(detail_buf, 'LLM Schema Details: ' .. schema_id)

0   local lines = { "# Schema: " .. schema_id, "" }
0   if schema.name then
0     table.insert(lines, "## Name: " .. schema.name); table.insert(lines, "")
    end
0   table.insert(lines, "## Schema Definition:"); table.insert(lines, "")
0   if schema.content then
0     local success, parsed = pcall(vim.fn.json_decode, schema.content)
0     if success then
0       local formatted_json = vim.fn.json_encode(parsed)
0       if formatted_json then
0         local indent = "  "
0         local current_indent = 0
0         local formatted_lines = {}
0         for line in formatted_json:gmatch("[^\r\n]+") do
0           if line:match("}") or line:match("]") then
0             current_indent = math.max(0, current_indent - 1)
            end
0           table.insert(formatted_lines, string.rep(indent, current_indent) .. line)
0           if line:match("{") or line:match("%[") then
0             current_indent = current_indent + 1
            end
          end
0         vim.list_extend(lines, formatted_lines)
        else
0         for line in schema.content:gmatch("[^\r\n]+") do table.insert(lines, line) end
        end
      else
0       for line in schema.content:gmatch("[^\r\n]+") do table.insert(lines, line) end
      end
    else
0     table.insert(lines, "No schema content available")
    end
0   table.insert(lines, ""); table.insert(lines, "Press [q]uit, [r]un schema, [e]dit schema, [a]dd alias, [d]elete alias")
0   api.nvim_buf_set_lines(detail_buf, 0, -1, false, lines)

    local function set_detail_keymap(mode, lhs, rhs)
0     api.nvim_buf_set_keymap(detail_buf, mode, lhs, rhs,
0       { noremap = true, silent = true })
    end
0   set_detail_keymap("n", "q", [[<cmd>lua vim.api.nvim_win_close(0, true)<CR>]])
0   set_detail_keymap("n", "<Esc>", [[<cmd>lua vim.api.nvim_win_close(0, true)<CR>]])
0   set_detail_keymap("n", "r",
0     string.format([[<Cmd>lua require('llm.managers.schemas_manager').run_schema_from_details('%s')<CR>]], schema_id))
0   set_detail_keymap("n", "e",
0     string.format([[<Cmd>lua require('llm.managers.schemas_manager').edit_schema_from_details('%s')<CR>]], schema_id))
0   set_detail_keymap("n", "a",
0     string.format([[<Cmd>lua require('llm.managers.schemas_manager').set_alias_from_details('%s')<CR>]], schema_id))
0   set_detail_keymap("n", "d",
0     string.format([[<Cmd>lua require('llm.managers.schemas_manager').delete_alias_from_details('%s')<CR>]], schema_id))

0   styles.setup_buffer_syntax(detail_buf)
  end

* return M

==============================================================================
lua/llm/ui/views/models_view.lua
==============================================================================
  -- llm/ui/views/models_view.lua - UI functions for model management
  -- License: Apache 2.0

* local M = {}

* local ui = require('llm.core.utils.ui')
* local api = vim.api

* function M.select_model(models, callback)
0   vim.ui.select(models, {
      prompt = "Select LLM model:",
      format_item = function(item)
0       return item.id
      end
0   }, callback)
  end

* function M.get_alias(model_display_name, callback)
0     ui.floating_input({ prompt = "Enter alias for model '" .. model_display_name .. "': " }, callback)
  end

* function M.select_alias_to_remove(aliases, callback)
0     vim.ui.select(aliases, {
          prompt = "Select alias to remove:",
0         format_item = function(item) return item end
0     }, callback)
  end

* function M.confirm_remove_alias(alias, callback)
0     ui.floating_confirm({
          prompt = "Remove alias '" .. alias .. "'?",
          on_confirm = function(choice)
0             if choice == "Yes" then
0                 callback()
              end
          end
      })
  end

* function M.get_custom_model_details(callback)
0     local details = {}
0     ui.floating_input({ prompt = "Enter Model ID (e.g., gpt-3.5-turbo-custom):" }, function(model_id)
0         if not model_id or model_id == "" then
0             vim.notify("Model ID cannot be empty. Aborted.", vim.log.levels.WARN)
0             return
          end
0         details.model_id = model_id

0         ui.floating_input({ prompt = "Enter Model Name (display name, optional):" }, function(model_name)
0             details.model_name = (model_name and model_name ~= "") and model_name or nil

0             ui.floating_input({ prompt = "Enter API Base URL (optional):" }, function(api_base)
0                 details.api_base = (api_base and api_base ~= "") and api_base or nil

0                 ui.floating_input({ prompt = "Enter API Key Name (optional, from keys.json):" }, function(api_key_name)
0                     details.api_key_name = (api_key_name and api_key_name ~= "") and api_key_name or nil
0                     callback(details)
                  end)
              end)
          end)
      end)
  end

* return M

==============================================================================
lua/llm/ui/views/plugins_view.lua
==============================================================================
  -- llm/ui/views/plugins_view.lua - UI functions for plugin management
  -- License: Apache 2.0

* local M = {}

* local ui = require('llm.core.utils.ui')

* function M.confirm_uninstall(plugin_name, callback)
0   ui.floating_confirm({
      prompt = "Uninstall " .. plugin_name .. "?",
      on_confirm = function(confirmed)
0       callback(confirmed == "Yes")
      end
    })
  end

* return M

==============================================================================
lua/llm/ui/views/fragments_view.lua
==============================================================================
  -- llm/ui/views/fragments_view.lua - UI functions for fragment management
  -- License: Apache 2.0

* local M = {}

* local ui = require('llm.core.utils.ui')
* local api = vim.api

* function M.view_fragment(fragment_hash, fragment_info)
0   local content_buf = api.nvim_create_buf(false, true)
0   api.nvim_buf_set_option(content_buf, 'buftype', 'nofile')
0   api.nvim_buf_set_option(content_buf, 'bufhidden', 'wipe')
0   api.nvim_buf_set_option(content_buf, 'swapfile', false)
0   api.nvim_buf_set_name(content_buf, 'Fragment: ' .. fragment_hash:sub(1, 8))

0   ui.create_floating_window(content_buf, 'LLM Fragment Content')

0   local content_lines = {
0     "# Fragment: " .. fragment_hash,
0     "Source: " .. (fragment_info.source or "unknown"),
0     "Aliases: " .. (#fragment_info.aliases > 0 and table.concat(fragment_info.aliases, ", ") or "none"),
0     "Date: " .. (fragment_info.datetime or "unknown"),
      "",
      "## Content:",
      "",
    }
0   for line in fragment_info.content:gmatch("[^\r\n]+") do table.insert(content_lines, line) end
0   api.nvim_buf_set_lines(content_buf, 0, -1, false, content_lines)

0   api.nvim_buf_set_option(content_buf, 'modifiable', false)

0   local filetype = "text"
0   if fragment_info.source then
0     local ext = fragment_info.source:match("%.([^%.]+)$")
0     if ext then filetype = ext end
0     if filetype == "js" then filetype = "javascript" end
0     if filetype == "py" then filetype = "python" end
0     if filetype == "md" then filetype = "markdown" end
    end
0   api.nvim_buf_set_option(content_buf, 'filetype', filetype)

0   api.nvim_buf_set_keymap(content_buf, 'n', 'q', [[<cmd>lua vim.api.nvim_win_close(0, true)<CR>]],
0     { noremap = true, silent = true })
0   api.nvim_buf_set_keymap(content_buf, 'n', '<Esc>', [[<cmd>lua vim.api.nvim_win_close(0, true)<CR>]],
0     { noremap = true, silent = true })
  end

* function M.get_alias(callback)
0   ui.floating_input({ prompt = "Enter alias for fragment: " }, callback)
  end

* function M.select_alias_to_remove(aliases, callback)
0   vim.ui.select(aliases, { prompt = "Select alias to remove:" }, callback)
  end

* function M.confirm_remove_alias(alias, callback)
0   ui.floating_confirm({
      prompt = "Remove alias '" .. alias .. "'?",
      on_confirm = function(confirmed)
0       callback(confirmed == "Yes")
      end
    })
  end

* function M.get_prompt(callback)
0     ui.floating_input({
0         prompt = "Enter prompt to use with fragment: "
0     }, callback)
  end

* function M.select_file(callback)
0     vim.ui.input({ prompt = "Enter file path: ", completion = "file" }, function(path)
0         callback(path)
      end)
  end

* function M.get_github_url(callback)
0     vim.ui.input({ prompt = "Enter GitHub URL: " }, function(url)
0         callback(url)
      end)
  end

* return M

==============================================================================
lua/llm/ui/views/keys_view.lua
==============================================================================
  -- llm/ui/views/keys_view.lua - UI functions for key management
  -- License: Apache 2.0

* local M = {}

* local ui = require('llm.core.utils.ui')

* function M.get_custom_key_name(callback)
0   ui.floating_input({ prompt = "Enter custom key name:" }, callback)
  end

* function M.get_api_key(provider_name, callback)
0   ui.floating_input({ prompt = "Enter API key for '" .. provider_name .. "':" }, callback)
  end

* function M.confirm_remove_key(provider_name, callback)
0   ui.floating_confirm({
      prompt = "Remove key for '" .. provider_name .. "'?",
      on_confirm = function()
0       callback()
      end
    })
  end

* return M

==============================================================================
lua/llm/ui/views/templates_view.lua
==============================================================================
  -- llm/ui/views/templates_view.lua - UI functions for template management
  -- License: Apache 2.0

* local M = {}

* local ui = require('llm.core.utils.ui')

* function M.select_template(templates, callback)
*     local template_items = {}

*     for _, template in ipairs(templates) do
*         table.insert(template_items, template)
      end

*     if #template_items == 0 then
*         vim.notify("No templates found", vim.log.levels.INFO)
*         return
      end

*     table.sort(template_items, function(a,b) return a.name < b.name end)

*     vim.ui.select(template_items, {
*         prompt = "Select a template to run:",
          format_item = function(item)
0             return item.name .. " - " .. (item.description or "")
          end
*     }, callback)
  end

* function M.get_user_input(prompt, default, callback)
*     ui.floating_input({
*         prompt = prompt,
*         default = default,
*     }, callback)
  end

* function M.get_input_source(callback)
*     vim.ui.select({
*         "Current selection",
*         "Current buffer",
          "URL (will use curl)"
*     }, {
*         prompt = "Choose input source:"
*     }, callback)
  end

* function M.get_template_type(callback)
*     vim.ui.select({
*         "Regular prompt",
*         "System prompt only",
          "Both system and regular prompt"
*     }, {
*         prompt = "Choose template type:"
*     }, callback)
  end

* function M.get_model_choice(callback)
*     vim.ui.select({
*         "Use default model",
          "Select specific model"
*     }, {
*         prompt = "Model selection:"
*     }, callback)
  end

* function M.select_model(models, callback)
*     vim.ui.select(models, {
*         prompt = "Select model for this template:"
*     }, callback)
  end

* function M.get_fragment_choice(callback)
*     vim.ui.select({
*         "No fragments",
*         "Add fragments",
          "Add system fragments"
*     }, {
*         prompt = "Do you want to add fragments?"
*     }, callback)
  end

* function M.get_add_fragment_choice(callback)
*     vim.ui.select({
*         "Select from file browser",
*         "Enter fragment path/URL",
          "Done adding fragments"
*     }, {
*         prompt = "Add fragment:"
*     }, callback)
  end

* function M.get_add_system_fragment_choice(callback)
*     vim.ui.select({
*         "Select from file browser",
*         "Enter fragment path/URL",
          "Done adding system fragments"
*     }, {
*         prompt = "Add system fragment:"
*     }, callback)
  end

* function M.get_option_choice(callback)
*     vim.ui.select({
*         "No options",
          "Add options"
*     }, {
*         prompt = "Do you want to add model options (like temperature)?"
*     }, callback)
  end

* function M.confirm_extract(callback)
*     ui.floating_confirm({
*         prompt = "Extract first code block from response?",
          on_confirm = function(choice)
0             callback(choice == "Yes")
          end
      })
  end

* function M.get_schema_choice(callback)
*     vim.ui.select({
*         "No schema",
          "Select existing schema"
*     }, {
*         prompt = "Do you want to add a schema?"
*     }, callback)
  end

* function M.select_schema(schemas, callback)
*     local schema_names = {}
*     for _, schema in ipairs(schemas) do
*         table.insert(schema_names, schema.name)
      end
*     table.sort(schema_names)

*     if #schema_names == 0 then
*         vim.notify("No schemas found", vim.log.levels.INFO)
*         callback(nil)
*         return
      end

*     vim.ui.select(schema_names, {
*         prompt = "Select schema:"
*     }, callback)
  end

* function M.confirm_delete(template_name, callback)
*     ui.floating_confirm({
*         prompt = "Delete template '" .. template_name .. "'?",
          on_confirm = function(choice)
0             if choice == "Yes" then
0                 callback()
              end
          end
      })
  end

* return M

==============================================================================
Summary
==============================================================================

File                                           Hits Missed Coverage
-------------------------------------------------------------------
tests/init.lua                                 0    0      0.00%
tests/spec/ui/views/schemas_view_spec.lua      0    0      0.00%
tests/spec/ui/views/templates_view_spec.lua    0    0      0.00%
lua/llm/ui/views/fragments_view.lua            11   37     22.92%
lua/llm/managers/models_manager.lua            92   282    24.60%
lua/llm/ui/views/models_view.lua               9    23     28.12%
lua/llm/managers/keys_manager.lua              36   92     28.12%
lua/llm/managers/schemas_manager.lua           122  287    29.83%
lua/llm/managers/custom_openai.lua             88   185    32.23%
lua/llm/commands.lua                           93   167    35.77%
tests/spec/mock_helper.lua                     3    5      37.50%
lua/llm/managers/templates_manager.lua         184  285    39.23%
lua/llm/managers/plugins_manager.lua           86   116    42.57%
lua/llm/managers/fragments_manager.lua         63   81     43.75%
lua/llm/ui/unified_manager.lua                 62   75     45.26%
lua/llm/chat/session.lua                       62   74     45.59%
lua/llm/core/utils/validate.lua                17   18     48.57%
plugin/llm.lua                                 34   34     50.00%
lua/llm/api.lua                                24   22     52.17%
lua/llm/ui/views/schemas_view.lua              52   45     53.61%
lua/llm/ui/views/keys_view.lua                 6    4      60.00%
tests/spec/mock_llm_cli.lua                    5    3      62.50%
lua/llm/chat.lua                               74   44     62.71%
lua/llm/core/utils/file_utils.lua              37   21     63.79%
lua/llm/ui/views/plugins_view.lua              4    2      66.67%
lua/llm/core/utils/job.lua                     31   15     67.39%
lua/llm/init.lua                               31   12     72.09%
tests/spec/mock_vim.lua                        85   20     80.95%
lua/llm/chat/buffer.lua                        210  45     82.35%
lua/llm/core/utils/ui.lua                      175  23     88.38%
lua/llm/core/utils/text.lua                    71   9      88.75%
lua/llm/core/utils/shell.lua                   103  13     88.79%
lua/llm/core/data/llm_cli.lua                  8    1      88.89%
lua/llm/config.lua                             79   8      90.80%
tests/spec/cache_spec.lua                      35   2      94.59%
tests/spec/core/data/cache_spec.lua            35   2      94.59%
lua/llm/errors.lua                             54   3      94.74%
lua/llm/ui/views/templates_view.lua            94   4      95.92%
lua/llm/core/data/cache.lua                    26   1      96.30%
tests/spec/core/loaders_spec.lua               158  6      96.34%
tests/spec/loaders_spec.lua                    158  6      96.34%
tests/spec/managers/plugins_manager_spec.lua   106  4      96.36%
lua/llm/ui/styles.lua                          135  5      96.43%
tests/spec/init_spec.lua                       96   3      96.97%
lua/llm/facade.lua                             37   1      97.37%
tests/spec/commands_spec.lua                   68   1      98.55%
tests/spec/chat_spec.lua                       256  2      99.22%
lua/llm/core/loaders.lua                       83   0      100.00%
lua/llm/core/utils/notify.lua                  4    0      100.00%
lua/llm/managers/models_io.lua                 17   0      100.00%
lua/llm/ui/ui.lua                              13   0      100.00%
tests/spec/api_spec.lua                        41   0      100.00%
tests/spec/config_spec.lua                     48   0      100.00%
tests/spec/core/data/llm_cli_spec.lua          26   0      100.00%
tests/spec/core/utils/file_utils_spec.lua      68   0      100.00%
tests/spec/core/utils/job_spec.lua             34   0      100.00%
tests/spec/core/utils/notify_spec.lua          14   0      100.00%
tests/spec/core/utils/shell_spec.lua           126  0      100.00%
tests/spec/core/utils/text_spec.lua            85   0      100.00%
tests/spec/core/utils/ui_spec.lua              132  0      100.00%
tests/spec/core/utils/validate_spec.lua        20   0      100.00%
tests/spec/errors_spec.lua                     53   0      100.00%
tests/spec/facade_spec.lua                     68   0      100.00%
tests/spec/file_utils_spec.lua                 68   0      100.00%
tests/spec/llm_cli_spec.lua                    26   0      100.00%
tests/spec/managers/custom_openai_spec.lua     80   0      100.00%
tests/spec/managers/fragments_manager_spec.lua 69   0      100.00%
tests/spec/managers/keys_manager_spec.lua      43   0      100.00%
tests/spec/managers/models_io_spec.lua         42   0      100.00%
tests/spec/managers/models_manager_spec.lua    67   0      100.00%
tests/spec/managers/schemas_manager_spec.lua   142  0      100.00%
tests/spec/managers/templates_manager_spec.lua 63   0      100.00%
tests/spec/notify_spec.lua                     14   0      100.00%
tests/spec/plugin_spec.lua                     64   0      100.00%
tests/spec/scratch_buffer_save_spec.lua        30   0      100.00%
tests/spec/scratch_buffer_spec.lua             17   0      100.00%
tests/spec/spec_helper.lua                     2    0      100.00%
tests/spec/ui/ui_spec.lua                      16   0      100.00%
-------------------------------------------------------------------
Total                                          4790 2088   69.64%
